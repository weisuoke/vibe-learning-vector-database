# å¸¸è§Embeddingæ¨¡å‹

> å­¦ä¹ ç›®æ ‡ï¼šäº†è§£ä¸»æµEmbeddingæ¨¡å‹çš„ç‰¹ç‚¹ï¼Œå­¦ä¼šæ ¹æ®åœºæ™¯é€‰æ‹©åˆé€‚çš„æ¨¡å‹

---

## 1. ã€30å­—æ ¸å¿ƒã€‘

**Embeddingæ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼Œä¸åŒæ¨¡å‹åœ¨ç»´åº¦ã€æ€§èƒ½ã€æˆæœ¬ä¸Šå„æœ‰æƒè¡¡ï¼Œéœ€æ ¹æ®åœºæ™¯é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹ã€‚**

---

## 2. ã€åç›´è§‰ç‚¹ã€‘æœ€å®¹æ˜“é”™çš„3ä¸ªè¯¯åŒº

### è¯¯åŒº1ï¼šç»´åº¦è¶Šé«˜çš„æ¨¡å‹æ•ˆæœè¶Šå¥½ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- ç»´åº¦é«˜åªä»£è¡¨"è¡¨ç¤ºèƒ½åŠ›"å¼ºï¼Œä¸ä»£è¡¨æ•ˆæœå¥½
- å®é™…æ•ˆæœå–å†³äºï¼šè®­ç»ƒæ•°æ®ã€æ¨¡å‹æ¶æ„ã€è®­ç»ƒç›®æ ‡
- 384ç»´çš„all-MiniLM-L6-v2åœ¨æŸäº›ä»»åŠ¡ä¸Šå¯èƒ½æ¯”1536ç»´çš„æ¨¡å‹æ›´å¥½

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
- ç›´è§‰ä¸Š"æ›´å¤šå‚æ•°=æ›´å¥½"
- ç±»ä¼¼äºè®¤ä¸º"ç›¸æœºåƒç´ è¶Šé«˜ç…§ç‰‡è¶Šå¥½"
- å¿½ç•¥äº†æ¨¡å‹è®­ç»ƒè´¨é‡çš„å½±å“

**æ­£ç¡®ç†è§£ï¼š**
```python
# ç»´åº¦ vs æ•ˆæœçš„å…³ç³»ä¸æ˜¯çº¿æ€§çš„

# æ¨¡å‹å¯¹æ¯”ï¼ˆMTEBåŸºå‡†æµ‹è¯•ï¼‰
models = {
    "all-MiniLM-L6-v2": {"dim": 384, "score": 68.06},
    "all-mpnet-base-v2": {"dim": 768, "score": 69.57},
    "text-embedding-ada-002": {"dim": 1536, "score": 70.5},
    "text-embedding-3-large": {"dim": 3072, "score": 75.2},  # æœ€æ–°æœ€å¼º
}

# è§‚å¯Ÿï¼š
# 1. ç»´åº¦ç¿»å€ï¼Œåˆ†æ•°åªæå‡1-2åˆ†
# 2. ç»´åº¦ä¸æ˜¯å”¯ä¸€å†³å®šå› ç´ 
# 3. æœ€æ–°æ¨¡å‹å¾€å¾€æ›´ä¼˜ï¼ˆè®­ç»ƒæ•°æ®ã€æ¶æ„æ”¹è¿›ï¼‰

print("ç»´åº¦ vs æ•ˆæœï¼š")
for name, info in models.items():
    print(f"  {name}: {info['dim']}ç»´ â†’ åˆ†æ•°{info['score']}")
```

---

### è¯¯åŒº2ï¼šOpenAIçš„æ¨¡å‹ä¸€å®šæ˜¯æœ€å¥½çš„ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- OpenAIæ¨¡å‹æ˜¯é€šç”¨å‹ï¼Œç‰¹å®šé¢†åŸŸå¯èƒ½ä¸æ˜¯æœ€ä¼˜
- å¼€æºæ¨¡å‹åœ¨æŸäº›åœºæ™¯ä¸‹è¡¨ç°æ›´å¥½
- æˆæœ¬ã€å»¶è¿Ÿã€éšç§ä¹Ÿæ˜¯é‡è¦è€ƒé‡å› ç´ 

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
- OpenAIå“ç‰Œæ•ˆåº”å¼º
- ChatGPTçš„æˆåŠŸå¸¦æ¥çš„å…‰ç¯æ•ˆåº”
- æ²¡æœ‰åœ¨è‡ªå·±çš„æ•°æ®ä¸Šå®é™…æµ‹è¯•

**æ­£ç¡®ç†è§£ï¼š**
```python
# ä¸åŒåœºæ™¯çš„æœ€ä½³é€‰æ‹©ä¸åŒ

scenarios = {
    "é€šç”¨æ–‡æœ¬æœç´¢": {
        "æ¨è": "text-embedding-3-small",
        "åŸå› ": "æ€§ä»·æ¯”é«˜ï¼Œæ•ˆæœå¥½"
    },
    "ä¸­æ–‡ä¸ºä¸»": {
        "æ¨è": "BAAI/bge-large-zh",
        "åŸå› ": "ä¸“é—¨é’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–"
    },
    "ä»£ç æœç´¢": {
        "æ¨è": "Voyage/voyage-code-2",
        "åŸå› ": "ä¸“é—¨é’ˆå¯¹ä»£ç è®­ç»ƒ"
    },
    "éšç§æ•æ„Ÿ": {
        "æ¨è": "æœ¬åœ°éƒ¨ç½²å¼€æºæ¨¡å‹",
        "åŸå› ": "æ•°æ®ä¸å‡ºå¢ƒ"
    },
    "ä½å»¶è¿Ÿéœ€æ±‚": {
        "æ¨è": "all-MiniLM-L6-v2",
        "åŸå› ": "æ¨¡å‹å°ï¼Œæ¨ç†å¿«"
    }
}

for scenario, info in scenarios.items():
    print(f"{scenario}ï¼š")
    print(f"  æ¨èï¼š{info['æ¨è']}")
    print(f"  åŸå› ï¼š{info['åŸå› ']}\n")
```

---

### è¯¯åŒº3ï¼šå¯ä»¥éšæ„åˆ‡æ¢Embeddingæ¨¡å‹ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- ä¸åŒæ¨¡å‹çš„å‘é‡ç©ºé—´ä¸å…¼å®¹
- åˆ‡æ¢æ¨¡å‹æ„å‘³ç€éœ€è¦é‡æ–°ç”Ÿæˆæ‰€æœ‰embedding
- è¿™æ˜¯ä¸€ä¸ªé‡å¤§çš„æ¶æ„å†³ç­–ï¼Œéœ€è¦è°¨æ…

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
- çœ‹åˆ°éƒ½æ˜¯"768ç»´å‘é‡"ï¼Œä»¥ä¸ºå¯ä»¥äº’æ¢
- ä¸ç†è§£ä¸åŒæ¨¡å‹çš„"è¯­ä¹‰åæ ‡ç³»"ä¸åŒ
- ä½ä¼°äº†é‡æ–°ç´¢å¼•çš„æˆæœ¬

**æ­£ç¡®ç†è§£ï¼š**
```python
# åˆ‡æ¢æ¨¡å‹çš„æˆæœ¬åˆ†æ

def migration_cost_analysis(num_docs, embedding_model):
    """åˆ†æåˆ‡æ¢æ¨¡å‹çš„æˆæœ¬"""
    
    # å‡è®¾å‚æ•°
    doc_count = num_docs
    chars_per_doc = 500
    
    # OpenAIå®šä»·ï¼ˆç¤ºä¾‹ï¼‰
    if embedding_model == "text-embedding-3-small":
        price_per_1m_tokens = 0.02
    elif embedding_model == "text-embedding-3-large":
        price_per_1m_tokens = 0.13
    
    # ä¼°ç®—tokenæ•°ï¼ˆç²—ç•¥ï¼š1 token â‰ˆ 4 å­—ç¬¦ï¼‰
    total_tokens = doc_count * chars_per_doc / 4
    
    # è®¡ç®—æˆæœ¬
    cost = total_tokens / 1_000_000 * price_per_1m_tokens
    
    # è®¡ç®—æ—¶é—´ï¼ˆå‡è®¾æ¯ç§’100æ¡ï¼‰
    time_hours = doc_count / 100 / 3600
    
    return {
        "æ–‡æ¡£æ•°": doc_count,
        "é¢„ä¼°æˆæœ¬($)": round(cost, 2),
        "é¢„ä¼°æ—¶é—´(å°æ—¶)": round(time_hours, 2)
    }

# ç¤ºä¾‹ï¼šåˆ‡æ¢100ä¸‡æ–‡æ¡£çš„æ¨¡å‹
result = migration_cost_analysis(1_000_000, "text-embedding-3-small")
print("åˆ‡æ¢æ¨¡å‹çš„æˆæœ¬ï¼ˆ100ä¸‡æ–‡æ¡£ï¼‰ï¼š")
for k, v in result.items():
    print(f"  {k}: {v}")

# æ•™è®­ï¼šé€‰æ‹©æ¨¡å‹æ—¶è¦æ…é‡ï¼Œåˆ‡æ¢æˆæœ¬å¾ˆé«˜ï¼
```

---

## 3. ã€æœ€å°å¯ç”¨ã€‘æŒæ¡20%è§£å†³80%é—®é¢˜

æŒæ¡ä»¥ä¸‹å†…å®¹ï¼Œå°±èƒ½é€‰æ‹©å’Œä½¿ç”¨åˆé€‚çš„Embeddingæ¨¡å‹ï¼š

### 3.1 ä¸»æµæ¨¡å‹é€ŸæŸ¥è¡¨

| æ¨¡å‹ | ç»´åº¦ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ | æˆæœ¬ |
|------|------|------|---------|------|
| text-embedding-3-small | 1536 | æ€§ä»·æ¯”é«˜ | é€šç”¨åœºæ™¯ | $0.02/1M |
| text-embedding-3-large | 3072 | æ•ˆæœæœ€ä½³ | é«˜ç²¾åº¦éœ€æ±‚ | $0.13/1M |
| all-MiniLM-L6-v2 | 384 | é€Ÿåº¦å¿« | åŸå‹å¼€å‘ | å…è´¹ |
| all-mpnet-base-v2 | 768 | å¹³è¡¡å‹ | ä¸­ç­‰è§„æ¨¡ | å…è´¹ |
| bge-large-zh | 1024 | ä¸­æ–‡ä¼˜åŒ– | ä¸­æ–‡åœºæ™¯ | å…è´¹ |

### 3.2 ä½¿ç”¨OpenAIæ¨¡å‹

```python
from openai import OpenAI

client = OpenAI()

def get_embedding_openai(text, model="text-embedding-3-small"):
    """ä½¿ç”¨OpenAIç”Ÿæˆembedding"""
    response = client.embeddings.create(
        input=text,
        model=model
    )
    return response.data[0].embedding

# å•æ–‡æœ¬
text = "å‘é‡æ•°æ®åº“æ˜¯AIåº”ç”¨çš„åŸºç¡€è®¾æ–½"
emb = get_embedding_openai(text)
print(f"ç»´åº¦: {len(emb)}")

# æ‰¹é‡ï¼ˆæ›´é«˜æ•ˆï¼‰
texts = ["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"]
response = client.embeddings.create(
    input=texts,
    model="text-embedding-3-small"
)
embeddings = [d.embedding for d in response.data]
```

### 3.3 ä½¿ç”¨å¼€æºæ¨¡å‹ï¼ˆSentence-Transformersï¼‰

```python
from sentence_transformers import SentenceTransformer

# åŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡ä¼šä¸‹è½½ï¼‰
model = SentenceTransformer('all-MiniLM-L6-v2')

# å•æ–‡æœ¬
text = "å‘é‡æ•°æ®åº“æ˜¯AIåº”ç”¨çš„åŸºç¡€è®¾æ–½"
emb = model.encode(text)
print(f"ç»´åº¦: {len(emb)}")

# æ‰¹é‡ï¼ˆè‡ªåŠ¨å¹¶è¡Œï¼‰
texts = ["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"]
embeddings = model.encode(texts)
print(f"å½¢çŠ¶: {embeddings.shape}")  # (3, 384)
```

### 3.4 ä½¿ç”¨ä¸­æ–‡æ¨¡å‹ï¼ˆBGEï¼‰

```python
from sentence_transformers import SentenceTransformer

# åŠ è½½ä¸­æ–‡æ¨¡å‹
model = SentenceTransformer('BAAI/bge-large-zh-v1.5')

# ä¸­æ–‡æ–‡æœ¬
texts = [
    "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒ",
    "æ·±åº¦å­¦ä¹ åŸºäºç¥ç»ç½‘ç»œ",
    "Pythonæ˜¯æµè¡Œçš„ç¼–ç¨‹è¯­è¨€"
]

# ç”Ÿæˆembedding
embeddings = model.encode(texts, normalize_embeddings=True)
print(f"ç»´åº¦: {embeddings.shape[1]}")  # 1024
```

### 3.5 é€‰æ‹©æ¨¡å‹çš„å†³ç­–æ ‘

```
å¼€å§‹
  â”‚
  â”œâ”€ æ˜¯å¦éœ€è¦APIè°ƒç”¨ï¼Ÿ
  â”‚   â”œâ”€ æ˜¯ â†’ æ˜¯å¦æœ‰é¢„ç®—é™åˆ¶ï¼Ÿ
  â”‚   â”‚       â”œâ”€ æ˜¯ â†’ text-embedding-3-small
  â”‚   â”‚       â””â”€ å¦ â†’ text-embedding-3-large
  â”‚   â”‚
  â”‚   â””â”€ å¦ â†’ æ˜¯å¦ä¸»è¦æ˜¯ä¸­æ–‡ï¼Ÿ
  â”‚           â”œâ”€ æ˜¯ â†’ bge-large-zh-v1.5
  â”‚           â””â”€ å¦ â†’ æ˜¯å¦éœ€è¦é«˜æ€§èƒ½ï¼Ÿ
  â”‚                   â”œâ”€ æ˜¯ â†’ all-mpnet-base-v2
  â”‚                   â””â”€ å¦ â†’ all-MiniLM-L6-v2
```

**è¿™äº›çŸ¥è¯†è¶³ä»¥ï¼š**
- æ ¹æ®åœºæ™¯é€‰æ‹©åˆé€‚çš„æ¨¡å‹
- ä½¿ç”¨APIæˆ–å¼€æºæ¨¡å‹ç”Ÿæˆembedding
- ç†è§£æ¨¡å‹åˆ‡æ¢çš„æˆæœ¬
- ä¸ºé¡¹ç›®åšå‡ºåˆç†çš„æŠ€æœ¯é€‰å‹

---

## 4. ã€å®æˆ˜ä»£ç ã€‘ä¸€ä¸ªèƒ½è·‘çš„ä¾‹å­

```python
import numpy as np
import time

# ===== 1. æ¨¡æ‹Ÿä¸åŒæ¨¡å‹çš„ç‰¹ç‚¹ =====
print("=== æ¨¡æ‹ŸEmbeddingæ¨¡å‹ç‰¹ç‚¹ ===")

class MockEmbeddingModel:
    """æ¨¡æ‹Ÿä¸åŒçš„Embeddingæ¨¡å‹"""
    
    def __init__(self, name, dim, latency_ms):
        self.name = name
        self.dim = dim
        self.latency_ms = latency_ms
    
    def encode(self, texts):
        """ç”Ÿæˆembeddingï¼ˆæ¨¡æ‹Ÿï¼‰"""
        if isinstance(texts, str):
            texts = [texts]
        
        # æ¨¡æ‹Ÿå»¶è¿Ÿ
        time.sleep(self.latency_ms * len(texts) / 1000)
        
        # ç”Ÿæˆä¼ªéšæœºembedding
        embeddings = []
        for text in texts:
            np.random.seed(hash(text + self.name) % 2**32)
            emb = np.random.randn(self.dim)
            emb = emb / np.linalg.norm(emb)  # å½’ä¸€åŒ–
            embeddings.append(emb)
        
        return np.array(embeddings)

# åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹
models = {
    "text-embedding-3-small": MockEmbeddingModel("openai-small", 1536, 50),
    "text-embedding-3-large": MockEmbeddingModel("openai-large", 3072, 100),
    "all-MiniLM-L6-v2": MockEmbeddingModel("minilm", 384, 5),
    "all-mpnet-base-v2": MockEmbeddingModel("mpnet", 768, 15),
    "bge-large-zh": MockEmbeddingModel("bge-zh", 1024, 20),
}

# æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
print("\næ¨¡å‹é…ç½®ï¼š")
for name, model in models.items():
    print(f"  {name}: {model.dim}ç»´, å»¶è¿Ÿ~{model.latency_ms}ms/æ¡")

# ===== 2. æµ‹è¯•ä¸åŒæ¨¡å‹ =====
print("\n=== æ¨¡å‹æ€§èƒ½æµ‹è¯• ===")

test_texts = [
    "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯",
    "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œè®­ç»ƒ",
    "å‘é‡æ•°æ®åº“å­˜å‚¨å’Œæ£€ç´¢é«˜ç»´å‘é‡",
    "RAGç³»ç»Ÿç»“åˆäº†æ£€ç´¢å’Œç”Ÿæˆèƒ½åŠ›",
    "Pythonæ˜¯æ•°æ®ç§‘å­¦çš„é¦–é€‰ç¼–ç¨‹è¯­è¨€"
]

for name, model in models.items():
    start = time.time()
    embeddings = model.encode(test_texts)
    elapsed = time.time() - start
    
    print(f"\n{name}:")
    print(f"  ç»´åº¦: {embeddings.shape[1]}")
    print(f"  è€—æ—¶: {elapsed*1000:.1f}ms")
    print(f"  ååé‡: {len(test_texts)/elapsed:.1f} æ¡/ç§’")

# ===== 3. ç›¸ä¼¼åº¦å¯¹æ¯”ï¼ˆä¸åŒæ¨¡å‹ï¼‰ =====
print("\n=== è·¨æ¨¡å‹ç›¸ä¼¼åº¦ï¼ˆæ¼”ç¤ºï¼šä¸å¯æ¯”è¾ƒï¼‰===")

def cosine_similarity(v1, v2):
    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

text1 = "æœºå™¨å­¦ä¹ å…¥é—¨"
text2 = "æ·±åº¦å­¦ä¹ åŸºç¡€"

print(f"\næ¯”è¾ƒ '{text1}' å’Œ '{text2}'ï¼š")
for name, model in list(models.items())[:3]:
    emb1 = model.encode(text1)[0]
    emb2 = model.encode(text2)[0]
    sim = cosine_similarity(emb1, emb2)
    print(f"  {name}: ç›¸ä¼¼åº¦ = {sim:.4f}")

print("\næ³¨æ„ï¼šä¸åŒæ¨¡å‹çš„ç›¸ä¼¼åº¦æ•°å€¼ä¸å¯ç›´æ¥æ¯”è¾ƒï¼")
print("åº”è¯¥åœ¨åŒä¸€æ¨¡å‹å†…éƒ¨æ¯”è¾ƒï¼Œæˆ–ä½¿ç”¨æ ‡å‡†åŒ–è¯„ä¼°é›†")

# ===== 4. æˆæœ¬ä¼°ç®— =====
print("\n=== æˆæœ¬ä¼°ç®— ===")

def estimate_cost(num_docs, avg_tokens_per_doc, model_name):
    """ä¼°ç®—ä½¿ç”¨OpenAIæ¨¡å‹çš„æˆæœ¬"""
    
    pricing = {
        "text-embedding-3-small": 0.02,   # $/1M tokens
        "text-embedding-3-large": 0.13,
        "text-embedding-ada-002": 0.10,
    }
    
    if model_name not in pricing:
        return {"error": "æœªçŸ¥æ¨¡å‹æˆ–å…è´¹å¼€æºæ¨¡å‹"}
    
    total_tokens = num_docs * avg_tokens_per_doc
    cost = total_tokens / 1_000_000 * pricing[model_name]
    
    return {
        "æ¨¡å‹": model_name,
        "æ–‡æ¡£æ•°": num_docs,
        "æ€»Token": f"{total_tokens:,}",
        "é¢„ä¼°æˆæœ¬": f"${cost:.2f}"
    }

# ä¼°ç®—ä¸åŒè§„æ¨¡çš„æˆæœ¬
scenarios = [
    (10_000, 200, "text-embedding-3-small"),
    (100_000, 200, "text-embedding-3-small"),
    (1_000_000, 200, "text-embedding-3-small"),
    (1_000_000, 200, "text-embedding-3-large"),
]

print("\nä¸åŒåœºæ™¯çš„æˆæœ¬é¢„ä¼°ï¼š")
for num_docs, tokens, model in scenarios:
    result = estimate_cost(num_docs, tokens, model)
    print(f"  {result['æ–‡æ¡£æ•°']:>10,} æ–‡æ¡£ Ã— {tokens} tokens/{result['æ¨¡å‹']}:")
    print(f"    é¢„ä¼°æˆæœ¬: {result['é¢„ä¼°æˆæœ¬']}")

# ===== 5. æ¨¡å‹é€‰æ‹©æ¨è =====
print("\n=== æ¨¡å‹é€‰æ‹©æ¨è ===")

def recommend_model(requirements):
    """æ ¹æ®éœ€æ±‚æ¨èæ¨¡å‹"""
    
    if requirements.get("budget") == "low":
        if requirements.get("language") == "chinese":
            return "bge-large-zh-v1.5", "å…è´¹å¼€æºï¼Œä¸­æ–‡ä¼˜åŒ–"
        else:
            return "all-MiniLM-L6-v2", "å…è´¹å¼€æºï¼Œé€Ÿåº¦å¿«"
    
    if requirements.get("accuracy") == "high":
        return "text-embedding-3-large", "æ•ˆæœæœ€ä½³"
    
    if requirements.get("language") == "chinese":
        return "bge-large-zh-v1.5", "ä¸­æ–‡æ•ˆæœå¥½"
    
    return "text-embedding-3-small", "æ€§ä»·æ¯”æœ€é«˜"

# æµ‹è¯•ä¸åŒéœ€æ±‚
test_requirements = [
    {"budget": "low", "language": "english"},
    {"budget": "low", "language": "chinese"},
    {"accuracy": "high"},
    {"language": "chinese"},
    {},  # é»˜è®¤
]

print("\néœ€æ±‚ â†’ æ¨èæ¨¡å‹ï¼š")
for req in test_requirements:
    model, reason = recommend_model(req)
    print(f"  {req or 'é»˜è®¤'}")
    print(f"    â†’ {model}: {reason}\n")

# ===== 6. æ‰¹é‡å¤„ç†æœ€ä½³å®è·µ =====
print("=== æ‰¹é‡å¤„ç†æœ€ä½³å®è·µ ===")

def batch_encode(model, texts, batch_size=32):
    """æ‰¹é‡ç”Ÿæˆembeddingï¼ˆæœ€ä½³å®è·µï¼‰"""
    
    all_embeddings = []
    
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        embeddings = model.encode(batch)
        all_embeddings.append(embeddings)
        
        # è¿›åº¦æ˜¾ç¤º
        progress = min(i + batch_size, len(texts))
        print(f"  è¿›åº¦: {progress}/{len(texts)}")
    
    return np.vstack(all_embeddings)

# æ¨¡æ‹Ÿå¤§æ‰¹é‡å¤„ç†
large_texts = [f"æ–‡æ¡£ {i}" for i in range(100)]
model = models["all-MiniLM-L6-v2"]

print(f"\næ‰¹é‡å¤„ç† {len(large_texts)} æ¡æ–‡æ¡£ï¼š")
start = time.time()
embeddings = batch_encode(model, large_texts, batch_size=32)
elapsed = time.time() - start

print(f"\næ€»è€—æ—¶: {elapsed:.2f}ç§’")
print(f"ååé‡: {len(large_texts)/elapsed:.1f} æ¡/ç§’")
print(f"ç»“æœå½¢çŠ¶: {embeddings.shape}")
```

**è¿è¡Œè¾“å‡ºç¤ºä¾‹ï¼š**
```
=== æ¨¡æ‹ŸEmbeddingæ¨¡å‹ç‰¹ç‚¹ ===

æ¨¡å‹é…ç½®ï¼š
  text-embedding-3-small: 1536ç»´, å»¶è¿Ÿ~50ms/æ¡
  text-embedding-3-large: 3072ç»´, å»¶è¿Ÿ~100ms/æ¡
  all-MiniLM-L6-v2: 384ç»´, å»¶è¿Ÿ~5ms/æ¡
  ...

=== æ¨¡å‹æ€§èƒ½æµ‹è¯• ===

text-embedding-3-small:
  ç»´åº¦: 1536
  è€—æ—¶: 250.3ms
  ååé‡: 20.0 æ¡/ç§’

all-MiniLM-L6-v2:
  ç»´åº¦: 384
  è€—æ—¶: 25.1ms
  ååé‡: 199.2 æ¡/ç§’
...

=== æˆæœ¬ä¼°ç®— ===

ä¸åŒåœºæ™¯çš„æˆæœ¬é¢„ä¼°ï¼š
      10,000 æ–‡æ¡£ Ã— 200 tokens/text-embedding-3-small:
    é¢„ä¼°æˆæœ¬: $0.04
   1,000,000 æ–‡æ¡£ Ã— 200 tokens/text-embedding-3-large:
    é¢„ä¼°æˆæœ¬: $26.00
```

---

## 5. ã€é¢è¯•å¿…é—®ã€‘å¦‚æœè¢«é—®åˆ°ï¼Œæ€ä¹ˆç­”å‡ºå½©

### é—®é¢˜ï¼š"ä½ ä»¬é¡¹ç›®ä¸­æ˜¯æ€ä¹ˆé€‰æ‹©Embeddingæ¨¡å‹çš„ï¼Ÿ"

**æ™®é€šå›ç­”ï¼ˆâŒ ä¸å‡ºå½©ï¼‰ï¼š**
"æˆ‘ä»¬ç”¨çš„æ˜¯OpenAIçš„æ¨¡å‹ï¼Œå› ä¸ºæ•ˆæœå¥½ã€‚"

**å‡ºå½©å›ç­”ï¼ˆâœ… æ¨èï¼‰ï¼š**

> **æˆ‘ä»¬åœ¨é€‰æ‹©Embeddingæ¨¡å‹æ—¶ï¼Œè€ƒè™‘äº†ä»¥ä¸‹å‡ ä¸ªç»´åº¦ï¼š**
>
> 1. **æ•ˆæœè¯„ä¼°**ï¼š
>    - é¦–å…ˆåœ¨æˆ‘ä»¬çš„é¢†åŸŸæ•°æ®ä¸Šæµ‹è¯•äº†å‡ ä¸ªå€™é€‰æ¨¡å‹
>    - ä½¿ç”¨è‡ªå»ºçš„æµ‹è¯•é›†è®¡ç®—Recall@Kå’ŒMRR
>    - å‘ç°å¯¹äºæˆ‘ä»¬çš„ä¸­æ–‡åœºæ™¯ï¼ŒBGEæ¨¡å‹æ¯”OpenAIæ•ˆæœç•¥å¥½
>
> 2. **æˆæœ¬åˆ†æ**ï¼š
>    - æˆ‘ä»¬æœ‰100ä¸‡+æ–‡æ¡£ï¼Œä½¿ç”¨OpenAIçš„æˆæœ¬çº¦$200/æ¬¡å…¨é‡ç´¢å¼•
>    - å¼€æºæ¨¡å‹å¯ä»¥æœ¬åœ°éƒ¨ç½²ï¼Œè¾¹é™…æˆæœ¬å‡ ä¹ä¸º0
>    - è€ƒè™‘åˆ°éœ€è¦é¢‘ç¹æ›´æ–°ï¼Œé€‰æ‹©äº†æœ¬åœ°éƒ¨ç½²æ–¹æ¡ˆ
>
> 3. **æ€§èƒ½éœ€æ±‚**ï¼š
>    - åœ¨çº¿æŸ¥è¯¢éœ€è¦ä½å»¶è¿Ÿï¼ˆ<100msï¼‰
>    - æµ‹è¯•å‘ç°æœ¬åœ°éƒ¨ç½²çš„MiniLMå»¶è¿Ÿçº¦10ms
>    - OpenAI APIå»¶è¿Ÿçº¦50-100msï¼ˆç½‘ç»œå› ç´ ï¼‰
>
> 4. **æœ€ç»ˆå†³ç­–**ï¼š
>    - é€‰æ‹©äº†bge-large-zh-v1.5ï¼Œæœ¬åœ°éƒ¨ç½²
>    - ä¸­æ–‡æ•ˆæœå¥½ï¼Œå»¶è¿Ÿä½ï¼Œæ— APIæˆæœ¬
>    - é€šè¿‡é‡åŒ–æŠ€æœ¯é™ä½äº†æ˜¾å­˜å ç”¨
>
> **ç»éªŒæ€»ç»“**ï¼šæ²¡æœ‰æœ€å¥½çš„æ¨¡å‹ï¼Œåªæœ‰æœ€é€‚åˆçš„æ¨¡å‹ã€‚ä¸€å®šè¦åœ¨è‡ªå·±çš„æ•°æ®ä¸Šæµ‹è¯•ï¼Œè€Œä¸æ˜¯åªçœ‹benchmarkã€‚

**ä¸ºä»€ä¹ˆè¿™ä¸ªå›ç­”å‡ºå½©ï¼Ÿ**
1. âœ… æœ‰æ¸…æ™°çš„è¯„ä¼°æ¡†æ¶ï¼ˆæ•ˆæœã€æˆæœ¬ã€æ€§èƒ½ï¼‰
2. âœ… æåˆ°äº†å®é™…æµ‹è¯•ï¼Œä¸æ˜¯çº¸ä¸Šè°ˆå…µ
3. âœ… æœ‰å…·ä½“çš„æ•°æ®æ”¯æ’‘
4. âœ… å±•ç¤ºäº†æŠ€æœ¯å†³ç­–çš„å…¨é¢æ€è€ƒ
5. âœ… æœ‰å®è·µæ€»ç»“å’Œç»éªŒè¾“å‡º

---

### å»¶ä¼¸é—®é¢˜ï¼š"å¦‚æœè¦è¿ç§»åˆ°æ–°æ¨¡å‹ï¼Œä½ ä¼šæ€ä¹ˆåšï¼Ÿ"

**å‡ºå½©å›ç­”ï¼š**

> **æ¨¡å‹è¿ç§»æ˜¯ä¸€ä¸ªç³»ç»Ÿå·¥ç¨‹ï¼Œéœ€è¦åˆ†é˜¶æ®µè¿›è¡Œï¼š**
>
> 1. **è¯„ä¼°é˜¶æ®µ**ï¼ˆ1-2å‘¨ï¼‰
>    - åœ¨æµ‹è¯•é›†ä¸Šå¯¹æ¯”æ–°è€æ¨¡å‹æ•ˆæœ
>    - è¯„ä¼°æˆæœ¬å˜åŒ–ï¼ˆAPIè´¹ç”¨ã€è®¡ç®—èµ„æºï¼‰
>    - ç¡®è®¤ç»´åº¦å˜åŒ–æ˜¯å¦å½±å“å‘é‡æ•°æ®åº“é…ç½®
>
> 2. **å…¼å®¹æ€§è®¾è®¡**
>    - å‘é‡æ•°æ®åº“éœ€è¦æ”¯æŒæ–°ç»´åº¦
>    - å¯èƒ½éœ€è¦åˆ›å»ºæ–°çš„Collection
>    - è€ƒè™‘æ¸è¿›å¼è¿ç§»è¿˜æ˜¯ä¸€æ¬¡æ€§åˆ‡æ¢
>
> 3. **è¿ç§»æ‰§è¡Œ**
>    - æ‰¹é‡é‡æ–°ç”Ÿæˆæ‰€æœ‰æ–‡æ¡£çš„embedding
>    - ä½¿ç”¨å¢é‡æ–¹å¼å†™å…¥æ–°Collection
>    - ä¿ç•™æ—§Collectionä½œä¸ºå›é€€æ–¹æ¡ˆ
>
> 4. **ç°åº¦å‘å¸ƒ**
>    - å…ˆåˆ‡æ¢å°æµé‡åˆ°æ–°æ¨¡å‹
>    - ç›‘æ§æ•ˆæœæŒ‡æ ‡ï¼ˆç‚¹å‡»ç‡ã€æ»¡æ„åº¦ï¼‰
>    - ç¡®è®¤æ— é—®é¢˜åå…¨é‡åˆ‡æ¢
>
> 5. **æ¸…ç†æ”¶å°¾**
>    - ä¸‹çº¿æ—§Collection
>    - æ›´æ–°æ–‡æ¡£å’Œé…ç½®
>    - æ€»ç»“ç»éªŒæ•™è®­

---

## 6. ã€åŒ–éª¨ç»µæŒã€‘10ä¸ª2åˆ†é’ŸçŸ¥è¯†å¡ç‰‡

### å¡ç‰‡1ï¼šEmbeddingæ¨¡å‹å…¨æ™¯å›¾ ğŸ—ºï¸

```
å•†ä¸šAPIæ¨¡å‹ï¼š
â”œâ”€â”€ OpenAI
â”‚   â”œâ”€â”€ text-embedding-3-small (1536ç»´, $0.02/1M)
â”‚   â”œâ”€â”€ text-embedding-3-large (3072ç»´, $0.13/1M)
â”‚   â””â”€â”€ text-embedding-ada-002 (1536ç»´, æ—§ç‰ˆ)
â”œâ”€â”€ Cohere
â”‚   â””â”€â”€ embed-english-v3.0 (1024ç»´)
â””â”€â”€ Voyage AI
    â””â”€â”€ voyage-2 (1024ç»´, ä¸“ä¸šé¢†åŸŸå¼º)

å¼€æºæ¨¡å‹ï¼š
â”œâ”€â”€ Sentence-Transformers
â”‚   â”œâ”€â”€ all-MiniLM-L6-v2 (384ç»´, å¿«é€Ÿ)
â”‚   â””â”€â”€ all-mpnet-base-v2 (768ç»´, å¹³è¡¡)
â”œâ”€â”€ BGE (æ™ºæº)
â”‚   â”œâ”€â”€ bge-large-zh-v1.5 (1024ç»´, ä¸­æ–‡)
â”‚   â””â”€â”€ bge-m3 (1024ç»´, å¤šè¯­è¨€)
â””â”€â”€ E5 (å¾®è½¯)
    â””â”€â”€ multilingual-e5-large (1024ç»´)
```

---

### å¡ç‰‡2ï¼šOpenAIæ¨¡å‹å¯¹æ¯” ğŸ¤–

| æ¨¡å‹ | ç»´åº¦ | ä»·æ ¼ | ç‰¹ç‚¹ |
|------|------|------|------|
| text-embedding-3-small | 1536 | $0.02/1M | æ€§ä»·æ¯”ä¹‹ç‹ |
| text-embedding-3-large | 3072 | $0.13/1M | æ•ˆæœæœ€ä½³ |
| text-embedding-ada-002 | 1536 | $0.10/1M | æ—§ç‰ˆï¼Œä¸æ¨è |

**é€‰æ‹©å»ºè®®ï¼š**
- é»˜è®¤é€‰3-small
- é«˜ç²¾åº¦éœ€æ±‚é€‰3-large
- ä¸è¦å†ç”¨ada-002äº†

---

### å¡ç‰‡3ï¼šSentence-Transformerså…¥é—¨ ğŸš€

```python
# å®‰è£…
# pip install sentence-transformers

from sentence_transformers import SentenceTransformer

# åŠ è½½æ¨¡å‹
model = SentenceTransformer('all-MiniLM-L6-v2')

# ç”Ÿæˆembedding
sentences = ["Hello world", "ä½ å¥½ä¸–ç•Œ"]
embeddings = model.encode(sentences)

print(f"å½¢çŠ¶: {embeddings.shape}")  # (2, 384)
```

**å¸¸ç”¨æ¨¡å‹ï¼š**
- `all-MiniLM-L6-v2`ï¼šå¿«é€Ÿï¼Œé€‚åˆåŸå‹
- `all-mpnet-base-v2`ï¼šå¹³è¡¡ï¼Œé€šç”¨åœºæ™¯
- `paraphrase-multilingual-MiniLM-L12-v2`ï¼šå¤šè¯­è¨€

---

### å¡ç‰‡4ï¼šä¸­æ–‡æ¨¡å‹é€‰æ‹© ğŸ‡¨ğŸ‡³

| æ¨¡å‹ | ç»´åº¦ | æ¥æº | ç‰¹ç‚¹ |
|------|------|------|------|
| bge-large-zh-v1.5 | 1024 | æ™ºæº | ä¸­æ–‡ç¬¬ä¸€ |
| bge-m3 | 1024 | æ™ºæº | å¤šè¯­è¨€ |
| text2vec-large-chinese | 1024 | shibing624 | ç®€å•æ˜“ç”¨ |
| m3e-base | 768 | Moka | è½»é‡çº§ |

**æ¨èï¼š** BGEç³»åˆ—ï¼Œä¸­æ–‡æ•ˆæœé¢†å…ˆ

```python
model = SentenceTransformer('BAAI/bge-large-zh-v1.5')
```

---

### å¡ç‰‡5ï¼šæ¨¡å‹æ€§èƒ½å¯¹æ¯” ğŸ“Š

```
å»¶è¿Ÿï¼ˆå•æ¡ï¼‰ï¼š
  all-MiniLM-L6-v2:    5ms   â–ˆâ–ˆâ–ˆâ–ˆ
  all-mpnet-base-v2:   15ms  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  bge-large-zh:        25ms  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  OpenAI API:          50ms+ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

ååé‡ï¼ˆæœ¬åœ°GPUï¼‰ï¼š
  all-MiniLM-L6-v2:    1000æ¡/ç§’
  all-mpnet-base-v2:   300æ¡/ç§’
  bge-large-zh:        150æ¡/ç§’
```

**ç»“è®ºï¼š** å°æ¨¡å‹é€Ÿåº¦ä¼˜åŠ¿æ˜æ˜¾

---

### å¡ç‰‡6ï¼šæˆæœ¬è®¡ç®—å…¬å¼ ğŸ’°

```python
# OpenAIæˆæœ¬è®¡ç®—

def calculate_cost(
    num_docs: int,
    avg_chars: int = 500,
    model: str = "text-embedding-3-small"
):
    # 1 token â‰ˆ 4 å­—ç¬¦ï¼ˆè‹±æ–‡ï¼‰â‰ˆ 2 å­—ç¬¦ï¼ˆä¸­æ–‡ï¼‰
    tokens_per_doc = avg_chars / 3  # æ··åˆä¼°è®¡
    total_tokens = num_docs * tokens_per_doc
    
    prices = {
        "text-embedding-3-small": 0.02,
        "text-embedding-3-large": 0.13,
    }
    
    cost = total_tokens / 1_000_000 * prices[model]
    return f"${cost:.2f}"

# ç¤ºä¾‹
print(calculate_cost(100_000))   # $0.33
print(calculate_cost(1_000_000)) # $3.33
```

---

### å¡ç‰‡7ï¼šå¤šæ¨¡æ€Embedding ğŸ–¼ï¸

```python
# CLIPï¼šå›¾æ–‡ç»Ÿä¸€ç©ºé—´

from sentence_transformers import SentenceTransformer

# åŠ è½½CLIPæ¨¡å‹
model = SentenceTransformer('clip-ViT-B-32')

# æ–‡æœ¬embedding
text_emb = model.encode("a photo of a cat")

# å›¾ç‰‡embedding
from PIL import Image
img = Image.open("cat.jpg")
img_emb = model.encode(img)

# å¯ä»¥è·¨æ¨¡æ€æ¯”è¾ƒï¼
similarity = cosine_similarity(text_emb, img_emb)
```

**åº”ç”¨åœºæ™¯ï¼š**
- ä»¥å›¾æœå›¾
- ä»¥æ–‡æœå›¾
- å›¾æ–‡åŒ¹é…

---

### å¡ç‰‡8ï¼šæ¨¡å‹è¯„ä¼°æŒ‡æ ‡ ğŸ“ˆ

**å¸¸ç”¨è¯„ä¼°æ•°æ®é›†ï¼šMTEBï¼ˆMassive Text Embedding Benchmarkï¼‰**

```
è¯„ä¼°ä»»åŠ¡ç±»å‹ï¼š
1. è¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼åº¦ (STS)
2. æ–‡æœ¬åˆ†ç±»
3. èšç±»
4. ä¿¡æ¯æ£€ç´¢
5. é‡æ’åº
6. å¯¹è¯é…å¯¹

è¯„ä¼°æŒ‡æ ‡ï¼š
- Recall@Kï¼šTop-Kä¸­å‘½ä¸­çš„æ¯”ä¾‹
- MRRï¼šå¹³å‡å€’æ•°æ’å
- nDCGï¼šå½’ä¸€åŒ–æŠ˜æŸç´¯è®¡å¢ç›Š
```

**æ’è¡Œæ¦œï¼š** https://huggingface.co/spaces/mteb/leaderboard

---

### å¡ç‰‡9ï¼šæœ¬åœ°éƒ¨ç½²æœ€ä½³å®è·µ ğŸ 

```python
# 1. æ¨¡å‹é‡åŒ–ï¼ˆå‡å°‘æ˜¾å­˜ï¼‰
from sentence_transformers import SentenceTransformer

model = SentenceTransformer(
    'all-MiniLM-L6-v2',
    device='cuda'
)

# 2. æ‰¹é‡å¤„ç†ï¼ˆæé«˜ååï¼‰
embeddings = model.encode(
    texts,
    batch_size=64,       # æ ¹æ®æ˜¾å­˜è°ƒæ•´
    show_progress_bar=True
)

# 3. è¿æ¥æ± ï¼ˆå‡å°‘åŠ è½½å¼€é”€ï¼‰
# åœ¨åº”ç”¨å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹ï¼Œå¤šæ¬¡å¤ç”¨
```

---

### å¡ç‰‡10ï¼šæ¨¡å‹é€‰æ‹©å†³ç­–æ ‘ ğŸŒ³

```
Q1: é¢„ç®—å……è¶³å—ï¼Ÿ
â”œâ”€â”€ æ˜¯ â†’ Q2: éœ€è¦æœ€é«˜ç²¾åº¦å—ï¼Ÿ
â”‚         â”œâ”€â”€ æ˜¯ â†’ text-embedding-3-large
â”‚         â””â”€â”€ å¦ â†’ text-embedding-3-small
â”‚
â””â”€â”€ å¦ â†’ Q3: ä¸»è¦æ˜¯ä¸­æ–‡å—ï¼Ÿ
          â”œâ”€â”€ æ˜¯ â†’ bge-large-zh-v1.5
          â””â”€â”€ å¦ â†’ Q4: éœ€è¦é«˜æ€§èƒ½å—ï¼Ÿ
                    â”œâ”€â”€ æ˜¯ â†’ all-mpnet-base-v2
                    â””â”€â”€ å¦ â†’ all-MiniLM-L6-v2
```

---

## 7. ã€3ä¸ªæ ¸å¿ƒæ¦‚å¿µã€‘

### æ ¸å¿ƒæ¦‚å¿µ1ï¼šæ¨¡å‹æ¶æ„ä¸èƒ½åŠ› ğŸ—ï¸

**ä¸€å¥è¯å®šä¹‰ï¼š** æ¨¡å‹çš„æ¶æ„å†³å®šäº†å®ƒèƒ½æ•æ‰çš„è¯­ä¹‰ç²’åº¦å’Œä¸Šä¸‹æ–‡é•¿åº¦

```python
# ä¸åŒæ¶æ„çš„ç‰¹ç‚¹

architectures = {
    "Word2Vec": {
        "ç±»å‹": "è¯çº§åˆ«",
        "ç‰¹ç‚¹": "æ¯ä¸ªè¯ä¸€ä¸ªå‘é‡ï¼Œä¸è€ƒè™‘ä¸Šä¸‹æ–‡",
        "å±€é™": "'bank'åœ¨æ‰€æœ‰å¥å­ä¸­å‘é‡ç›¸åŒ"
    },
    "BERT/Transformer": {
        "ç±»å‹": "ä¸Šä¸‹æ–‡ç›¸å…³",
        "ç‰¹ç‚¹": "åŒä¸€ä¸ªè¯åœ¨ä¸åŒä¸Šä¸‹æ–‡æœ‰ä¸åŒå‘é‡",
        "ä¼˜åŠ¿": "'bank'åœ¨é“¶è¡Œè¯­å¢ƒå’Œæ²³å²¸è¯­å¢ƒå‘é‡ä¸åŒ"
    },
    "å¯¹æ¯”å­¦ä¹ æ¨¡å‹": {
        "ç±»å‹": "å¥å­çº§åˆ«",
        "ç‰¹ç‚¹": "ä¸“é—¨ä¼˜åŒ–å¥å­ç›¸ä¼¼åº¦ä»»åŠ¡",
        "ä»£è¡¨": "Sentence-BERT, BGE"
    }
}

for name, info in architectures.items():
    print(f"\n{name}:")
    for k, v in info.items():
        print(f"  {k}: {v}")
```

**ä¸Šä¸‹æ–‡é•¿åº¦çš„å½±å“ï¼š**
```python
# ä¸åŒæ¨¡å‹çš„æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦

max_lengths = {
    "all-MiniLM-L6-v2": 256,    # tokens
    "all-mpnet-base-v2": 384,
    "bge-large-zh-v1.5": 512,
    "text-embedding-3-small": 8191,
    "text-embedding-3-large": 8191,
}

# è¶…è¿‡é•¿åº¦ä¼šè¢«æˆªæ–­ï¼
# å¯¹äºé•¿æ–‡æœ¬ï¼Œéœ€è¦åˆ†å—å¤„ç†
```

---

### æ ¸å¿ƒæ¦‚å¿µ2ï¼šç»´åº¦ä¸å­˜å‚¨ ğŸ’¾

**ä¸€å¥è¯å®šä¹‰ï¼š** ç»´åº¦ç›´æ¥å½±å“å­˜å‚¨æˆæœ¬å’Œè®¡ç®—å¤æ‚åº¦

```python
import numpy as np

def storage_analysis(num_vectors, dim, precision="float32"):
    """åˆ†æå­˜å‚¨éœ€æ±‚"""
    
    bytes_per_value = {"float32": 4, "float16": 2, "int8": 1}
    
    # åŸå§‹å‘é‡å­˜å‚¨
    raw_size = num_vectors * dim * bytes_per_value[precision]
    
    # HNSWç´¢å¼•é¢å¤–å¼€é”€ï¼ˆçº¦1.5-2å€ï¼‰
    index_size = raw_size * 1.7
    
    return {
        "å‘é‡æ•°": f"{num_vectors:,}",
        "ç»´åº¦": dim,
        "ç²¾åº¦": precision,
        "å‘é‡å­˜å‚¨": f"{raw_size / 1e9:.2f} GB",
        "é¢„ä¼°ç´¢å¼•": f"{index_size / 1e9:.2f} GB"
    }

# å¯¹æ¯”ä¸åŒç»´åº¦çš„å­˜å‚¨éœ€æ±‚
configs = [
    (1_000_000, 384, "float32"),   # MiniLM
    (1_000_000, 768, "float32"),   # MPNET
    (1_000_000, 1536, "float32"),  # OpenAI
    (1_000_000, 3072, "float32"),  # OpenAI-large
]

print("å­˜å‚¨éœ€æ±‚å¯¹æ¯”ï¼ˆ100ä¸‡å‘é‡ï¼‰ï¼š")
for n, d, p in configs:
    result = storage_analysis(n, d, p)
    print(f"  {d}ç»´: å‘é‡{result['å‘é‡å­˜å‚¨']}, ç´¢å¼•{result['é¢„ä¼°ç´¢å¼•']}")
```

---

### æ ¸å¿ƒæ¦‚å¿µ3ï¼šè¿ç§»æˆæœ¬ä¸é”å®š ğŸ”’

**ä¸€å¥è¯å®šä¹‰ï¼š** é€‰æ‹©Embeddingæ¨¡å‹æ˜¯ä¸€ä¸ªæœ‰é•¿æœŸå½±å“çš„æ¶æ„å†³ç­–

```python
def migration_analysis():
    """æ¨¡å‹è¿ç§»æˆæœ¬åˆ†æ"""
    
    costs = {
        "é‡æ–°ç”ŸæˆEmbedding": {
            "æ—¶é—´": "å‡ å°æ—¶åˆ°å‡ å¤©",
            "è´¹ç”¨": "APIè°ƒç”¨è´¹ç”¨ or è®¡ç®—èµ„æº",
            "é£é™©": "ä½"
        },
        "æ›´æ–°å‘é‡æ•°æ®åº“": {
            "æ—¶é—´": "ç´¢å¼•æ„å»ºæ—¶é—´",
            "è´¹ç”¨": "è®¡ç®—èµ„æº",
            "é£é™©": "ä¸­ï¼ˆå¯èƒ½éœ€è¦åœæœºï¼‰"
        },
        "æ•ˆæœéªŒè¯": {
            "æ—¶é—´": "1-2å‘¨æµ‹è¯•",
            "è´¹ç”¨": "äººåŠ›æˆæœ¬",
            "é£é™©": "å¯èƒ½å‘ç°æ•ˆæœä¸‹é™"
        },
        "ä¸‹æ¸¸é€‚é…": {
            "æ—¶é—´": "å–å†³äºç³»ç»Ÿå¤æ‚åº¦",
            "è´¹ç”¨": "å¼€å‘æˆæœ¬",
            "é£é™©": "å¯èƒ½æœ‰å…¼å®¹æ€§é—®é¢˜"
        }
    }
    
    return costs

costs = migration_analysis()
print("æ¨¡å‹è¿ç§»æˆæœ¬æ¸…å•ï¼š")
for item, details in costs.items():
    print(f"\n{item}:")
    for k, v in details.items():
        print(f"  {k}: {v}")

# å»ºè®®ï¼š
# 1. åˆæœŸé€‰å‹è¦æ…é‡
# 2. è®¾è®¡æ—¶è€ƒè™‘æ¨¡å‹å¯æ›¿æ¢æ€§
# 3. ä¿ç•™æµ‹è¯•é›†ç”¨äºè¯„ä¼°æ–°æ¨¡å‹
```

---

## 8. ã€1ä¸ªç±»æ¯”ã€‘ç”¨å‰ç«¯å¼€å‘ç†è§£Embeddingæ¨¡å‹

### ç±»æ¯”1ï¼šEmbeddingæ¨¡å‹ = UIç»„ä»¶åº“ ğŸ“¦

**å‰ç«¯ä¸–ç•Œï¼š**
```javascript
// é€‰æ‹©UIç»„ä»¶åº“
const choices = {
  "Ant Design": "åŠŸèƒ½å…¨é¢ï¼Œä¼ä¸šçº§",
  "Material UI": "Googleé£æ ¼ï¼Œç¾è§‚",
  "Tailwind CSS": "çµæ´»ï¼Œè‡ªå®šä¹‰å¼º",
  "Bootstrap": "ç®€å•ï¼Œå¿«é€Ÿä¸Šæ‰‹"
};

// ä¸€æ—¦é€‰æ‹©ï¼Œåˆ‡æ¢æˆæœ¬å¾ˆé«˜ï¼ˆæ‰€æœ‰é¡µé¢éƒ½è¦æ”¹ï¼‰
```

**Embeddingä¸–ç•Œï¼š**
```python
# é€‰æ‹©Embeddingæ¨¡å‹
choices = {
    "text-embedding-3-large": "åŠŸèƒ½å…¨é¢ï¼Œæ•ˆæœæœ€ä½³",
    "all-mpnet-base-v2": "å¼€æºï¼Œå¹³è¡¡",
    "all-MiniLM-L6-v2": "è½»é‡ï¼Œå¿«é€Ÿä¸Šæ‰‹",
    "bge-large-zh": "ä¸­æ–‡ç‰¹åŒ–"
}

# ä¸€æ—¦é€‰æ‹©ï¼Œåˆ‡æ¢æˆæœ¬å¾ˆé«˜ï¼ˆæ‰€æœ‰å‘é‡éƒ½è¦é‡æ–°ç”Ÿæˆï¼‰
```

---

### ç±»æ¯”2ï¼šæ¨¡å‹ç»´åº¦ = å“åº”å¼æ–­ç‚¹ ğŸ“±

```css
/* å‰ç«¯ï¼šæ–­ç‚¹è¶Šå¤šï¼Œé€‚é…è¶Šç²¾ç»†ï¼Œä½†å¤æ‚åº¦è¶Šé«˜ */
@media (max-width: 576px) { /* xs */ }
@media (max-width: 768px) { /* sm */ }
@media (max-width: 992px) { /* md */ }
@media (max-width: 1200px) { /* lg */ }
@media (max-width: 1400px) { /* xl */ }
```

```python
# Embeddingï¼šç»´åº¦è¶Šé«˜ï¼Œè¡¨ç¤ºè¶Šç²¾ç»†ï¼Œä½†æˆæœ¬è¶Šé«˜
dimensions = {
    384: "åŸºç¡€è¡¨ç¤ºï¼Œå¿«é€Ÿ",
    768: "ä¸­ç­‰è¡¨ç¤ºï¼Œå¹³è¡¡",
    1024: "ç»†è‡´è¡¨ç¤ºï¼Œé€‚åˆä¸“ä¸šåœºæ™¯",
    1536: "ä¸°å¯Œè¡¨ç¤ºï¼Œé€šç”¨",
    3072: "ç²¾ç»†è¡¨ç¤ºï¼Œé«˜ç²¾åº¦"
}
```

**ç±»æ¯”ç‚¹ï¼š**
- æ–­ç‚¹/ç»´åº¦è¶Šå¤š â†’ é€‚é…/è¡¨ç¤ºè¶Šç²¾ç»†
- ä½†å¢åŠ å¤æ‚åº¦å’Œæˆæœ¬
- éœ€è¦æ ¹æ®éœ€æ±‚æƒè¡¡

---

### ç±»æ¯”3ï¼šAPI vs æœ¬åœ° = SaaS vs è‡ªå»º â˜ï¸

```javascript
// å‰ç«¯é€‰æ‹©ï¼šSaaSæœåŠ¡ vs è‡ªå»º

// SaaS (å¦‚Firebase)
const saas = {
  ä¼˜ç‚¹: ["å¿«é€Ÿæ¥å…¥", "æ— éœ€è¿ç»´", "å¼¹æ€§æ‰©å±•"],
  ç¼ºç‚¹: ["æŒç»­è´¹ç”¨", "æ•°æ®åœ¨å¤–", "å®šåˆ¶å—é™"]
};

// è‡ªå»º (å¦‚è‡ªå·±æ­å»ºåç«¯)
const selfHosted = {
  ä¼˜ç‚¹: ["å®Œå…¨æ§åˆ¶", "ä¸€æ¬¡æ€§æˆæœ¬", "å¯å®šåˆ¶"],
  ç¼ºç‚¹: ["éœ€è¦è¿ç»´", "åˆå§‹æŠ•å…¥å¤§", "æ‰©å±•å¤æ‚"]
};
```

```python
# Embeddingé€‰æ‹©ï¼šAPI vs æœ¬åœ°éƒ¨ç½²

# API (OpenAI)
api = {
    "ä¼˜ç‚¹": ["å¿«é€Ÿæ¥å…¥", "æ•ˆæœå¥½", "æŒç»­æ›´æ–°"],
    "ç¼ºç‚¹": ["æŒ‰é‡ä»˜è´¹", "æ•°æ®å‡ºå¢ƒ", "å»¶è¿Ÿè¾ƒé«˜"]
}

# æœ¬åœ°éƒ¨ç½² (Sentence-Transformers)
local = {
    "ä¼˜ç‚¹": ["ä¸€æ¬¡éƒ¨ç½²", "æ•°æ®å®‰å…¨", "ä½å»¶è¿Ÿ"],
    "ç¼ºç‚¹": ["éœ€è¦GPU", "è‡ªå·±ç»´æŠ¤", "æ¨¡å‹å›ºå®š"]
}
```

---

### ç±»æ¯”4ï¼šæ¨¡å‹è¯„ä¼° = æ€§èƒ½æµ‹è¯• ğŸ“Š

```javascript
// å‰ç«¯æ€§èƒ½æµ‹è¯•
const frontendMetrics = {
  "LCP": "æœ€å¤§å†…å®¹ç»˜åˆ¶æ—¶é—´",  // ç±»ä¼¼äºï¼šé¦–æ¬¡å“åº”å»¶è¿Ÿ
  "FID": "é¦–æ¬¡è¾“å…¥å»¶è¿Ÿ",     // ç±»ä¼¼äºï¼šæŸ¥è¯¢å»¶è¿Ÿ
  "CLS": "ç´¯è®¡å¸ƒå±€åç§»",     // ç±»ä¼¼äºï¼šç»“æœç¨³å®šæ€§
  "TTFB": "é¦–å­—èŠ‚æ—¶é—´"       // ç±»ä¼¼äºï¼šAPIå“åº”æ—¶é—´
};

// Lighthouseè¯„åˆ†ï¼šç»¼åˆæ‰“åˆ†
```

```python
# Embeddingæ¨¡å‹è¯„ä¼°ï¼ˆMTEBï¼‰
embedding_metrics = {
    "Recall@K": "æ£€ç´¢å¬å›ç‡",
    "MRR": "å¹³å‡å€’æ•°æ’å",
    "nDCG": "å½’ä¸€åŒ–ç´¯è®¡å¢ç›Š",
    "Latency": "æ¨ç†å»¶è¿Ÿ"
}

# MTEBæ’è¡Œæ¦œï¼šç»¼åˆæ‰“åˆ†
```

**ç±»æ¯”ç‚¹ï¼š**
- éƒ½æœ‰æ ‡å‡†åŒ–çš„è¯„ä¼°åŸºå‡†
- éƒ½éœ€è¦åœ¨çœŸå®åœºæ™¯éªŒè¯
- ç»¼åˆæŒ‡æ ‡æ¯”å•ä¸€æŒ‡æ ‡æ›´æœ‰å‚è€ƒä»·å€¼

---

### ç±»æ¯”5ï¼šç‰ˆæœ¬é”å®š = package.json ğŸ“‹

```json
// å‰ç«¯ï¼šé”å®šä¾èµ–ç‰ˆæœ¬
{
  "dependencies": {
    "react": "^18.2.0",
    "axios": "^1.4.0"
  }
}
// å‡çº§æœ‰é£é™©ï¼Œéœ€è¦æµ‹è¯•
```

```python
# Embeddingï¼šé”å®šæ¨¡å‹ç‰ˆæœ¬
EMBEDDING_CONFIG = {
    "model": "text-embedding-3-small",
    "dimension": 1536,
    "created_at": "2024-01-15"
}
# æ›´æ¢æ¨¡å‹éœ€è¦é‡æ–°ç´¢å¼•ï¼Œæˆæœ¬å¾ˆé«˜
```

**ç±»æ¯”ç‚¹ï¼š**
- éƒ½éœ€è¦ç‰ˆæœ¬ç®¡ç†
- å‡çº§éƒ½æœ‰é£é™©
- éœ€è¦æµ‹è¯•å’Œå›é€€æœºåˆ¶

---

### ç±»æ¯”æ€»ç»“ ğŸ¯

| Embeddingæ¦‚å¿µ | å‰ç«¯ç±»æ¯” | å…³é”®å¯¹åº” |
|--------------|---------|---------|
| æ¨¡å‹é€‰æ‹© | UIåº“é€‰æ‹© | é•¿æœŸå†³ç­– |
| ç»´åº¦å¤§å° | å“åº”å¼æ–­ç‚¹ | ç²¾ç»†åº¦æƒè¡¡ |
| API vs æœ¬åœ° | SaaS vs è‡ªå»º | æˆæœ¬æ¨¡å¼ |
| æ¨¡å‹è¯„ä¼° | æ€§èƒ½æµ‹è¯• | æ ‡å‡†åŒ–æŒ‡æ ‡ |
| ç‰ˆæœ¬é”å®š | package.json | å˜æ›´ç®¡ç† |

---

## 9. ã€ç¬¬ä¸€æ€§åŸç†ã€‘Embeddingæ¨¡å‹çš„æœ¬è´¨

### ä»€ä¹ˆæ˜¯ç¬¬ä¸€æ€§åŸç†ï¼Ÿ

**ç¬¬ä¸€æ€§åŸç†**ï¼šå›åˆ°äº‹ç‰©æœ€åŸºæœ¬çš„çœŸç†ï¼Œä»æºå¤´æ€è€ƒé—®é¢˜

### Embeddingæ¨¡å‹çš„ç¬¬ä¸€æ€§åŸç† ğŸ¯

#### 1. æœ€åŸºç¡€çš„é—®é¢˜

**é—®é¢˜ï¼šå¦‚ä½•æŠŠæ–‡æœ¬å˜æˆè®¡ç®—æœºå¯ä»¥ç†è§£å’Œæ¯”è¾ƒçš„æ•°å­—ï¼Ÿ**

```
è¾“å…¥ï¼šä¸€æ®µæ–‡æœ¬ï¼ˆäººç±»è¯­è¨€ï¼‰
è¾“å‡ºï¼šä¸€ä¸ªå‘é‡ï¼ˆæ•°å­—è¡¨ç¤ºï¼‰

æ ¸å¿ƒé—®é¢˜ï¼š
1. å¦‚ä½•ä¿ç•™è¯­ä¹‰ä¿¡æ¯ï¼Ÿ
2. å¦‚ä½•è®©ç›¸ä¼¼æ–‡æœ¬çš„å‘é‡ç›¸è¿‘ï¼Ÿ
3. å¦‚ä½•å¹³è¡¡æ•ˆæœå’Œæ•ˆç‡ï¼Ÿ
```

#### 2. ä»ç¬¬ä¸€æ€§åŸç†æ¨å¯¼æ¨¡å‹æ¼”è¿›

```
ç¬¬ä¸€ä»£ï¼šè¯è¢‹æ¨¡å‹ï¼ˆBag of Wordsï¼‰
  åŸç†ï¼šç»Ÿè®¡æ¯ä¸ªè¯å‡ºç°çš„æ¬¡æ•°
  é—®é¢˜ï¼šä¸¢å¤±è¯­åºï¼Œç»´åº¦çˆ†ç‚¸
  
  â†“ å¦‚ä½•ä¿ç•™è¯­åºï¼Ÿ

ç¬¬äºŒä»£ï¼šWord2Vec
  åŸç†ï¼šé¢„æµ‹ä¸Šä¸‹æ–‡è¯
  è¿›æ­¥ï¼šæ•æ‰è¯ä¹‹é—´çš„å…³ç³»
  é—®é¢˜ï¼šæ¯ä¸ªè¯åªæœ‰ä¸€ä¸ªå‘é‡ï¼ˆå¿½ç•¥å¤šä¹‰ï¼‰
  
  â†“ å¦‚ä½•å¤„ç†ä¸€è¯å¤šä¹‰ï¼Ÿ

ç¬¬ä¸‰ä»£ï¼šBERT/Transformer
  åŸç†ï¼šåŒå‘ä¸Šä¸‹æ–‡ç¼–ç 
  è¿›æ­¥ï¼šåŒä¸€è¯åœ¨ä¸åŒä¸Šä¸‹æ–‡æœ‰ä¸åŒè¡¨ç¤º
  é—®é¢˜ï¼šå¥å­è¡¨ç¤ºè´¨é‡ä¸€èˆ¬
  
  â†“ å¦‚ä½•ä¼˜åŒ–å¥å­è¡¨ç¤ºï¼Ÿ

ç¬¬å››ä»£ï¼šå¯¹æ¯”å­¦ä¹ æ¨¡å‹ï¼ˆSentence-BERT, BGEï¼‰
  åŸç†ï¼šå¯¹æ¯”å­¦ä¹ ï¼Œæ‹‰è¿‘ç›¸ä¼¼æ ·æœ¬
  è¿›æ­¥ï¼šä¸“é—¨ä¼˜åŒ–å¥å­ç›¸ä¼¼åº¦
  ç°çŠ¶ï¼šå½“å‰ä¸»æµæ–¹æ¡ˆ
```

#### 3. æ¨¡å‹çš„æ ¸å¿ƒæƒè¡¡

**ä»ç¬¬ä¸€æ€§åŸç†çœ‹ï¼Œæ¯ä¸ªæ¨¡å‹éƒ½åœ¨åšä»¥ä¸‹æƒè¡¡ï¼š**

```python
tradeoffs = {
    "è¡¨ç¤ºèƒ½åŠ› vs è®¡ç®—æ•ˆç‡": {
        "å¤§æ¨¡å‹": "é«˜è¡¨ç¤ºèƒ½åŠ›ï¼Œé«˜è®¡ç®—æˆæœ¬",
        "å°æ¨¡å‹": "ä½è¡¨ç¤ºèƒ½åŠ›ï¼Œä½è®¡ç®—æˆæœ¬",
        "è§£å†³": "çŸ¥è¯†è’¸é¦ã€é‡åŒ–å‹ç¼©"
    },
    "é€šç”¨æ€§ vs ä¸“ä¸šæ€§": {
        "é€šç”¨æ¨¡å‹": "ä»€ä¹ˆéƒ½èƒ½åšï¼Œä½†ä¸ä¸“ç²¾",
        "é¢†åŸŸæ¨¡å‹": "ç‰¹å®šé¢†åŸŸå¼ºï¼Œä½†æ³›åŒ–å·®",
        "è§£å†³": "åœ¨é¢†åŸŸæ•°æ®ä¸Šå¾®è°ƒ"
    },
    "è´¨é‡ vs æˆæœ¬": {
        "é«˜è´¨é‡": "éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®å’Œè®¡ç®—",
        "ä½æˆæœ¬": "å¯èƒ½ç‰ºç‰²æ•ˆæœ",
        "è§£å†³": "è¿ç§»å­¦ä¹ ã€é¢„è®­ç»ƒ+å¾®è°ƒ"
    }
}
```

#### 4. ä¸ºä»€ä¹ˆä¸åŒæ¨¡å‹æ•ˆæœä¸åŒï¼Ÿ

**ç¬¬ä¸€æ€§åŸç†åˆ†æï¼š**

```
å†³å®šæ¨¡å‹æ•ˆæœçš„å› ç´ ï¼š

1. è®­ç»ƒæ•°æ®
   â”œâ”€â”€ æ•°æ®é‡ï¼šæ›´å¤šæ•°æ® â†’ æ›´å¥½æ³›åŒ–
   â”œâ”€â”€ æ•°æ®è´¨é‡ï¼šé«˜è´¨é‡å¯¹ â†’ æ›´å‡†ç¡®çš„ç›¸ä¼¼æ€§
   â””â”€â”€ æ•°æ®åˆ†å¸ƒï¼šè¦†ç›–ç›®æ ‡åœºæ™¯ â†’ é¢†åŸŸæ•ˆæœå¥½

2. æ¨¡å‹æ¶æ„
   â”œâ”€â”€ å‚æ•°é‡ï¼šæ›´å¤šå‚æ•° â†’ æ›´å¼ºè¡¨ç¤ºèƒ½åŠ›
   â”œâ”€â”€ æ³¨æ„åŠ›æœºåˆ¶ï¼šTransformer â†’ æ•æ‰é•¿è·ç¦»ä¾èµ–
   â””â”€â”€ æ± åŒ–ç­–ç•¥ï¼šCLS / Mean â†’ å½±å“å¥å­è¡¨ç¤º

3. è®­ç»ƒç›®æ ‡
   â”œâ”€â”€ MLMï¼šé¢„æµ‹æ©ç è¯ â†’ ç†è§£è¯­è¨€
   â”œâ”€â”€ å¯¹æ¯”å­¦ä¹ ï¼šåŒºåˆ†æ­£è´Ÿæ ·æœ¬ â†’ ä¼˜åŒ–ç›¸ä¼¼åº¦
   â””â”€â”€ å¤šä»»åŠ¡å­¦ä¹ ï¼šå¤šç§ä»»åŠ¡ â†’ æ³›åŒ–èƒ½åŠ›

4. æ¨ç†ä¼˜åŒ–
   â”œâ”€â”€ é‡åŒ–ï¼šé™ä½ç²¾åº¦ â†’ å‡å°‘èµ„æº
   â”œâ”€â”€ è’¸é¦ï¼šå¤§æ¨¡å‹â†’å°æ¨¡å‹ â†’ ä¿æŒæ•ˆæœ
   â””â”€â”€ å‰ªæï¼šå»é™¤å†—ä½™ â†’ åŠ é€Ÿæ¨ç†
```

#### 5. å¦‚ä½•é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹ï¼Ÿ

**ç¬¬ä¸€æ€§åŸç†å†³ç­–æ¡†æ¶ï¼š**

```python
def choose_model(requirements):
    """
    ä»ç¬¬ä¸€æ€§åŸç†å‡ºå‘çš„æ¨¡å‹é€‰æ‹©
    """
    
    # 1. æ˜ç¡®æ ¸å¿ƒéœ€æ±‚
    core_need = requirements.get("core_need")
    
    if core_need == "æœ€é«˜ç²¾åº¦":
        # é€‰æ‹©æœ€å¼ºæ¨¡å‹ï¼Œä¸è®¡æˆæœ¬
        return "text-embedding-3-large"
    
    if core_need == "æœ€ä½æˆæœ¬":
        # é€‰æ‹©å…è´¹å¼€æº
        return "all-MiniLM-L6-v2"
    
    # 2. åˆ†æçº¦æŸæ¡ä»¶
    constraints = requirements.get("constraints", {})
    
    if constraints.get("chinese_heavy"):
        return "bge-large-zh-v1.5"
    
    if constraints.get("low_latency"):
        return "all-MiniLM-L6-v2"
    
    if constraints.get("no_api"):
        return "all-mpnet-base-v2"
    
    # 3. é»˜è®¤ï¼šæ€§ä»·æ¯”æœ€ä¼˜
    return "text-embedding-3-small"
```

#### 6. æ¨¡å‹çš„æœ¬è´¨æ˜¯ä»€ä¹ˆï¼Ÿ

**ä¸€å¥è¯æ€»ç»“ï¼š**

> Embeddingæ¨¡å‹çš„æœ¬è´¨æ˜¯ä¸€ä¸ª**å‡½æ•°**ï¼Œå®ƒå­¦ä¹ äº†å¦‚ä½•å°†äººç±»è¯­è¨€æ˜ å°„åˆ°ä¸€ä¸ª**ä¿ç•™è¯­ä¹‰å…³ç³»**çš„å‘é‡ç©ºé—´ã€‚
>
> ä¸åŒæ¨¡å‹çš„å·®å¼‚åœ¨äºï¼š
> - **è¾“å…¥å¤„ç†**ï¼šåˆ†è¯æ–¹å¼ã€ä¸Šä¸‹æ–‡é•¿åº¦
> - **æ˜ å°„æ–¹å¼**ï¼šç½‘ç»œæ¶æ„ã€å‚æ•°æ•°é‡
> - **è®­ç»ƒæ–¹å¼**ï¼šæ•°æ®ã€ç›®æ ‡å‡½æ•°ã€ä¼˜åŒ–ç­–ç•¥

```
f(text) â†’ vector

ä½¿å¾—ï¼š
- similar(text1, text2) âŸº close(f(text1), f(text2))
- ä¸åŒæ¨¡å‹ = ä¸åŒçš„f
- æ²¡æœ‰"æœ€å¥½çš„f"ï¼Œåªæœ‰"æœ€é€‚åˆçš„f"
```

---

## 10. ã€ä¸€å¥è¯æ€»ç»“ã€‘

**Embeddingæ¨¡å‹æ˜¯å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡çš„å·¥å…·ï¼Œä¸åŒæ¨¡å‹åœ¨ç»´åº¦ã€æ•ˆæœã€æˆæœ¬ä¸Šå„æœ‰ç‰¹ç‚¹ã€‚é€‰æ‹©æ¨¡å‹éœ€è¦æ ¹æ®å®é™…åœºæ™¯æƒè¡¡ï¼šOpenAIé€‚åˆè¿½æ±‚æ•ˆæœï¼Œå¼€æºæ¨¡å‹é€‚åˆæ§åˆ¶æˆæœ¬ï¼Œä¸­æ–‡åœºæ™¯æ¨èBGEç³»åˆ—ã€‚åˆ‡æ¢æ¨¡å‹æˆæœ¬é«˜ï¼ŒåˆæœŸé€‰å‹è¦æ…é‡ã€‚**

---

## é™„å½•ï¼šå¿«é€Ÿå‚è€ƒå¡ ğŸ“‹

### æ¨¡å‹é€ŸæŸ¥è¡¨

| æ¨¡å‹ | ç»´åº¦ | è¯­è¨€ | æˆæœ¬ | æ¨èåœºæ™¯ |
|------|------|------|------|---------|
| text-embedding-3-small | 1536 | å¤šè¯­è¨€ | $0.02/1M | é€šç”¨é¦–é€‰ |
| text-embedding-3-large | 3072 | å¤šè¯­è¨€ | $0.13/1M | é«˜ç²¾åº¦ |
| all-MiniLM-L6-v2 | 384 | è‹±æ–‡ | å…è´¹ | åŸå‹å¼€å‘ |
| all-mpnet-base-v2 | 768 | è‹±æ–‡ | å…è´¹ | å¹³è¡¡é€‰æ‹© |
| bge-large-zh-v1.5 | 1024 | ä¸­æ–‡ | å…è´¹ | ä¸­æ–‡åœºæ™¯ |
| bge-m3 | 1024 | å¤šè¯­è¨€ | å…è´¹ | å¤šè¯­è¨€ |

### ä»£ç æ¨¡æ¿

```python
# OpenAI
from openai import OpenAI
client = OpenAI()
emb = client.embeddings.create(input=text, model="text-embedding-3-small")

# Sentence-Transformers
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')
emb = model.encode(text)

# BGEä¸­æ–‡
model = SentenceTransformer('BAAI/bge-large-zh-v1.5')
emb = model.encode(text, normalize_embeddings=True)
```

### å­¦ä¹ æ£€æŸ¥æ¸…å• âœ…

- [ ] äº†è§£ä¸»æµEmbeddingæ¨¡å‹çš„ç‰¹ç‚¹
- [ ] èƒ½æ ¹æ®åœºæ™¯é€‰æ‹©åˆé€‚çš„æ¨¡å‹
- [ ] ä¼šä½¿ç”¨OpenAI APIç”Ÿæˆembedding
- [ ] ä¼šä½¿ç”¨Sentence-Transformers
- [ ] ç†è§£æ¨¡å‹åˆ‡æ¢çš„æˆæœ¬
- [ ] çŸ¥é“ä¸­æ–‡åœºæ™¯çš„æ¨¡å‹é€‰æ‹©

### ä¸‹ä¸€æ­¥å­¦ä¹  ğŸš€

æŒæ¡äº†å¸¸è§æ¨¡å‹åï¼Œå»ºè®®å­¦ä¹ ï¼š

1. **ç»´åº¦ä¸è´¨é‡å…³ç³»**ï¼šæ·±å…¥ç†è§£ç»´åº¦çš„å½±å“
2. **å‘é‡æ•°æ®åº“é€‰å‹**ï¼šPineconeã€Milvusã€Qdrant
3. **RAGç³»ç»Ÿæ„å»º**ï¼šå°†embeddingåº”ç”¨åˆ°å®é™…ç³»ç»Ÿ

---

## å‚è€ƒèµ„æº ğŸ“š

1. **MTEBæ’è¡Œæ¦œ**ï¼šhttps://huggingface.co/spaces/mteb/leaderboard
2. **Sentence-Transformers**ï¼šhttps://www.sbert.net/
3. **BGEæ¨¡å‹**ï¼šhttps://github.com/FlagOpen/FlagEmbedding
4. **OpenAI Embedding**ï¼šhttps://platform.openai.com/docs/guides/embeddings

---

**ç»“è¯­ï¼š** æ¨¡å‹é€‰æ‹©æ˜¯æŠ€æœ¯å†³ç­–ï¼Œæ²¡æœ‰"æœ€å¥½"åªæœ‰"æœ€é€‚åˆ"ã€‚åœ¨è‡ªå·±çš„æ•°æ®ä¸Šæµ‹è¯•ï¼Œæ˜¯å”¯ä¸€å¯é çš„è¯„ä¼°æ–¹å¼ï¼ğŸ¯
