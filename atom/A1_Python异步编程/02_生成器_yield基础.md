# ç”Ÿæˆå™¨ - yield åŸºç¡€

## 1. ã€30å­—æ ¸å¿ƒã€‘

**ç”Ÿæˆå™¨æ˜¯ä¸€ç§ç‰¹æ®Šå‡½æ•°ï¼Œç”¨ yield é€ä¸ªäº§å‡ºå€¼è€Œéä¸€æ¬¡è¿”å›ï¼Œå®ç°æƒ°æ€§è®¡ç®—å’Œå†…å­˜é«˜æ•ˆçš„æ•°æ®æµå¤„ç†ã€‚**

---

## 2. ã€ç¬¬ä¸€æ€§åŸç†ã€‘

### ä»€ä¹ˆæ˜¯ç¬¬ä¸€æ€§åŸç†ï¼Ÿ

**ç¬¬ä¸€æ€§åŸç†**ï¼šå›åˆ°äº‹ç‰©æœ€åŸºæœ¬çš„çœŸç†ï¼Œä»æºå¤´æ€è€ƒé—®é¢˜

### ç”Ÿæˆå™¨çš„ç¬¬ä¸€æ€§åŸç† ğŸ¯

#### 1. æœ€åŸºç¡€çš„å®šä¹‰

**ç”Ÿæˆå™¨ = å¯ä»¥æš‚åœå’Œæ¢å¤çš„å‡½æ•°**

ä»…æ­¤è€Œå·²ï¼æ²¡æœ‰æ›´åŸºç¡€çš„äº†ã€‚

æ™®é€šå‡½æ•°ï¼šä»å¤´æ‰§è¡Œåˆ°å°¾ï¼Œä¸€æ¬¡æ€§è¿”å›ç»“æœ
ç”Ÿæˆå™¨å‡½æ•°ï¼šæ‰§è¡Œåˆ° `yield` æš‚åœï¼Œä¸‹æ¬¡ä»æš‚åœå¤„ç»§ç»­

#### 2. ä¸ºä»€ä¹ˆéœ€è¦ç”Ÿæˆå™¨ï¼Ÿ

**æ ¸å¿ƒé—®é¢˜ï¼šå½“æ•°æ®é‡å¾ˆå¤§æ—¶ï¼Œä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜ä¼šçˆ†ç‚¸ã€‚**

æƒ³è±¡ä¸€ä¸ªåœºæ™¯ï¼š
- ä½ è¦å¤„ç† 1äº¿æ¡å‘é‡æ•°æ®
- æ¯æ¡æ•°æ®å ç”¨ 1KB
- å…¨éƒ¨åŠ è½½éœ€è¦ 100GB å†…å­˜
- é—®é¢˜ï¼šä½ çš„ç”µè„‘åªæœ‰ 16GB å†…å­˜

```python
# æ²¡æœ‰ç”Ÿæˆå™¨çš„å›°å¢ƒ
def get_all_vectors():
    result = []
    for i in range(100_000_000):
        result.append(compute_vector(i))  # å†…å­˜çˆ†ç‚¸ï¼
    return result

# æœ‰äº†ç”Ÿæˆå™¨
def get_all_vectors():
    for i in range(100_000_000):
        yield compute_vector(i)  # ä¸€æ¬¡åªåœ¨å†…å­˜ä¸­ä¿ç•™ä¸€ä¸ªï¼
```

#### 3. ç”Ÿæˆå™¨çš„ä¸‰å±‚ä»·å€¼

##### ä»·å€¼1ï¼šå†…å­˜æ•ˆç‡
åªåœ¨éœ€è¦æ—¶è®¡ç®—ï¼Œä¸æå‰å ç”¨å†…å­˜ã€‚

```python
# åˆ—è¡¨ï¼šç«‹å³è®¡ç®—ï¼Œå ç”¨å†…å­˜
squares_list = [x**2 for x in range(10_000_000)]  # ~80MB

# ç”Ÿæˆå™¨ï¼šæƒ°æ€§è®¡ç®—ï¼Œå‡ ä¹ä¸å å†…å­˜
squares_gen = (x**2 for x in range(10_000_000))   # ~120 bytes
```

##### ä»·å€¼2ï¼šå¤„ç†æ— é™æµ
å¯ä»¥è¡¨ç¤ºæ— é™åºåˆ—ï¼Œå› ä¸ºå€¼æ˜¯æŒ‰éœ€äº§ç”Ÿçš„ã€‚

```python
def infinite_ids():
    id = 0
    while True:
        yield id
        id += 1

id_gen = infinite_ids()
print(next(id_gen))  # 0
print(next(id_gen))  # 1
# å¯ä»¥æ— é™è°ƒç”¨ä¸‹å»...
```

##### ä»·å€¼3ï¼šæµæ°´çº¿å¤„ç†
å¤šä¸ªç”Ÿæˆå™¨å¯ä»¥ä¸²è”ï¼Œå½¢æˆé«˜æ•ˆçš„æ•°æ®å¤„ç†æµæ°´çº¿ã€‚

```python
def read_vectors(file):
    for line in open(file):
        yield parse_vector(line)

def normalize(vectors):
    for v in vectors:
        yield v / np.linalg.norm(v)

def filter_valid(vectors):
    for v in vectors:
        if not np.isnan(v).any():
            yield v

# æµæ°´çº¿ï¼šå†…å­˜ä¸­åŒæ—¶åªæœ‰ä¸€ä¸ªå‘é‡
pipeline = filter_valid(normalize(read_vectors('huge.txt')))
```

#### 4. ä»ç¬¬ä¸€æ€§åŸç†æ¨å¯¼å‘é‡æ•°æ®åº“åº”ç”¨

**æ¨ç†é“¾ï¼š**
```
1. å‘é‡æ•°æ®åº“å­˜å‚¨æµ·é‡å‘é‡ï¼ˆå¯èƒ½æ•°åäº¿ï¼‰
   â†“
2. ä¸å¯èƒ½ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰å‘é‡åˆ°å†…å­˜
   â†“
3. éœ€è¦ä¸€ç§"æŒ‰éœ€å–ç”¨"çš„æœºåˆ¶
   â†“
4. ç”Ÿæˆå™¨æä¾›"æƒ°æ€§æ±‚å€¼"èƒ½åŠ›
   â†“
5. åº”ç”¨ï¼šæ‰¹é‡å¯¼å…¥ã€æµå¼æŸ¥è¯¢ã€æ•°æ®é¢„å¤„ç†
```

```python
def batch_vectors(vectors, batch_size=1000):
    """å°†å‘é‡æµåˆ†æ‰¹ï¼Œç”¨äºæ‰¹é‡æ’å…¥æ•°æ®åº“"""
    batch = []
    for vector in vectors:
        batch.append(vector)
        if len(batch) >= batch_size:
            yield batch
            batch = []
    if batch:
        yield batch

# ä½¿ç”¨ï¼šå†…å­˜å‹å¥½çš„æ‰¹é‡æ’å…¥
for batch in batch_vectors(huge_vector_stream, batch_size=1000):
    db.insert_batch(batch)
```

#### 5. ä¸€å¥è¯æ€»ç»“ç¬¬ä¸€æ€§åŸç†

**ç”Ÿæˆå™¨æ˜¯"æŒ‰éœ€ç”Ÿäº§"çš„å‡½æ•°ï¼Œç”¨æš‚åœ/æ¢å¤æœºåˆ¶å®ç°æƒ°æ€§è®¡ç®—ï¼Œæ˜¯å¤„ç†å¤§æ•°æ®æµçš„å†…å­˜å‹å¥½æ–¹æ¡ˆã€‚**

---

## 3. ã€3ä¸ªæ ¸å¿ƒæ¦‚å¿µã€‘

### æ ¸å¿ƒæ¦‚å¿µ1ï¼šyield å…³é”®å­— ğŸ¯

**yield æ˜¯ç”Ÿæˆå™¨çš„å¿ƒè„ï¼Œå®ƒè®©å‡½æ•°å¯ä»¥"æš‚åœ"å¹¶äº§å‡ºä¸€ä¸ªå€¼ã€‚**

```python
def simple_generator():
    print("å¼€å§‹")
    yield 1        # æš‚åœï¼Œäº§å‡º 1
    print("ç»§ç»­")
    yield 2        # æš‚åœï¼Œäº§å‡º 2
    print("ç»“æŸ")
    yield 3        # æš‚åœï¼Œäº§å‡º 3

gen = simple_generator()
print(next(gen))  # è¾“å‡º"å¼€å§‹"ï¼Œè¿”å› 1
print(next(gen))  # è¾“å‡º"ç»§ç»­"ï¼Œè¿”å› 2
print(next(gen))  # è¾“å‡º"ç»“æŸ"ï¼Œè¿”å› 3
```

**yield vs returnï¼š**

| ç‰¹æ€§ | yield | return |
|-----|-------|--------|
| å‡½æ•°çŠ¶æ€ | æš‚åœï¼Œä¿ç•™çŠ¶æ€ | ç»ˆæ­¢ï¼Œæ¸…é™¤çŠ¶æ€ |
| å¯æ‰§è¡Œæ¬¡æ•° | å¤šæ¬¡ | ä¸€æ¬¡ |
| è¿”å›å€¼ç±»å‹ | ç”Ÿæˆå™¨å¯¹è±¡ | å…·ä½“å€¼ |
| å†…å­˜ä½¿ç”¨ | æƒ°æ€§ï¼ŒæŒ‰éœ€ | ç«‹å³ï¼Œå…¨éƒ¨ |

**åœ¨å‘é‡æ•°æ®åº“ä¸­çš„åº”ç”¨ï¼š**
é€æ¡è¯»å–å’Œå¤„ç†å‘é‡ï¼Œé¿å…å†…å­˜æº¢å‡ºã€‚

---

### æ ¸å¿ƒæ¦‚å¿µ2ï¼šç”Ÿæˆå™¨å¯¹è±¡ ğŸ“¦

**è°ƒç”¨ç”Ÿæˆå™¨å‡½æ•°ä¸ä¼šæ‰§è¡Œå‡½æ•°ä½“ï¼Œè€Œæ˜¯è¿”å›ä¸€ä¸ªç”Ÿæˆå™¨å¯¹è±¡ã€‚**

```python
def my_gen():
    print("æ‰§è¡Œäº†ï¼")
    yield 1

# è°ƒç”¨å‡½æ•°ï¼Œä¸ä¼šæ‰“å°ä»»ä½•ä¸œè¥¿ï¼
gen = my_gen()
print(type(gen))  # <class 'generator'>

# è°ƒç”¨ next() æ‰å¼€å§‹æ‰§è¡Œ
value = next(gen)  # ç°åœ¨æ‰“å°"æ‰§è¡Œäº†ï¼"
print(value)       # 1
```

**ç”Ÿæˆå™¨å¯¹è±¡çš„å…³é”®æ–¹æ³•ï¼š**

```python
gen = (x for x in range(3))

# __next__() / next() - è·å–ä¸‹ä¸€ä¸ªå€¼
print(next(gen))  # 0

# __iter__() - è¿”å›è‡ªèº«ï¼Œæ‰€ä»¥å¯ä»¥ç”¨ for å¾ªç¯
for x in gen:
    print(x)  # 1, 2
```

**ç”Ÿæˆå™¨çš„çŠ¶æ€ï¼š**
```python
import inspect

def gen_func():
    yield 1
    yield 2

gen = gen_func()
print(inspect.getgeneratorstate(gen))  # GEN_CREATED
next(gen)
print(inspect.getgeneratorstate(gen))  # GEN_SUSPENDED
next(gen)
print(inspect.getgeneratorstate(gen))  # GEN_SUSPENDED
try:
    next(gen)
except StopIteration:
    print(inspect.getgeneratorstate(gen))  # GEN_CLOSED
```

---

### æ ¸å¿ƒæ¦‚å¿µ3ï¼šStopIteration å¼‚å¸¸ ğŸ›‘

**å½“ç”Ÿæˆå™¨è€—å°½æ—¶ï¼Œä¼šæŠ›å‡º StopIteration å¼‚å¸¸ã€‚**

```python
def short_gen():
    yield 1
    yield 2

gen = short_gen()
print(next(gen))  # 1
print(next(gen))  # 2
print(next(gen))  # StopIteration å¼‚å¸¸ï¼
```

**for å¾ªç¯è‡ªåŠ¨å¤„ç†ï¼š**
```python
# for å¾ªç¯ä¼šè‡ªåŠ¨æ•è· StopIteration
for x in short_gen():
    print(x)  # 1, 2 - ä¸ä¼šæŠ¥é”™
```

**æ‰‹åŠ¨å¤„ç†ï¼š**
```python
gen = short_gen()
while True:
    try:
        value = next(gen)
        print(value)
    except StopIteration:
        print("ç”Ÿæˆå™¨è€—å°½")
        break
```

**return å€¼å­˜å‚¨åœ¨å¼‚å¸¸ä¸­ï¼š**
```python
def gen_with_return():
    yield 1
    yield 2
    return "å®Œæˆ"

gen = gen_with_return()
next(gen)  # 1
next(gen)  # 2
try:
    next(gen)
except StopIteration as e:
    print(e.value)  # "å®Œæˆ"
```

---

## 4. ã€æœ€å°å¯ç”¨ã€‘

æŒæ¡ä»¥ä¸‹å†…å®¹ï¼Œå°±èƒ½åœ¨80%çš„åœºæ™¯ä¸­ä½¿ç”¨ç”Ÿæˆå™¨ï¼š

### 4.1 å®šä¹‰ç”Ÿæˆå™¨å‡½æ•°

```python
def count_up(n):
    """ä» 0 æ•°åˆ° n-1"""
    for i in range(n):
        yield i

# ä½¿ç”¨
for num in count_up(5):
    print(num)  # 0 1 2 3 4
```

### 4.2 ç”Ÿæˆå™¨è¡¨è¾¾å¼ï¼ˆä¸€è¡Œæå®šï¼‰

```python
# åˆ—è¡¨æ¨å¯¼å¼ -> ç«‹å³è®¡ç®—
squares_list = [x**2 for x in range(10)]

# ç”Ÿæˆå™¨è¡¨è¾¾å¼ -> æƒ°æ€§è®¡ç®—ï¼ˆæŠŠ [] æ¢æˆ ()ï¼‰
squares_gen = (x**2 for x in range(10))

# éå†
for s in squares_gen:
    print(s)
```

### 4.3 ç”¨ next() æ‰‹åŠ¨è·å–å€¼

```python
gen = (x for x in range(3))

print(next(gen))  # 0
print(next(gen))  # 1
print(next(gen))  # 2
# print(next(gen))  # StopIteration!

# å®‰å…¨è·å–ï¼šæä¾›é»˜è®¤å€¼
gen2 = (x for x in range(2))
print(next(gen2, 'æ²¡äº†'))  # 0
print(next(gen2, 'æ²¡äº†'))  # 1
print(next(gen2, 'æ²¡äº†'))  # 'æ²¡äº†'ï¼ˆä¸ä¼šæŠ¥é”™ï¼‰
```

### 4.4 è¯»å–å¤§æ–‡ä»¶

```python
def read_large_file(filepath):
    """é€è¡Œè¯»å–å¤§æ–‡ä»¶"""
    with open(filepath, 'r') as f:
        for line in f:
            yield line.strip()

# å¤„ç† 10GB æ—¥å¿—æ–‡ä»¶ä¹Ÿä¸ä¼šçˆ†å†…å­˜
for line in read_large_file('huge.log'):
    if 'ERROR' in line:
        print(line)
```

### 4.5 æ‰¹é‡å¤„ç†ï¼ˆå‘é‡æ•°æ®åº“å¸¸ç”¨ï¼‰

```python
def batch_iter(iterable, batch_size):
    """å°†ä»»æ„å¯è¿­ä»£å¯¹è±¡åˆ†æ‰¹"""
    batch = []
    for item in iterable:
        batch.append(item)
        if len(batch) >= batch_size:
            yield batch
            batch = []
    if batch:
        yield batch

# æ‰¹é‡æ’å…¥å‘é‡
vectors = (generate_vector(i) for i in range(10000))
for batch in batch_iter(vectors, batch_size=100):
    db.insert_many(batch)  # æ¯æ¬¡æ’å…¥100æ¡
```

**è¿™äº›çŸ¥è¯†è¶³ä»¥ï¼š**
- å¤„ç†å¤§æ–‡ä»¶å’Œå¤§æ•°æ®æµ
- å®ç°å†…å­˜å‹å¥½çš„æ•°æ®å¤„ç†
- ä¸ºå‘é‡æ•°æ®åº“æ‰¹é‡æ“ä½œæ‰“ä¸‹åŸºç¡€
- ç†è§£å¼‚æ­¥ç¼–ç¨‹çš„åŸºç¡€ï¼ˆasync/await åŸºäºç”Ÿæˆå™¨ï¼‰

---

## 5. ã€1ä¸ªç±»æ¯”ã€‘

### ç±»æ¯”1ï¼šç”Ÿæˆå™¨ = JavaScript Generator ğŸ¨

Python ç”Ÿæˆå™¨å’Œ JavaScript Generator å‡ ä¹ä¸€æ¨¡ä¸€æ ·ï¼

```javascript
// JavaScript Generator
function* countUp(n) {
    for (let i = 0; i < n; i++) {
        yield i;
    }
}

const gen = countUp(3);
console.log(gen.next().value);  // 0
console.log(gen.next().value);  // 1
console.log(gen.next().value);  // 2
console.log(gen.next().done);   // true
```

```python
# Python Generator
def count_up(n):
    for i in range(n):
        yield i

gen = count_up(3)
print(next(gen))  # 0
print(next(gen))  # 1
print(next(gen))  # 2
# next(gen) -> StopIteration
```

**ä¸»è¦åŒºåˆ«ï¼š**
- JS ç”¨ `function*` æ ‡è®°ï¼ŒPython æœ‰ `yield` å°±æ˜¯ç”Ÿæˆå™¨
- JS çš„ `next()` è¿”å› `{value, done}` å¯¹è±¡
- Python ç›´æ¥è¿”å›å€¼ï¼Œè€—å°½æŠ› `StopIteration`

---

### ç±»æ¯”2ï¼šç”Ÿæˆå™¨ = æ‡’åŠ è½½å›¾ç‰‡ ğŸ–¼ï¸

å‰ç«¯ç»å¸¸ç”¨æ‡’åŠ è½½ä¼˜åŒ–æ€§èƒ½ï¼Œç”Ÿæˆå™¨å°±æ˜¯æ•°æ®çš„"æ‡’åŠ è½½"ï¼

```javascript
// å‰ç«¯ï¼šå›¾ç‰‡æ‡’åŠ è½½
// ä¸æ˜¯ä¸€æ¬¡åŠ è½½æ‰€æœ‰å›¾ç‰‡ï¼Œè€Œæ˜¯æ»šåŠ¨åˆ°å¯è§†åŒºåŸŸæ‰åŠ è½½
<img loading="lazy" src="image.jpg">
```

```python
# Pythonï¼šæ•°æ®æ‡’åŠ è½½
# ä¸æ˜¯ä¸€æ¬¡è®¡ç®—æ‰€æœ‰æ•°æ®ï¼Œè€Œæ˜¯éœ€è¦æ—¶æ‰è®¡ç®—
def lazy_vectors():
    for i in range(1000000):
        yield expensive_computation(i)  # ç”¨åˆ°æ‰ç®—

# å¯èƒ½åªç”¨å‰ 10 ä¸ª
gen = lazy_vectors()
first_10 = [next(gen) for _ in range(10)]
# åªè®¡ç®—äº† 10 æ¬¡ï¼Œä¸æ˜¯ 100 ä¸‡æ¬¡ï¼
```

---

### ç±»æ¯”3ï¼šç”Ÿæˆå™¨ = æµå¼ API å“åº” ğŸ“¡

å‰ç«¯è°ƒç”¨æµå¼ APIï¼ˆå¦‚ ChatGPTï¼‰æ—¶ï¼Œæ•°æ®æ˜¯ä¸€ç‚¹ä¸€ç‚¹åˆ°è¾¾çš„ã€‚

```javascript
// å‰ç«¯ï¼šæµå¼æ¥æ”¶ API å“åº”
const response = await fetch('/api/stream');
const reader = response.body.getReader();

while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    console.log(new TextDecoder().decode(value));
}
```

```python
# Pythonï¼šæµå¼äº§å‡ºæ•°æ®
def stream_response(query):
    """æ¨¡æ‹Ÿæµå¼ LLM å“åº”"""
    for token in llm.generate_stream(query):
        yield token  # ä¸€ä¸ªè¯ä¸€ä¸ªè¯äº§å‡º

# ä½¿ç”¨
for token in stream_response("ä»€ä¹ˆæ˜¯å‘é‡æ•°æ®åº“ï¼Ÿ"):
    print(token, end='', flush=True)
```

---

### ç±»æ¯”4ï¼šç”Ÿæˆå™¨ = React çš„ Suspense/Lazy ğŸ”„

```javascript
// React: æ‡’åŠ è½½ç»„ä»¶
const HeavyComponent = React.lazy(() => import('./HeavyComponent'));

// éœ€è¦æ—¶æ‰åŠ è½½
<Suspense fallback={<Loading />}>
    <HeavyComponent />
</Suspense>
```

```python
# Python: æ‡’è®¡ç®—æ•°æ®
def lazy_embeddings(texts):
    """éœ€è¦æ—¶æ‰è®¡ç®— embedding"""
    for text in texts:
        yield model.encode(text)  # ç”¨åˆ°æ‰ç®—

# å¯èƒ½ä¸éœ€è¦å…¨éƒ¨
embeddings = lazy_embeddings(million_texts)
first_100 = list(itertools.islice(embeddings, 100))
```

---

### ç±»æ¯”5ï¼šç”Ÿæˆå™¨ = åˆ†é¡µ API ğŸ“„

```javascript
// å‰ç«¯ï¼šåˆ†é¡µè·å–æ•°æ®
async function* fetchPages(url) {
    let page = 1;
    while (true) {
        const response = await fetch(`${url}?page=${page}`);
        const data = await response.json();
        if (data.length === 0) break;
        yield data;
        page++;
    }
}

// ä½¿ç”¨
for await (const page of fetchPages('/api/users')) {
    renderUsers(page);
}
```

```python
# Pythonï¼šåˆ†é¡µæŸ¥è¯¢å‘é‡æ•°æ®åº“
def query_pages(collection, query_vector, page_size=100):
    """åˆ†é¡µè·å–ç›¸ä¼¼å‘é‡"""
    offset = 0
    while True:
        results = collection.search(
            query_vector,
            limit=page_size,
            offset=offset
        )
        if not results:
            break
        yield results
        offset += page_size

# ä½¿ç”¨
for page in query_pages(my_collection, query_vec):
    process_results(page)
```

---

### ç±»æ¯”æ€»ç»“è¡¨

| Python ç”Ÿæˆå™¨æ¦‚å¿µ | å‰ç«¯å¯¹åº”æ¦‚å¿µ |
|-----------------|-------------|
| yield | JavaScript yield |
| ç”Ÿæˆå™¨å‡½æ•° | function* |
| æƒ°æ€§è®¡ç®— | æ‡’åŠ è½½ (lazy loading) |
| next() | iterator.next() |
| StopIteration | { done: true } |
| ç”Ÿæˆå™¨è¡¨è¾¾å¼ | æ— ç›´æ¥å¯¹åº”ï¼ˆç±»ä¼¼æ‡’æ•°ç»„ï¼‰ |
| æµå¼å¤„ç† | ReadableStream |

---

## 6. ã€åç›´è§‰ç‚¹ã€‘

### è¯¯åŒº1ï¼šè°ƒç”¨ç”Ÿæˆå™¨å‡½æ•°ä¼šæ‰§è¡Œå‡½æ•°ä½“ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- è°ƒç”¨ç”Ÿæˆå™¨å‡½æ•°åªæ˜¯åˆ›å»ºç”Ÿæˆå™¨å¯¹è±¡
- å‡½æ•°ä½“çš„ä»£ç ä¸€è¡Œéƒ½ä¸ä¼šæ‰§è¡Œ
- åªæœ‰è°ƒç”¨ `next()` æˆ–éå†æ—¶æ‰æ‰§è¡Œ

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
å› ä¸ºæ™®é€šå‡½æ•°è°ƒç”¨å°±ä¼šæ‰§è¡Œï¼Œæˆ‘ä»¬ä¹ æƒ¯æ€§åœ°è®¤ä¸ºæ‰€æœ‰å‡½æ•°éƒ½è¿™æ ·ã€‚

**æ­£ç¡®ç†è§£ï¼š**
```python
def my_gen():
    print("A")
    yield 1
    print("B")
    yield 2

# è°ƒç”¨å‡½æ•° - ä»€ä¹ˆéƒ½ä¸æ‰“å°ï¼
gen = my_gen()
print("åˆ›å»ºäº†ç”Ÿæˆå™¨")

# è°ƒç”¨ next() æ‰å¼€å§‹æ‰§è¡Œ
print(next(gen))  # æ‰“å°"A"ï¼Œè¿”å› 1
print(next(gen))  # æ‰“å°"B"ï¼Œè¿”å› 2

# è¾“å‡ºï¼š
# åˆ›å»ºäº†ç”Ÿæˆå™¨
# A
# 1
# B
# 2
```

---

### è¯¯åŒº2ï¼šç”Ÿæˆå™¨å¯ä»¥é‡å¤ä½¿ç”¨ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- ç”Ÿæˆå™¨æ˜¯ä¸€æ¬¡æ€§çš„ï¼Œè€—å°½åä¸èƒ½é‡ç½®
- æƒ³å†æ¬¡éå†ï¼Œå¿…é¡»é‡æ–°åˆ›å»ºç”Ÿæˆå™¨

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
å› ä¸ºåˆ—è¡¨å¯ä»¥åå¤éå†ï¼Œä»¥ä¸ºç”Ÿæˆå™¨ä¹Ÿä¸€æ ·ã€‚

**æ­£ç¡®ç†è§£ï¼š**
```python
def gen():
    yield 1
    yield 2

g = gen()

# ç¬¬ä¸€æ¬¡éå†
print(list(g))  # [1, 2]

# ç¬¬äºŒæ¬¡éå†
print(list(g))  # [] ç©ºï¼ç”Ÿæˆå™¨å·²è€—å°½

# æ­£ç¡®åšæ³•ï¼šé‡æ–°åˆ›å»º
g = gen()
print(list(g))  # [1, 2]

# æˆ–è€…ï¼šä¿å­˜ä¸ºåˆ—è¡¨ï¼ˆå¦‚æœå†…å­˜å…è®¸ï¼‰
data = list(gen())
print(data)  # [1, 2]
print(data)  # [1, 2] - å¯ä»¥é‡å¤ä½¿ç”¨
```

---

### è¯¯åŒº3ï¼šç”Ÿæˆå™¨æ¯”åˆ—è¡¨æ…¢ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- ç”Ÿæˆå™¨åœ¨å¤§å¤šæ•°åœºæ™¯ä¸‹æ›´å¿«
- é¿å…äº†å†…å­˜åˆ†é…å’Œåƒåœ¾å›æ”¶çš„å¼€é”€
- åªæœ‰åœ¨éœ€è¦éšæœºè®¿é—®æ—¶ï¼Œåˆ—è¡¨æ‰æ›´åˆé€‚

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
å› ä¸º"æ¯æ¬¡è°ƒç”¨ next() éƒ½è¦æ¢å¤çŠ¶æ€"å¬èµ·æ¥åƒæ˜¯é¢å¤–å¼€é”€ã€‚

**æ­£ç¡®ç†è§£ï¼š**
```python
import time

# æµ‹è¯•ï¼šè®¡ç®—å‰ 100 ä¸ªæ»¡è¶³æ¡ä»¶çš„æ•°
def find_first_n(n, condition):
    """æ–¹å¼1ï¼šåˆ—è¡¨æ¨å¯¼å¼"""
    all_results = [x for x in range(10_000_000) if condition(x)]
    return all_results[:n]

def find_first_n_gen(n, condition):
    """æ–¹å¼2ï¼šç”Ÿæˆå™¨"""
    count = 0
    for x in range(10_000_000):
        if condition(x):
            yield x
            count += 1
            if count >= n:
                break

condition = lambda x: x % 1000 == 0

# åˆ—è¡¨æ–¹å¼ï¼šéœ€è¦éå†å®Œæ‰€æœ‰ 1000 ä¸‡ä¸ªæ•°
start = time.time()
result1 = find_first_n(100, condition)
print(f"åˆ—è¡¨æ–¹å¼: {time.time() - start:.3f}s")

# ç”Ÿæˆå™¨æ–¹å¼ï¼šæ‰¾åˆ° 100 ä¸ªå°±åœæ­¢
start = time.time()
result2 = list(find_first_n_gen(100, condition))
print(f"ç”Ÿæˆå™¨æ–¹å¼: {time.time() - start:.6f}s")

# è¾“å‡ºç¤ºä¾‹ï¼š
# åˆ—è¡¨æ–¹å¼: 0.850s
# ç”Ÿæˆå™¨æ–¹å¼: 0.000100sï¼ˆå¿« 8500 å€ï¼ï¼‰
```

---

## 7. ã€å®æˆ˜ä»£ç ã€‘

```python
"""
ç”Ÿæˆå™¨å®æˆ˜ç¤ºä¾‹ï¼šå‘é‡æ•°æ®å¤„ç†æµæ°´çº¿
å±•ç¤ºç”Ÿæˆå™¨åœ¨å‘é‡æ•°æ®åº“åœºæ™¯ä¸­çš„åº”ç”¨
"""

import time
import random

# ===== 1. åŸºç¡€ï¼šåˆ›å»ºç”Ÿæˆå™¨ =====
print("=== 1. åŸºç¡€ï¼šåˆ›å»ºç”Ÿæˆå™¨ ===")

def count_vectors(n):
    """ç”Ÿæˆ n ä¸ªæ¨¡æ‹Ÿå‘é‡"""
    for i in range(n):
        yield [random.random() for _ in range(4)]  # 4ç»´å‘é‡

# åªåˆ›å»ºç”Ÿæˆå™¨ï¼Œä¸æ‰§è¡Œ
gen = count_vectors(1000000)
print(f"ç”Ÿæˆå™¨ç±»å‹: {type(gen)}")
print(f"è·å–å‰3ä¸ª: {[next(gen) for _ in range(3)]}")

# ===== 2. ç”Ÿæˆå™¨è¡¨è¾¾å¼ =====
print("\n=== 2. ç”Ÿæˆå™¨è¡¨è¾¾å¼ ===")

import sys

# å†…å­˜å¯¹æ¯”
list_comp = [x**2 for x in range(1000000)]
gen_expr = (x**2 for x in range(1000000))

print(f"åˆ—è¡¨å†…å­˜: {sys.getsizeof(list_comp):,} bytes")
print(f"ç”Ÿæˆå™¨å†…å­˜: {sys.getsizeof(gen_expr)} bytes")

# ===== 3. è¯»å–å¤§æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿï¼‰=====
print("\n=== 3. æ¨¡æ‹Ÿè¯»å–å¤§é‡å‘é‡æ•°æ® ===")

def read_vectors_from_source(source, limit=None):
    """ä»æ•°æ®æºé€æ¡è¯»å–å‘é‡"""
    count = 0
    while limit is None or count < limit:
        # æ¨¡æ‹Ÿä»æ–‡ä»¶/æ•°æ®åº“è¯»å–
        vector = {
            'id': count,
            'embedding': [random.random() for _ in range(128)],
            'metadata': {'source': source}
        }
        yield vector
        count += 1
        if limit and count >= limit:
            break

# åªè¯»å–éœ€è¦çš„æ•°é‡
reader = read_vectors_from_source('documents', limit=5)
for vec in reader:
    print(f"ID: {vec['id']}, embedding ç»´åº¦: {len(vec['embedding'])}")

# ===== 4. æµæ°´çº¿å¤„ç† =====
print("\n=== 4. å‘é‡å¤„ç†æµæ°´çº¿ ===")

def normalize_vectors(vectors):
    """å½’ä¸€åŒ–å‘é‡"""
    for vec in vectors:
        embedding = vec['embedding']
        norm = sum(x**2 for x in embedding) ** 0.5
        vec['embedding'] = [x/norm for x in embedding]
        yield vec

def filter_by_norm(vectors, min_norm=0.5):
    """è¿‡æ»¤èŒƒæ•°è¿‡å°çš„å‘é‡"""
    for vec in vectors:
        embedding = vec['embedding']
        norm = sum(x**2 for x in embedding) ** 0.5
        if norm >= min_norm:
            yield vec

def add_timestamp(vectors):
    """æ·»åŠ æ—¶é—´æˆ³"""
    for vec in vectors:
        vec['timestamp'] = time.time()
        yield vec

# ç»„åˆæµæ°´çº¿ï¼šè¯»å– -> å½’ä¸€åŒ– -> è¿‡æ»¤ -> æ·»åŠ æ—¶é—´æˆ³
pipeline = add_timestamp(
    filter_by_norm(
        normalize_vectors(
            read_vectors_from_source('docs', limit=10)
        )
    )
)

print("æµæ°´çº¿å¤„ç†ç»“æœ:")
for i, vec in enumerate(pipeline):
    if i < 3:  # åªæ‰“å°å‰3ä¸ª
        print(f"  ID: {vec['id']}, æœ‰æ—¶é—´æˆ³: {'timestamp' in vec}")

# ===== 5. æ‰¹é‡å¤„ç† =====
print("\n=== 5. æ‰¹é‡å¤„ç†ï¼ˆå‘é‡æ•°æ®åº“æ’å…¥ï¼‰===")

def batch_generator(iterable, batch_size):
    """å°†æ•°æ®æµåˆ†æ‰¹"""
    batch = []
    for item in iterable:
        batch.append(item)
        if len(batch) >= batch_size:
            yield batch
            batch = []
    if batch:
        yield batch

def mock_db_insert(batch):
    """æ¨¡æ‹Ÿæ•°æ®åº“æ‰¹é‡æ’å…¥"""
    time.sleep(0.01)  # æ¨¡æ‹Ÿ IO å»¶è¿Ÿ
    return len(batch)

# æ‰¹é‡æ’å…¥ 100 æ¡æ•°æ®ï¼Œæ¯æ‰¹ 20 æ¡
vectors = read_vectors_from_source('images', limit=100)
total_inserted = 0

for batch_num, batch in enumerate(batch_generator(vectors, batch_size=20)):
    inserted = mock_db_insert(batch)
    total_inserted += inserted
    print(f"  æ‰¹æ¬¡ {batch_num + 1}: æ’å…¥ {inserted} æ¡")

print(f"æ€»å…±æ’å…¥: {total_inserted} æ¡")

# ===== 6. æ— é™ç”Ÿæˆå™¨ =====
print("\n=== 6. æ— é™IDç”Ÿæˆå™¨ ===")

def infinite_id_generator(prefix='vec'):
    """ç”Ÿæˆæ— é™å”¯ä¸€ID"""
    counter = 0
    while True:
        yield f"{prefix}_{counter:08d}"
        counter += 1

id_gen = infinite_id_generator()
print("ç”Ÿæˆçš„ID:", [next(id_gen) for _ in range(5)])

# ===== 7. ç”Ÿæˆå™¨ç»„åˆï¼šyield from =====
print("\n=== 7. ä½¿ç”¨ yield from ç»„åˆç”Ÿæˆå™¨ ===")

def read_from_multiple_sources(sources):
    """ä»å¤šä¸ªæ•°æ®æºè¯»å–"""
    for source in sources:
        yield from read_vectors_from_source(source, limit=2)

sources = ['docs', 'images', 'audio']
combined = read_from_multiple_sources(sources)

print("å¤šæºæ•°æ®:")
for vec in combined:
    print(f"  æ¥æº: {vec['metadata']['source']}, ID: {vec['id']}")

# ===== 8. å¸¦çŠ¶æ€çš„ç”Ÿæˆå™¨ =====
print("\n=== 8. å¸¦ç»Ÿè®¡çš„ç”Ÿæˆå™¨ ===")

def counting_generator(iterable):
    """åŒ…è£…ç”Ÿæˆå™¨ï¼Œç»Ÿè®¡å¤„ç†æ•°é‡"""
    count = 0
    for item in iterable:
        count += 1
        yield item
    print(f"[ç»Ÿè®¡] å…±å¤„ç† {count} ä¸ªå…ƒç´ ")

data = counting_generator(range(10))
result = sum(data)  # è§¦å‘éå†
print(f"æ±‚å’Œç»“æœ: {result}")

# ===== 9. å‘é‡ç›¸ä¼¼åº¦æœç´¢ç»“æœæµ =====
print("\n=== 9. æ¨¡æ‹Ÿæµå¼æœç´¢ç»“æœ ===")

def similarity_search_stream(query_vector, threshold=0.5, max_results=100):
    """æµå¼è¿”å›ç›¸ä¼¼åº¦æœç´¢ç»“æœ"""
    for i in range(max_results):
        # æ¨¡æ‹Ÿè®¡ç®—ç›¸ä¼¼åº¦
        similarity = random.random()
        if similarity >= threshold:
            yield {
                'id': f'doc_{i}',
                'similarity': round(similarity, 3),
                'content': f'Document {i} content...'
            }

query = [0.1, 0.2, 0.3, 0.4]
results = similarity_search_stream(query, threshold=0.7, max_results=20)

print("æœç´¢ç»“æœï¼ˆç›¸ä¼¼åº¦ >= 0.7ï¼‰:")
for r in results:
    print(f"  {r['id']}: ç›¸ä¼¼åº¦ {r['similarity']}")

# ===== 10. æ€§èƒ½å¯¹æ¯” =====
print("\n=== 10. æ€§èƒ½å¯¹æ¯” ===")

def measure_time(func, *args):
    start = time.time()
    result = func(*args)
    return time.time() - start, result

# åˆ—è¡¨æ–¹å¼
def list_approach(n):
    data = [x**2 for x in range(n)]
    return sum(x for x in data if x % 2 == 0)

# ç”Ÿæˆå™¨æ–¹å¼
def gen_approach(n):
    data = (x**2 for x in range(n))
    return sum(x for x in data if x % 2 == 0)

n = 1000000
time_list, result_list = measure_time(list_approach, n)
time_gen, result_gen = measure_time(gen_approach, n)

print(f"åˆ—è¡¨æ–¹å¼: {time_list:.3f}s")
print(f"ç”Ÿæˆå™¨æ–¹å¼: {time_gen:.3f}s")
print(f"ç»“æœä¸€è‡´: {result_list == result_gen}")
```

**è¿è¡Œè¾“å‡ºç¤ºä¾‹ï¼š**
```
=== 1. åŸºç¡€ï¼šåˆ›å»ºç”Ÿæˆå™¨ ===
ç”Ÿæˆå™¨ç±»å‹: <class 'generator'>
è·å–å‰3ä¸ª: [[0.23, 0.45, 0.67, 0.89], ...]

=== 2. ç”Ÿæˆå™¨è¡¨è¾¾å¼ ===
åˆ—è¡¨å†…å­˜: 8,448,728 bytes
ç”Ÿæˆå™¨å†…å­˜: 112 bytes

=== 3. æ¨¡æ‹Ÿè¯»å–å¤§é‡å‘é‡æ•°æ® ===
ID: 0, embedding ç»´åº¦: 128
ID: 1, embedding ç»´åº¦: 128
...

=== 4. å‘é‡å¤„ç†æµæ°´çº¿ ===
æµæ°´çº¿å¤„ç†ç»“æœ:
  ID: 0, æœ‰æ—¶é—´æˆ³: True
  ID: 1, æœ‰æ—¶é—´æˆ³: True
  ID: 2, æœ‰æ—¶é—´æˆ³: True

=== 5. æ‰¹é‡å¤„ç†ï¼ˆå‘é‡æ•°æ®åº“æ’å…¥ï¼‰===
  æ‰¹æ¬¡ 1: æ’å…¥ 20 æ¡
  æ‰¹æ¬¡ 2: æ’å…¥ 20 æ¡
  æ‰¹æ¬¡ 3: æ’å…¥ 20 æ¡
  æ‰¹æ¬¡ 4: æ’å…¥ 20 æ¡
  æ‰¹æ¬¡ 5: æ’å…¥ 20 æ¡
æ€»å…±æ’å…¥: 100 æ¡

=== 6. æ— é™IDç”Ÿæˆå™¨ ===
ç”Ÿæˆçš„ID: ['vec_00000000', 'vec_00000001', ...]

=== 7. ä½¿ç”¨ yield from ç»„åˆç”Ÿæˆå™¨ ===
å¤šæºæ•°æ®:
  æ¥æº: docs, ID: 0
  æ¥æº: docs, ID: 1
  æ¥æº: images, ID: 0
  æ¥æº: images, ID: 1
  æ¥æº: audio, ID: 0
  æ¥æº: audio, ID: 1

=== 8. å¸¦ç»Ÿè®¡çš„ç”Ÿæˆå™¨ ===
[ç»Ÿè®¡] å…±å¤„ç† 10 ä¸ªå…ƒç´ 
æ±‚å’Œç»“æœ: 45

=== 9. æ¨¡æ‹Ÿæµå¼æœç´¢ç»“æœ ===
æœç´¢ç»“æœï¼ˆç›¸ä¼¼åº¦ >= 0.7ï¼‰:
  doc_3: ç›¸ä¼¼åº¦ 0.823
  doc_7: ç›¸ä¼¼åº¦ 0.756
  ...

=== 10. æ€§èƒ½å¯¹æ¯” ===
åˆ—è¡¨æ–¹å¼: 0.156s
ç”Ÿæˆå™¨æ–¹å¼: 0.089s
ç»“æœä¸€è‡´: True
```

---

## 8. ã€é¢è¯•å¿…é—®ã€‘

### é—®é¢˜1ï¼š"ä»€ä¹ˆæ˜¯ç”Ÿæˆå™¨ï¼Ÿå’Œæ™®é€šå‡½æ•°æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"

**æ™®é€šå›ç­”ï¼ˆâŒ ä¸å‡ºå½©ï¼‰ï¼š**
"ç”Ÿæˆå™¨æ˜¯ç”¨ yield çš„å‡½æ•°ï¼Œå¯ä»¥äº§å‡ºå¤šä¸ªå€¼ã€‚"

**å‡ºå½©å›ç­”ï¼ˆâœ… æ¨èï¼‰ï¼š**

> **ç”Ÿæˆå™¨æœ‰ä¸‰ä¸ªå…³é”®åŒºåˆ«ï¼š**
>
> 1. **æ‰§è¡Œæ–¹å¼ä¸åŒ**ï¼šæ™®é€šå‡½æ•°è°ƒç”¨ç«‹å³æ‰§è¡Œå®Œæ¯•ï¼›ç”Ÿæˆå™¨å‡½æ•°è°ƒç”¨åªåˆ›å»ºç”Ÿæˆå™¨å¯¹è±¡ï¼Œéœ€è¦ `next()` æ‰å¼€å§‹æ‰§è¡Œï¼Œé‡åˆ° `yield` æš‚åœã€‚
>
> 2. **è¿”å›å€¼ä¸åŒ**ï¼šæ™®é€šå‡½æ•° `return` ä¸€ä¸ªå€¼å°±ç»“æŸï¼›ç”Ÿæˆå™¨å¯ä»¥ `yield` å¤šæ¬¡ï¼Œæ¯æ¬¡æš‚åœå¹¶äº§å‡ºä¸€ä¸ªå€¼ã€‚
>
> 3. **å†…å­˜ä½¿ç”¨ä¸åŒ**ï¼šæ™®é€šå‡½æ•°éœ€è¦ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰ç»“æœï¼›ç”Ÿæˆå™¨æ˜¯æƒ°æ€§è®¡ç®—ï¼ŒæŒ‰éœ€äº§å‡ºï¼Œå†…å­˜å ç”¨æ’å®šã€‚
>
> **å®é™…åº”ç”¨åœºæ™¯ï¼š**
> åœ¨å‘é‡æ•°æ®åº“å¼€å‘ä¸­ï¼Œå¤„ç†ç™¾ä¸‡çº§å‘é‡æ—¶ï¼Œæˆ‘ä¼šç”¨ç”Ÿæˆå™¨é€æ‰¹è¯»å–å’Œå¤„ç†ï¼š
>
> ```python
> def batch_vectors(file, batch_size=1000):
>     batch = []
>     for line in open(file):
>         batch.append(parse(line))
>         if len(batch) >= batch_size:
>             yield batch
>             batch = []
>     if batch:
>         yield batch
> ```
>
> è¿™æ ·å³ä½¿å¤„ç† 10GB çš„å‘é‡æ–‡ä»¶ï¼Œå†…å­˜ä¹Ÿåªå ç”¨ä¸€ä¸ªæ‰¹æ¬¡çš„å¤§å°ã€‚

**ä¸ºä»€ä¹ˆè¿™ä¸ªå›ç­”å‡ºå½©ï¼Ÿ**
1. âœ… æ¸…æ™°çš„ä¸‰ç‚¹å¯¹æ¯”ï¼Œç»“æ„åŒ–æ€ç»´
2. âœ… æåˆ°"æƒ°æ€§è®¡ç®—"è¿™ä¸ªæ ¸å¿ƒæ¦‚å¿µ
3. âœ… ç»“åˆå®é™…åœºæ™¯ï¼ˆå‘é‡æ•°æ®åº“æ‰¹å¤„ç†ï¼‰
4. âœ… ä»£ç ç¤ºä¾‹ç®€æ´å®ç”¨

---

### é—®é¢˜2ï¼š"ç”Ÿæˆå™¨è¡¨è¾¾å¼å’Œåˆ—è¡¨æ¨å¯¼å¼æ€ä¹ˆé€‰ï¼Ÿ"

**æ™®é€šå›ç­”ï¼ˆâŒ ä¸å‡ºå½©ï¼‰ï¼š**
"æ•°æ®é‡å¤§ç”¨ç”Ÿæˆå™¨ï¼Œå°ç”¨åˆ—è¡¨ã€‚"

**å‡ºå½©å›ç­”ï¼ˆâœ… æ¨èï¼‰ï¼š**

> **é€‰æ‹©ä¾æ®æœ‰ä¸‰ä¸ªç»´åº¦ï¼š**
>
> | ç»´åº¦ | åˆ—è¡¨æ¨å¯¼å¼ | ç”Ÿæˆå™¨è¡¨è¾¾å¼ |
> |-----|-----------|-------------|
> | å†…å­˜ | O(n) | O(1) |
> | éå†æ¬¡æ•° | å¯å¤šæ¬¡ | åªèƒ½ä¸€æ¬¡ |
> | éšæœºè®¿é—® | æ”¯æŒ | ä¸æ”¯æŒ |
>
> **å…·ä½“é€‰æ‹©ç­–ç•¥ï¼š**
>
> 1. **éœ€è¦å¤šæ¬¡éå†æˆ–éšæœºè®¿é—®** â†’ åˆ—è¡¨
>    ```python
>    data = [x**2 for x in range(100)]
>    print(data[50])  # éœ€è¦ç´¢å¼•è®¿é—®
>    ```
>
> 2. **æ•°æ®é‡å¤§ã€åªéå†ä¸€æ¬¡** â†’ ç”Ÿæˆå™¨
>    ```python
>    vectors = (compute_embedding(doc) for doc in million_docs)
>    for vec in vectors:
>        db.insert(vec)
>    ```
>
> 3. **éœ€è¦æå‰çŸ¥é“é•¿åº¦** â†’ åˆ—è¡¨ï¼ˆç”Ÿæˆå™¨ä¸èƒ½ `len()`ï¼‰
>
> 4. **æµå¼å¤„ç†ã€ç®¡é“æ“ä½œ** â†’ ç”Ÿæˆå™¨
>    ```python
>    pipeline = (process(x) for x in (filter(x) for x in raw_data))
>    ```

---

## 9. ã€åŒ–éª¨ç»µæŒã€‘

### å¡ç‰‡1ï¼šä»€ä¹ˆæ˜¯ç”Ÿæˆå™¨ï¼Ÿ ğŸ¯

**ä¸€å¥è¯ï¼š** ç”Ÿæˆå™¨æ˜¯å¯ä»¥æš‚åœå’Œæ¢å¤çš„å‡½æ•°ã€‚

**ä¸¾ä¾‹ï¼š**
```python
def gen():
    yield 1  # æš‚åœï¼Œäº§å‡º 1
    yield 2  # æš‚åœï¼Œäº§å‡º 2

g = gen()
print(next(g))  # 1
print(next(g))  # 2
```

**åº”ç”¨ï¼š** å‘é‡æ•°æ®åº“ä¸­ç”¨äºæµå¼è¯»å–æµ·é‡æ•°æ®ã€‚

---

### å¡ç‰‡2ï¼šyield vs return ğŸ”„

**ä¸€å¥è¯ï¼š** yield æš‚åœå‡½æ•°å¹¶äº§å‡ºå€¼ï¼Œreturn ç»ˆæ­¢å‡½æ•°å¹¶è¿”å›å€¼ã€‚

**å¯¹æ¯”ï¼š**
```python
# returnï¼šæ‰§è¡Œä¸€æ¬¡å°±ç»“æŸ
def normal():
    return 1
    return 2  # æ°¸è¿œä¸ä¼šæ‰§è¡Œ

# yieldï¼šå¯ä»¥å¤šæ¬¡äº§å‡º
def generator():
    yield 1
    yield 2  # ä¼šæ‰§è¡Œ
```

---

### å¡ç‰‡3ï¼šç”Ÿæˆå™¨è¡¨è¾¾å¼ ğŸ“

**ä¸€å¥è¯ï¼š** æŠŠåˆ—è¡¨æ¨å¯¼å¼çš„ `[]` æ¢æˆ `()` å°±æ˜¯ç”Ÿæˆå™¨è¡¨è¾¾å¼ã€‚

**ä¸¾ä¾‹ï¼š**
```python
# åˆ—è¡¨ï¼šç«‹å³è®¡ç®—ï¼Œå å†…å­˜
list_comp = [x**2 for x in range(1000000)]

# ç”Ÿæˆå™¨ï¼šæƒ°æ€§è®¡ç®—ï¼Œå‡ ä¹ä¸å å†…å­˜
gen_expr = (x**2 for x in range(1000000))
```

---

### å¡ç‰‡4ï¼šnext() å‡½æ•° â¡ï¸

**ä¸€å¥è¯ï¼š** next() è®©ç”Ÿæˆå™¨æ‰§è¡Œåˆ°ä¸‹ä¸€ä¸ª yield å¹¶è¿”å›å…¶å€¼ã€‚

**ä¸¾ä¾‹ï¼š**
```python
gen = (x for x in [1, 2, 3])
print(next(gen))  # 1
print(next(gen))  # 2
print(next(gen))  # 3
print(next(gen, 'æ²¡äº†'))  # 'æ²¡äº†'ï¼ˆé»˜è®¤å€¼ï¼Œé¿å…æŠ¥é”™ï¼‰
```

---

### å¡ç‰‡5ï¼šStopIteration ğŸ›‘

**ä¸€å¥è¯ï¼š** ç”Ÿæˆå™¨è€—å°½æ—¶æŠ›å‡º StopIteration å¼‚å¸¸ã€‚

**ä¸¾ä¾‹ï¼š**
```python
gen = (x for x in [1])
next(gen)  # 1
next(gen)  # StopIteration!

# for å¾ªç¯è‡ªåŠ¨å¤„ç†
for x in (x for x in [1]):
    print(x)  # æ­£å¸¸ç»“æŸï¼Œä¸æŠ¥é”™
```

---

### å¡ç‰‡6ï¼šç”Ÿæˆå™¨æ˜¯ä¸€æ¬¡æ€§çš„ âš ï¸

**ä¸€å¥è¯ï¼š** ç”Ÿæˆå™¨è€—å°½åä¸èƒ½é‡ç½®ï¼Œéœ€è¦é‡æ–°åˆ›å»ºã€‚

**ä¸¾ä¾‹ï¼š**
```python
gen = (x for x in [1, 2, 3])
print(list(gen))  # [1, 2, 3]
print(list(gen))  # [] ç©ºäº†ï¼

# è§£å†³ï¼šé‡æ–°åˆ›å»º
gen = (x for x in [1, 2, 3])
print(list(gen))  # [1, 2, 3]
```

---

### å¡ç‰‡7ï¼šyield from ğŸ”—

**ä¸€å¥è¯ï¼š** yield from å§”æ‰˜ç»™å¦ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œç®€åŒ–åµŒå¥—è¿­ä»£ã€‚

**ä¸¾ä¾‹ï¼š**
```python
def combined():
    yield from [1, 2]
    yield from [3, 4]

list(combined())  # [1, 2, 3, 4]

# ç­‰ä»·äº
def combined():
    for x in [1, 2]:
        yield x
    for x in [3, 4]:
        yield x
```

---

### å¡ç‰‡8ï¼šæƒ°æ€§è®¡ç®— ğŸ’¤

**ä¸€å¥è¯ï¼š** ç”Ÿæˆå™¨åªåœ¨éœ€è¦æ—¶æ‰è®¡ç®—ï¼Œä¸æå‰å ç”¨èµ„æºã€‚

**ä¸¾ä¾‹ï¼š**
```python
def expensive():
    for i in range(1000000):
        yield i ** 2  # ä¸æ˜¯ä¸€æ¬¡ç®—å®Œ

gen = expensive()
# åªç®—å‰ 3 ä¸ª
result = [next(gen) for _ in range(3)]  # [0, 1, 4]
```

---

### å¡ç‰‡9ï¼šæ‰¹å¤„ç†æ¨¡å¼ ğŸ“¦

**ä¸€å¥è¯ï¼š** ç”¨ç”Ÿæˆå™¨å°†æ•°æ®æµåˆ†æ‰¹ï¼Œæ˜¯å‘é‡æ•°æ®åº“æ’å…¥çš„å¸¸ç”¨æ¨¡å¼ã€‚

**ä¸¾ä¾‹ï¼š**
```python
def batch(iterable, size):
    batch = []
    for item in iterable:
        batch.append(item)
        if len(batch) >= size:
            yield batch
            batch = []
    if batch:
        yield batch

for b in batch(range(7), 3):
    print(b)  # [0,1,2] [3,4,5] [6]
```

---

### å¡ç‰‡10ï¼šç”Ÿæˆå™¨ä¸å¼‚æ­¥ ğŸ”®

**ä¸€å¥è¯ï¼š** Python çš„ async/await åº•å±‚åŸºäºç”Ÿæˆå™¨å®ç°ã€‚

**å…³è”ï¼š**
```python
# ç”Ÿæˆå™¨ï¼šyield æš‚åœ
def gen():
    result = yield request()
    return result

# åç¨‹ï¼šawait æš‚åœ
async def coro():
    result = await request()
    return result
```

**å­¦å®Œç”Ÿæˆå™¨ï¼Œå¼‚æ­¥ç¼–ç¨‹å°±æœ‰äº†åŸºç¡€ï¼**

---

## 10. ã€ä¸€å¥è¯æ€»ç»“ã€‘

**ç”Ÿæˆå™¨æ˜¯é€šè¿‡ yield å®ç°"æš‚åœ-æ¢å¤"èƒ½åŠ›çš„å‡½æ•°ï¼ŒæŒ‰éœ€äº§å‡ºå€¼è€Œéä¸€æ¬¡æ€§è®¡ç®—ï¼Œåœ¨å‘é‡æ•°æ®åº“å¼€å‘ä¸­ç”¨äºå†…å­˜å‹å¥½åœ°å¤„ç†æµ·é‡å‘é‡æ•°æ®çš„è¯»å–ã€è½¬æ¢å’Œæ‰¹é‡æ“ä½œã€‚**

---

## ğŸ“š å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£ yield å’Œ return çš„åŒºåˆ«
- [ ] ä¼šå†™ç”Ÿæˆå™¨å‡½æ•°å’Œç”Ÿæˆå™¨è¡¨è¾¾å¼
- [ ] çŸ¥é“ next() çš„ç”¨æ³•å’Œé»˜è®¤å€¼
- [ ] ç†è§£ StopIteration å¼‚å¸¸
- [ ] çŸ¥é“ç”Ÿæˆå™¨æ˜¯ä¸€æ¬¡æ€§çš„
- [ ] èƒ½ç”¨ç”Ÿæˆå™¨å¤„ç†å¤§æ–‡ä»¶
- [ ] èƒ½å®ç°æ‰¹å¤„ç†ç”Ÿæˆå™¨
- [ ] ç†è§£æƒ°æ€§è®¡ç®—çš„ä¼˜åŠ¿

## ğŸ”— ä¸‹ä¸€æ­¥å­¦ä¹ 

å­¦å®Œ yield åŸºç¡€åï¼Œå»ºè®®å­¦ä¹ ï¼š
1. **ç”Ÿæˆå™¨ - send()** - å‘ç”Ÿæˆå™¨å‘é€æ•°æ®
2. **è¿­ä»£å™¨åè®®** - ç”Ÿæˆå™¨çš„åº•å±‚åŸç†
3. **async/await** - ç”Ÿæˆå™¨çš„å¼‚æ­¥æ‰©å±•
