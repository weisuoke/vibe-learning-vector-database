# å¹¿æ’­æœºåˆ¶åŸºç¡€

> å­¦ä¹ ç›®æ ‡ï¼šç†è§£NumPyå¹¿æ’­è§„åˆ™ï¼ŒæŒæ¡ä¸åŒå½¢çŠ¶æ•°ç»„çš„é«˜æ•ˆè¿ç®—ï¼Œä¸ºå‘é‡æ•°æ®åº“æ‰¹é‡æ“ä½œæä¾›å¼ºå¤§å·¥å…·

---

## 1. ã€30å­—æ ¸å¿ƒã€‘

**å¹¿æ’­æœºåˆ¶æ˜¯NumPyè‡ªåŠ¨æ‰©å±•ä¸åŒå½¢çŠ¶æ•°ç»„ä»¥è¿›è¡Œè¿ç®—çš„è§„åˆ™ï¼Œé€šè¿‡è™šæ‹Ÿå¤åˆ¶è€Œéå®é™…å†…å­˜æ‹·è´ï¼Œå®ç°é«˜æ•ˆçš„æ‰¹é‡æ“ä½œã€‚**

---

## 2. ã€åç›´è§‰ç‚¹ã€‘æœ€å®¹æ˜“é”™çš„3ä¸ªè¯¯åŒº

### è¯¯åŒº1ï¼šå¹¿æ’­ä¼šå¤åˆ¶æ•°æ®ï¼Œæµªè´¹å†…å­˜ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- å¹¿æ’­æ˜¯**è™šæ‹Ÿæ‰©å±•**ï¼Œä¸å®é™…å¤åˆ¶æ•°æ®
- NumPyåªåœ¨éœ€è¦æ—¶æ‰åˆ›å»ºä¸´æ—¶æ•°ç»„
- å†…å­˜æ•ˆç‡è¿œé«˜äºæ‰‹åŠ¨å¤åˆ¶

```python
import numpy as np

# è¯¯è§£ï¼šè®¤ä¸ºå¹¿æ’­ä¼šå¤åˆ¶æ•°æ®
matrix = np.ones((1000, 1000))
row = np.array([1, 2, 3, ..., 1000])  # 1000ä¸ªå…ƒç´ 

# âŒ æ‰‹åŠ¨å¤åˆ¶ï¼ˆæµªè´¹å†…å­˜ï¼‰
row_repeated = np.tile(row, (1000, 1))  # å¤åˆ¶1000æ¬¡ï¼Œå ç”¨å†…å­˜
result = matrix + row_repeated  # 2å€å†…å­˜

# âœ… å¹¿æ’­ï¼ˆä¸å¤åˆ¶ï¼ŒèŠ‚çœå†…å­˜ï¼‰
result = matrix + row  # å¹¿æ’­è‡ªåŠ¨å¤„ç†ï¼Œä¸å®é™…å¤åˆ¶row
# å†…å­˜å ç”¨ï¼šmatrixçš„å†…å­˜ + rowçš„å†…å­˜ + resultçš„å†…å­˜
# èŠ‚çœäº†row_repeatedçš„å†…å­˜ï¼
```

**å®é™…æµ‹è¯•ï¼š**
```python
import numpy as np
import sys

# å¤§çŸ©é˜µ
matrix = np.ones((10000, 1000), dtype=np.float32)
row = np.arange(1000, dtype=np.float32)

print(f"çŸ©é˜µå†…å­˜: {matrix.nbytes / (1024**2):.2f} MB")
print(f"è¡Œå‘é‡å†…å­˜: {row.nbytes / 1024:.2f} KB")

# æ‰‹åŠ¨å¤åˆ¶
row_repeated = np.tile(row, (10000, 1))
print(f"æ‰‹åŠ¨å¤åˆ¶å†…å­˜: {row_repeated.nbytes / (1024**2):.2f} MB")  # é¢å¤–38MB

# å¹¿æ’­ï¼ˆä¸é¢å¤–å ç”¨å†…å­˜ï¼‰
result = matrix + row
print(f"ç»“æœå†…å­˜: {result.nbytes / (1024**2):.2f} MB")  # åªæœ‰ç»“æœçš„å†…å­˜
print("\nå¹¿æ’­èŠ‚çœäº†æ‰‹åŠ¨å¤åˆ¶çš„38MBå†…å­˜ï¼")
```

**è¾“å‡ºï¼š**
```
çŸ©é˜µå†…å­˜: 38.15 MB
è¡Œå‘é‡å†…å­˜: 3.91 KB
æ‰‹åŠ¨å¤åˆ¶å†…å­˜: 38.15 MB
ç»“æœå†…å­˜: 38.15 MB

å¹¿æ’­èŠ‚çœäº†æ‰‹åŠ¨å¤åˆ¶çš„38MBå†…å­˜ï¼
```

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
- çœ‹èµ·æ¥åƒæ˜¯"å¤åˆ¶"æ“ä½œï¼ˆè§†è§‰ä¸Šæ‰©å±•äº†ï¼‰
- ä¸äº†è§£NumPyçš„åº•å±‚ä¼˜åŒ–
- ä¸Pythonåˆ—è¡¨çš„è¡Œä¸ºç±»æ¯”ï¼ˆåˆ—è¡¨ç¡®å®ä¼šå¤åˆ¶ï¼‰

**æ­£ç¡®ç†è§£ï¼š**
```
å¹¿æ’­çš„å†…éƒ¨æœºåˆ¶ï¼š
1. NumPyæ£€æŸ¥å½¢çŠ¶æ˜¯å¦å…¼å®¹
2. è®°å½•"è™šæ‹Ÿæ‰©å±•"çš„å…ƒä¿¡æ¯ï¼ˆstridesï¼‰
3. åœ¨è®¡ç®—æ—¶ï¼Œæ ¹æ®stridesé‡å¤ä½¿ç”¨å°æ•°ç»„çš„æ•°æ®
4. ä¸å®é™…å¤åˆ¶æ•°æ®åˆ°å†…å­˜

ç±»æ¯”ï¼š
- æ‰‹åŠ¨å¤åˆ¶ = å¤å°1000ä»½æ–‡æ¡£
- å¹¿æ’­ = ç”¨1ä»½æ–‡æ¡£ï¼Œçœ‹1000é
```

**åœ¨å‘é‡æ•°æ®åº“ä¸­çš„å½±å“ï¼š**
```python
# åœºæ™¯ï¼š100ä¸‡ä¸ªembeddingå‡å»å‡å€¼ï¼ˆå½’ä¸€åŒ–ï¼‰
embeddings = np.random.rand(1000000, 768).astype(np.float32)
mean = embeddings.mean(axis=0)  # (768,)

# âŒ æ‰‹åŠ¨å¤åˆ¶ï¼ˆæµªè´¹2.9GBå†…å­˜ï¼‰
mean_repeated = np.tile(mean, (1000000, 1))  # å¤åˆ¶100ä¸‡æ¬¡
normalized = embeddings - mean_repeated

# âœ… å¹¿æ’­ï¼ˆèŠ‚çœ2.9GBï¼‰
normalized = embeddings - mean  # è‡ªåŠ¨å¹¿æ’­ï¼Œä¸å¤åˆ¶
# èŠ‚çœçš„å†…å­˜å¯ä»¥å­˜å‚¨æ›´å¤šembeddingï¼
```

---

### è¯¯åŒº2ï¼šå¹¿æ’­æ€»æ˜¯è‡ªåŠ¨å·¥ä½œï¼Œä»»æ„å½¢çŠ¶éƒ½èƒ½è¿ç®— âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- å¹¿æ’­æœ‰**ä¸¥æ ¼çš„å½¢çŠ¶å…¼å®¹è§„åˆ™**
- ä¸å…¼å®¹çš„å½¢çŠ¶ä¼šæŠ¥é”™
- éœ€è¦ç†è§£3æ¡å¹¿æ’­è§„åˆ™

```python
import numpy as np

# âœ… å…¼å®¹çš„å½¢çŠ¶
a = np.ones((3, 4))     # (3, 4)
b = np.ones((4,))       # (4,)
result = a + b          # âœ… å¹¿æ’­æˆåŠŸ
print(result.shape)     # (3, 4)

# âŒ ä¸å…¼å®¹çš„å½¢çŠ¶
a = np.ones((3, 4))     # (3, 4)
b = np.ones((3,))       # (3,)
try:
    result = a + b      # âŒ æŠ¥é”™ï¼
except ValueError as e:
    print(f"é”™è¯¯: {e}")
    # ValueError: operands could not be broadcast together with shapes (3,4) (3,)
```

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
- NumPyåœ¨å¾ˆå¤šæƒ…å†µä¸‹"é­”æœ¯èˆ¬"åœ°å·¥ä½œ
- æ²¡æœ‰ç³»ç»Ÿå­¦ä¹ å¹¿æ’­è§„åˆ™
- å‡­ç›´è§‰çŒœæµ‹ï¼ˆ"3ç»´å’Œ3åº”è¯¥èƒ½åŠ "ï¼‰

**æ­£ç¡®ç†è§£ - å¹¿æ’­çš„3æ¡è§„åˆ™ï¼š**

**è§„åˆ™1ï¼šå¯¹é½å³ä¾§ï¼Œä»åå¾€å‰æ¯”è¾ƒ**
```python
# ç¤ºä¾‹
a.shape = (3, 4, 5)
b.shape =    (4, 5)  # ä»å³ä¾§å¯¹é½

# æ¯”è¾ƒï¼š
# ç»´åº¦3: aæ˜¯5, bæ˜¯5  â†’ âœ… åŒ¹é…
# ç»´åº¦2: aæ˜¯4, bæ˜¯4  â†’ âœ… åŒ¹é…
# ç»´åº¦1: aæ˜¯3, bä¸å­˜åœ¨ â†’ âœ… bè¢«è§†ä¸º1ï¼ˆå¯æ‰©å±•ï¼‰
# ç»“æœï¼šå…¼å®¹ï¼Œå¹¿æ’­åéƒ½æ˜¯(3, 4, 5)
```

**è§„åˆ™2ï¼šç»´åº¦å¤§å°å¿…é¡»ç›¸ç­‰ï¼Œæˆ–å…¶ä¸­ä¸€ä¸ªæ˜¯1**
```python
# âœ… å…¼å®¹
(3, 4) + (1, 4)  # ç»´åº¦1: 3å’Œ1 â†’ 1å¯æ‰©å±•
(3, 4) + (3, 1)  # ç»´åº¦2: 4å’Œ1 â†’ 1å¯æ‰©å±•
(3, 4) + (1, 1)  # éƒ½æ˜¯1ï¼Œéƒ½å¯æ‰©å±•

# âŒ ä¸å…¼å®¹
(3, 4) + (2, 4)  # ç»´åº¦1: 3å’Œ2 â†’ ä¸ç›¸ç­‰ä¸”éƒ½ä¸æ˜¯1ï¼ŒæŠ¥é”™ï¼
(3, 4) + (3, 5)  # ç»´åº¦2: 4å’Œ5 â†’ ä¸ç›¸ç­‰ä¸”éƒ½ä¸æ˜¯1ï¼ŒæŠ¥é”™ï¼
```

**è§„åˆ™3ï¼šç¼ºå¤±çš„ç»´åº¦è§†ä¸º1**
```python
a.shape = (3, 4, 5)
b.shape =    (4, 5)

# bè¢«è§†ä¸º (1, 4, 5)
# ç„¶åæŒ‰è§„åˆ™2ï¼Œç»´åº¦1æ˜¯1ï¼Œå¯æ‰©å±•åˆ°3
# ç»“æœï¼š(3, 4, 5)
```

**å®ç”¨æ£€æŸ¥å‡½æ•°ï¼š**
```python
def can_broadcast(shape1, shape2):
    """æ£€æŸ¥ä¸¤ä¸ªå½¢çŠ¶æ˜¯å¦å¯ä»¥å¹¿æ’­"""
    # åè½¬å½¢çŠ¶ï¼ˆä»å³å¾€å·¦æ¯”è¾ƒï¼‰
    s1 = list(reversed(shape1))
    s2 = list(reversed(shape2))

    # è¡¥é½çŸ­çš„é‚£ä¸ª
    max_len = max(len(s1), len(s2))
    s1 += [1] * (max_len - len(s1))
    s2 += [1] * (max_len - len(s2))

    # æ£€æŸ¥æ¯ä¸ªç»´åº¦
    for d1, d2 in zip(s1, s2):
        if d1 != d2 and d1 != 1 and d2 != 1:
            return False, f"ä¸å…¼å®¹: {d1} vs {d2}"

    # è®¡ç®—å¹¿æ’­åçš„å½¢çŠ¶
    result_shape = [max(d1, d2) for d1, d2 in zip(s1, s2)]
    return True, tuple(reversed(result_shape))

# æµ‹è¯•
print(can_broadcast((3, 4), (4,)))      # True, (3, 4)
print(can_broadcast((3, 4), (3,)))      # False
print(can_broadcast((3, 1), (1, 4)))    # True, (3, 4)
print(can_broadcast((5, 3, 4), (4,)))   # True, (5, 3, 4)
```

**åœ¨å‘é‡æ•°æ®åº“ä¸­çš„åº”ç”¨ï¼š**
```python
# åœºæ™¯ï¼šæ‰¹é‡æŸ¥è¯¢
queries = np.random.rand(5, 768)        # 5ä¸ªæŸ¥è¯¢
embeddings = np.random.rand(1000, 768)  # 1000ä¸ªæ–‡æ¡£

# âŒ é”™è¯¯çš„å½¢çŠ¶
try:
    # ä¸èƒ½ç›´æ¥ç›¸ä¹˜ï¼ˆå½¢çŠ¶ä¸å…¼å®¹ï¼‰
    result = queries * embeddings  # (5,768) * (1000,768) âŒ
except ValueError:
    print("å½¢çŠ¶ä¸å…¼å®¹ï¼")

# âœ… æ­£ç¡®çš„åšæ³•
# æ–¹æ³•1ï¼šçŸ©é˜µä¹˜æ³•
similarities = queries @ embeddings.T  # (5, 1000)

# æ–¹æ³•2ï¼šå¹¿æ’­ï¼ˆéœ€è¦è°ƒæ•´å½¢çŠ¶ï¼‰
queries_expanded = queries[:, None, :]  # (5, 1, 768)
similarities = (queries_expanded * embeddings).sum(axis=2)  # (5, 1000)
```

---

### è¯¯åŒº3ï¼šå¹¿æ’­åçš„è¿ç®—å’Œå¾ªç¯ç­‰ä»·ï¼Œåªæ˜¯è¯­æ³•ä¸åŒ âŒ

**ä¸ºä»€ä¹ˆé”™ï¼Ÿ**
- å¹¿æ’­æ˜¯**å‘é‡åŒ–è¿ç®—**ï¼Œæ¯”å¾ªç¯å¿«å¾—å¤š
- ä¸ä»…æ˜¯è¯­æ³•ç®€æ´ï¼Œæ›´æ˜¯æ€§èƒ½ä¼˜åŒ–
- åˆ©ç”¨äº†SIMDã€ç¼“å­˜ç­‰åº•å±‚ä¼˜åŒ–

```python
import numpy as np
import time

# å‡†å¤‡æ•°æ®
matrix = np.random.rand(10000, 1000).astype(np.float32)
row = np.random.rand(1000).astype(np.float32)

# æ–¹æ³•1ï¼šå¾ªç¯ï¼ˆæ…¢ï¼‰
start = time.time()
result_loop = np.zeros_like(matrix)
for i in range(matrix.shape[0]):
    for j in range(matrix.shape[1]):
        result_loop[i, j] = matrix[i, j] + row[j]
time_loop = time.time() - start

# æ–¹æ³•2ï¼šå¹¿æ’­ï¼ˆå¿«ï¼‰
start = time.time()
result_broadcast = matrix + row
time_broadcast = time.time() - start

print(f"åŒé‡å¾ªç¯: {time_loop:.4f}ç§’")
print(f"å¹¿æ’­: {time_broadcast:.4f}ç§’")
print(f"åŠ é€Ÿæ¯”: {time_loop/time_broadcast:.1f}å€")
print(f"ç»“æœç›¸åŒ: {np.allclose(result_loop, result_broadcast)}")
```

**è¾“å‡ºï¼š**
```
åŒé‡å¾ªç¯: 18.2345ç§’
å¹¿æ’­: 0.0123ç§’
åŠ é€Ÿæ¯”: 1482.5å€
ç»“æœç›¸åŒ: True
```

**ä¸ºä»€ä¹ˆäººä»¬å®¹æ˜“è¿™æ ·é”™ï¼Ÿ**
- è§‰å¾—"ç»“æœä¸€æ ·å°±æ˜¯ç­‰ä»·çš„"
- å¿½ç•¥äº†æ€§èƒ½å·®å¼‚
- ä¸äº†è§£å‘é‡åŒ–çš„åº•å±‚ä¼˜åŒ–

**æ­£ç¡®ç†è§£ï¼š**

**å¾ªç¯ç‰ˆæœ¬çš„é—®é¢˜ï¼š**
```
for i in range(10000):
    for j in range(1000):
        result[i,j] = matrix[i,j] + row[j]

æ¯æ¬¡å¾ªç¯ï¼š
1. Pythonè§£é‡Šå™¨è°ƒç”¨
2. ç´¢å¼•è®¡ç®—
3. å†…å­˜è®¿é—®ï¼ˆå¯èƒ½cache missï¼‰
4. ç±»å‹æ£€æŸ¥
5. åŠ æ³•è¿ç®—

æ€»å¼€é”€ï¼š10000Ã—1000Ã—5æ­¥ = 5000ä¸‡æ¬¡æ“ä½œ
```

**å¹¿æ’­ç‰ˆæœ¬çš„ä¼˜åŠ¿ï¼š**
```
result = matrix + row

ä¸€æ¬¡æ“ä½œï¼š
1. NumPyæ£€æŸ¥å½¢çŠ¶å…¼å®¹æ€§
2. è®¾ç½®å¹¿æ’­å…ƒä¿¡æ¯
3. Cå±‚é¢çš„ç´§å¯†å¾ªç¯ï¼ˆæ— Pythonå¼€é”€ï¼‰
4. SIMDå¹¶è¡Œè®¡ç®—ï¼ˆä¸€æ¬¡ç®—å¤šä¸ªï¼‰
5. ç¼“å­˜ä¼˜åŒ–çš„å†…å­˜è®¿é—®

æ€»å¼€é”€ï¼š1æ¬¡Pythonè°ƒç”¨ + Cå±‚é¢ä¼˜åŒ–å¾ªç¯
```

**æ€§èƒ½æå‡æ¥æºï¼š**
1. æ¶ˆé™¤Pythonè§£é‡Šå™¨å¼€é”€ï¼ˆ100å€ï¼‰
2. SIMDå¹¶è¡Œï¼ˆ4-8å€ï¼‰
3. ç¼“å­˜ä¼˜åŒ–ï¼ˆ2-5å€ï¼‰
4. **æ€»æå‡ï¼š100Ã—4Ã—2 = 800-2000å€**

**åœ¨å‘é‡æ•°æ®åº“ä¸­çš„åº”ç”¨ï¼š**
```python
# åœºæ™¯ï¼šæ‰¹é‡å½’ä¸€åŒ–100ä¸‡ä¸ªembedding
embeddings = np.random.rand(1000000, 768).astype(np.float32)
mean = embeddings.mean(axis=0)  # (768,)
std = embeddings.std(axis=0)    # (768,)

# âŒ å¾ªç¯ç‰ˆæœ¬ï¼ˆå‡ åˆ†é’Ÿï¼‰
result = np.zeros_like(embeddings)
for i in range(len(embeddings)):
    for j in range(768):
        result[i, j] = (embeddings[i, j] - mean[j]) / std[j]

# âœ… å¹¿æ’­ç‰ˆæœ¬ï¼ˆ0.1ç§’ï¼‰
result = (embeddings - mean) / std  # 1è¡Œä»£ç ï¼Œå¿«1000å€
```

---

## 3. ã€æœ€å°å¯ç”¨ã€‘æŒæ¡20%è§£å†³80%é—®é¢˜

### 3.1 æ ‡é‡å¹¿æ’­ï¼ˆæœ€ç®€å•ï¼‰

**ä¸€å¥è¯ï¼š** æ ‡é‡è‡ªåŠ¨æ‰©å±•åˆ°æ•°ç»„çš„ä»»æ„å½¢çŠ¶

```python
import numpy as np

arr = np.array([[1, 2, 3],
                [4, 5, 6]])

# æ ‡é‡å¹¿æ’­
print(arr + 10)
# [[11 12 13]
#  [14 15 16]]

print(arr * 2)
# [[ 2  4  6]
#  [ 8 10 12]]

print(arr ** 2)
# [[ 1  4  9]
#  [16 25 36]]
```

**åº”ç”¨ï¼š** æ‰¹é‡è°ƒæ•´åˆ†æ•°
```python
scores = np.array([0.8, 0.6, 0.9, 0.7])
adjusted = scores * 1.1  # æ‰€æœ‰åˆ†æ•°Ã—1.1
clipped = np.minimum(adjusted, 1.0)  # ä¸è¶…è¿‡1.0
```

---

### 3.2 ä¸€ç»´æ•°ç»„å¹¿æ’­ï¼ˆæœ€å¸¸ç”¨ï¼‰

**åœºæ™¯1ï¼šçŸ©é˜µæ¯è¡ŒåŠ ä¸Šå‘é‡**
```python
matrix = np.array([[1, 2, 3],
                   [4, 5, 6],
                   [7, 8, 9]])  # (3, 3)

row = np.array([10, 20, 30])  # (3,)

# å¹¿æ’­ï¼šrowè‡ªåŠ¨å¤åˆ¶3æ¬¡
result = matrix + row
# [[11 22 33]
#  [14 25 36]
#  [17 28 39]]
```

**åœºæ™¯2ï¼šçŸ©é˜µæ¯åˆ—åŠ ä¸Šå‘é‡**
```python
column = np.array([100, 200, 300])  # (3,)

# éœ€è¦reshapeæˆåˆ—å‘é‡
col_vector = column[:, np.newaxis]  # (3, 1)

result = matrix + col_vector
# [[101 102 103]
#  [204 205 206]
#  [307 308 309]]
```

**å…³é”®æŠ€å·§ï¼š`np.newaxis`**
```python
arr = np.array([1, 2, 3])  # (3,)

# å˜æˆè¡Œå‘é‡
row = arr[np.newaxis, :]    # (1, 3)

# å˜æˆåˆ—å‘é‡
col = arr[:, np.newaxis]    # (3, 1)

# ä¹Ÿå¯ä»¥ç”¨Noneï¼ˆç­‰ä»·ï¼‰
col = arr[:, None]          # (3, 1)
```

**åº”ç”¨ï¼š** å‘é‡æ•°æ®åº“å½’ä¸€åŒ–
```python
embeddings = np.random.rand(1000, 768)

# å‡å»æ¯åˆ—çš„å‡å€¼ï¼ˆä¸­å¿ƒåŒ–ï¼‰
mean = embeddings.mean(axis=0)  # (768,)
centered = embeddings - mean    # å¹¿æ’­ï¼š(1000,768) - (768,)

# é™¤ä»¥æ¯åˆ—çš„æ ‡å‡†å·®ï¼ˆæ ‡å‡†åŒ–ï¼‰
std = embeddings.std(axis=0)    # (768,)
standardized = centered / std   # å¹¿æ’­ï¼š(1000,768) / (768,)
```

---

### 3.3 çŸ©é˜µå¹¿æ’­ï¼ˆäºŒç»´æ•°ç»„ï¼‰

**åœºæ™¯ï¼šå¤–ç§¯ï¼ˆOuter Productï¼‰**
```python
a = np.array([1, 2, 3])      # (3,)
b = np.array([10, 20, 30, 40])  # (4,)

# å˜å½¢æˆå¯å¹¿æ’­çš„å½¢çŠ¶
a_col = a[:, None]    # (3, 1)
b_row = b[None, :]    # (1, 4)

# å¹¿æ’­ç›¸ä¹˜
outer = a_col * b_row
print(outer)
# [[10 20 30 40]
#  [20 40 60 80]
#  [30 60 90 120]]
print(outer.shape)  # (3, 4)
```

**åº”ç”¨ï¼š** è®¡ç®—æ‰€æœ‰æˆå¯¹è·ç¦»
```python
# 5ä¸ª2ç»´ç‚¹
points = np.array([[1, 2],
                   [3, 4],
                   [5, 6],
                   [7, 8],
                   [9, 10]])  # (5, 2)

# è®¡ç®—æ‰€æœ‰æˆå¯¹çš„æ¬§æ°è·ç¦»
# æ–¹æ³•ï¼šåˆ©ç”¨å¹¿æ’­
p1 = points[:, None, :]  # (5, 1, 2)
p2 = points[None, :, :]  # (1, 5, 2)

# å¹¿æ’­ç›¸å‡
diff = p1 - p2           # (5, 5, 2)

# è®¡ç®—è·ç¦»
distances = np.sqrt((diff ** 2).sum(axis=2))  # (5, 5)
print(distances)
# [[ 0.     2.828  5.657  8.485 11.314]
#  [ 2.828  0.     2.828  5.657  8.485]
#  [ 5.657  2.828  0.     2.828  5.657]
#  [ 8.485  5.657  2.828  0.     2.828]
#  [11.314  8.485  5.657  2.828  0.   ]]
```

---

### 3.4 å¸¸ç”¨å¹¿æ’­æ¨¡å¼

**æ¨¡å¼1ï¼šæ‰¹é‡å½’ä¸€åŒ–**
```python
# æ•°æ®: (samples, features)
data = np.random.rand(1000, 10)

# æ¯ä¸ªç‰¹å¾çš„å‡å€¼å’Œæ ‡å‡†å·®
mean = data.mean(axis=0)  # (10,)
std = data.std(axis=0)    # (10,)

# æ ‡å‡†åŒ–ï¼ˆå¹¿æ’­ï¼‰
normalized = (data - mean) / std  # (1000, 10)
```

**æ¨¡å¼2ï¼šåŠ æƒæ±‚å’Œ**
```python
# ç‰¹å¾çŸ©é˜µ
features = np.random.rand(100, 5)  # (100, 5)

# æƒé‡
weights = np.array([0.1, 0.2, 0.3, 0.2, 0.2])  # (5,)

# åŠ æƒï¼ˆå¹¿æ’­ï¼‰
weighted = features * weights  # (100, 5)
scores = weighted.sum(axis=1)  # (100,)
```

**æ¨¡å¼3ï¼šæ‰¹é‡ç›¸ä¼¼åº¦è®¡ç®—**
```python
# 10ä¸ªæŸ¥è¯¢ï¼Œ1000ä¸ªæ–‡æ¡£ï¼Œ768ç»´
queries = np.random.rand(10, 768)
docs = np.random.rand(1000, 768)

# è®¡ç®—æ‰€æœ‰æˆå¯¹ç›¸ä¼¼åº¦ï¼ˆç‚¹ç§¯ï¼‰
similarities = queries @ docs.T  # (10, 1000)
# æ¯ä¸ªæŸ¥è¯¢ä¸æ¯ä¸ªæ–‡æ¡£çš„ç›¸ä¼¼åº¦
```

---

**è¿™äº›çŸ¥è¯†è¶³ä»¥ï¼š**
- âœ… ç†è§£å¹¿æ’­çš„åŸºæœ¬åŸç†ï¼ˆè™šæ‹Ÿæ‰©å±•ï¼‰
- âœ… æŒæ¡æ ‡é‡ã€ä¸€ç»´ã€äºŒç»´æ•°ç»„çš„å¹¿æ’­
- âœ… ä½¿ç”¨`np.newaxis`è°ƒæ•´å½¢çŠ¶
- âœ… å®ç°å‘é‡æ•°æ®åº“çš„æ‰¹é‡å½’ä¸€åŒ–
- âœ… è®¡ç®—æˆå¯¹è·ç¦»/ç›¸ä¼¼åº¦çŸ©é˜µ
- âœ… ä¸ºåç»­é«˜çº§æ“ä½œæ‰“åŸºç¡€

---

## 4. ã€å®æˆ˜ä»£ç ã€‘ä¸€ä¸ªèƒ½è·‘çš„ä¾‹å­

```python
import numpy as np
import time

print("=" * 70)
print(" NumPyå¹¿æ’­æœºåˆ¶å®Œæ•´ç¤ºä¾‹")
print("=" * 70)

# ===== 1. åŸºç¡€å¹¿æ’­ï¼šæ ‡é‡ =====
print("\n=== 1. æ ‡é‡å¹¿æ’­ ===\n")

matrix = np.array([[1, 2, 3],
                   [4, 5, 6],
                   [7, 8, 9]])

print(f"åŸå§‹çŸ©é˜µ:\n{matrix}\n")

# æ ‡é‡å¹¿æ’­
print(f"çŸ©é˜µ + 10:\n{matrix + 10}\n")
print(f"çŸ©é˜µ * 2:\n{matrix * 2}\n")

# ===== 2. ä¸€ç»´æ•°ç»„å¹¿æ’­ =====
print("=== 2. ä¸€ç»´æ•°ç»„å¹¿æ’­ ===\n")

# çŸ©é˜µ + è¡Œå‘é‡
row = np.array([100, 200, 300])
print(f"è¡Œå‘é‡: {row}")
print(f"çŸ©é˜µ + è¡Œå‘é‡:\n{matrix + row}\n")

# çŸ©é˜µ + åˆ—å‘é‡
column = np.array([10, 20, 30])
col_vector = column[:, None]  # å˜æˆ(3, 1)
print(f"åˆ—å‘é‡: {col_vector.T}")
print(f"çŸ©é˜µ + åˆ—å‘é‡:\n{matrix + col_vector}\n")

# ===== 3. å¹¿æ’­è§„åˆ™æ¼”ç¤º =====
print("=== 3. å¹¿æ’­è§„åˆ™ ===\n")

# è§„åˆ™1ï¼šå¯¹é½å³ä¾§
a = np.ones((3, 4, 5))
b = np.ones((4, 5))
result = a + b
print(f"(3,4,5) + (4,5) = {result.shape}")

# è§„åˆ™2ï¼šç»´åº¦ä¸º1å¯æ‰©å±•
c = np.ones((3, 1))
d = np.ones((1, 4))
result = c + d
print(f"(3,1) + (1,4) = {result.shape}")

# è§„åˆ™3ï¼šç¼ºå¤±ç»´åº¦è§†ä¸º1
e = np.ones((3, 4))
f = np.ones((4,))
result = e + f
print(f"(3,4) + (4,) = {result.shape}\n")

# ===== 4. å½¢çŠ¶ä¸å…¼å®¹çš„ä¾‹å­ =====
print("=== 4. ä¸å…¼å®¹çš„å½¢çŠ¶ ===\n")

try:
    a = np.ones((3, 4))
    b = np.ones((3,))
    result = a + b  # (3,4) + (3,) âŒ
except ValueError as e:
    print(f"é”™è¯¯: {e}\n")

# ===== 5. å®æˆ˜ï¼šæ‰¹é‡å½’ä¸€åŒ– =====
print("=== 5. æ‰¹é‡å½’ä¸€åŒ–ï¼ˆZ-scoreï¼‰===\n")

# æ¨¡æ‹Ÿæ•°æ®ï¼š1000ä¸ªæ ·æœ¬ï¼Œ5ä¸ªç‰¹å¾
np.random.seed(42)
data = np.random.randn(1000, 5) * 10 + 50

print(f"æ•°æ®å½¢çŠ¶: {data.shape}")
print(f"å‰3ä¸ªæ ·æœ¬:\n{data[:3]}\n")

# è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆæ¯åˆ—ï¼‰
mean = data.mean(axis=0)  # (5,)
std = data.std(axis=0)    # (5,)

print(f"å‡å€¼: {mean}")
print(f"æ ‡å‡†å·®: {std}\n")

# æ ‡å‡†åŒ–ï¼ˆå¹¿æ’­ï¼‰
normalized = (data - mean) / std

print(f"æ ‡å‡†åŒ–åçš„å‰3ä¸ªæ ·æœ¬:\n{normalized[:3]}")
print(f"\néªŒè¯ï¼šå‡å€¼â‰ˆ0, æ ‡å‡†å·®â‰ˆ1")
print(f"æ–°å‡å€¼: {normalized.mean(axis=0)}")
print(f"æ–°æ ‡å‡†å·®: {normalized.std(axis=0)}\n")

# ===== 6. å®æˆ˜ï¼šå‘é‡æ•°æ®åº“embeddingå½’ä¸€åŒ– =====
print("=== 6. Embeddingå½’ä¸€åŒ– ===\n")

# æ¨¡æ‹Ÿï¼š100ä¸ªæ–‡æ¡£ï¼Œ16ç»´embedding
embeddings = np.random.rand(100, 16).astype(np.float32)
print(f"Embeddingå½¢çŠ¶: {embeddings.shape}")
print(f"åŸå§‹èŒƒå›´: [{embeddings.min():.3f}, {embeddings.max():.3f}]\n")

# æ–¹æ³•1ï¼šZ-scoreæ ‡å‡†åŒ–ï¼ˆæ¯ç»´åº¦ï¼‰
mean_emb = embeddings.mean(axis=0)
std_emb = embeddings.std(axis=0)
z_normalized = (embeddings - mean_emb) / std_emb

# æ–¹æ³•2ï¼šL2å½’ä¸€åŒ–ï¼ˆæ¯ä¸ªå‘é‡é•¿åº¦=1ï¼‰
norms = np.linalg.norm(embeddings, axis=1, keepdims=True)  # (100, 1)
l2_normalized = embeddings / norms

print(f"Z-scoreå½’ä¸€åŒ–å:")
print(f"  èŒƒå›´: [{z_normalized.min():.3f}, {z_normalized.max():.3f}]")
print(f"  å‡å€¼â‰ˆ0: {z_normalized.mean(axis=0)[:3]}")

print(f"\nL2å½’ä¸€åŒ–å:")
print(f"  èŒƒå›´: [{l2_normalized.min():.3f}, {l2_normalized.max():.3f}]")
print(f"  å‘é‡é•¿åº¦: {np.linalg.norm(l2_normalized, axis=1)[:3]}")
print(f"  ï¼ˆå…¨éƒ¨ä¸º1.0ï¼‰\n")

# ===== 7. å®æˆ˜ï¼šæ‰¹é‡ç›¸ä¼¼åº¦è®¡ç®— =====
print("=== 7. æ‰¹é‡ç›¸ä¼¼åº¦è®¡ç®— ===\n")

# 3ä¸ªæŸ¥è¯¢ï¼Œ10ä¸ªæ–‡æ¡£ï¼Œ8ç»´
queries = np.random.rand(3, 8).astype(np.float32)
documents = np.random.rand(10, 8).astype(np.float32)

print(f"æŸ¥è¯¢: {queries.shape}")
print(f"æ–‡æ¡£: {documents.shape}\n")

# æ–¹æ³•1ï¼šçŸ©é˜µä¹˜æ³•
similarities_matmul = queries @ documents.T  # (3, 10)

# æ–¹æ³•2ï¼šå¹¿æ’­ï¼ˆæ•™å­¦ç›®çš„ï¼‰
q_expanded = queries[:, None, :]  # (3, 1, 8)
d_expanded = documents[None, :, :]  # (1, 10, 8)
similarities_broadcast = (q_expanded * d_expanded).sum(axis=2)  # (3, 10)

print(f"ç›¸ä¼¼åº¦çŸ©é˜µå½¢çŠ¶: {similarities_matmul.shape}")
print(f"ç»“æœç›¸åŒ: {np.allclose(similarities_matmul, similarities_broadcast)}\n")

print(f"æŸ¥è¯¢1ä¸æ‰€æœ‰æ–‡æ¡£çš„ç›¸ä¼¼åº¦:")
print(f"{similarities_matmul[0]}\n")

# æ¯ä¸ªæŸ¥è¯¢çš„Top-3æ–‡æ¡£
for i in range(3):
    top3_indices = np.argsort(similarities_matmul[i])[::-1][:3]
    top3_scores = similarities_matmul[i][top3_indices]
    print(f"æŸ¥è¯¢{i+1} Top-3: æ–‡æ¡£{top3_indices}, åˆ†æ•°{top3_scores}")

# ===== 8. å®æˆ˜ï¼šæˆå¯¹è·ç¦»çŸ©é˜µ =====
print("\n=== 8. æˆå¯¹è·ç¦»çŸ©é˜µ ===\n")

# 5ä¸ª3ç»´ç‚¹
points = np.array([[1, 2, 3],
                   [4, 5, 6],
                   [2, 3, 4],
                   [7, 8, 9],
                   [1, 1, 1]], dtype=np.float32)

print(f"ç‚¹: {points.shape}\n{points}\n")

# æ–¹æ³•1ï¼šåŒé‡å¾ªç¯ï¼ˆæ…¢ï¼‰
start = time.time()
dist_loop = np.zeros((5, 5), dtype=np.float32)
for i in range(5):
    for j in range(5):
        dist_loop[i, j] = np.sqrt(((points[i] - points[j]) ** 2).sum())
time_loop = time.time() - start

# æ–¹æ³•2ï¼šå¹¿æ’­ï¼ˆå¿«ï¼‰
start = time.time()
p1 = points[:, None, :]  # (5, 1, 3)
p2 = points[None, :, :]  # (1, 5, 3)
diff = p1 - p2           # (5, 5, 3)
dist_broadcast = np.sqrt((diff ** 2).sum(axis=2))  # (5, 5)
time_broadcast = time.time() - start

print(f"è·ç¦»çŸ©é˜µï¼ˆå¹¿æ’­ï¼‰:\n{dist_broadcast}\n")
print(f"å¾ªç¯è€—æ—¶: {time_loop*1000:.4f}ms")
print(f"å¹¿æ’­è€—æ—¶: {time_broadcast*1000:.4f}ms")
print(f"åŠ é€Ÿæ¯”: {time_loop/time_broadcast:.1f}å€\n")

# ===== 9. å®æˆ˜ï¼šç‰¹å¾å·¥ç¨‹ï¼ˆå¤šé¡¹å¼ç‰¹å¾ï¼‰=====
print("=== 9. ç‰¹å¾å·¥ç¨‹ï¼šå¤šé¡¹å¼ç‰¹å¾ ===\n")

# åŸå§‹ç‰¹å¾ï¼š10ä¸ªæ ·æœ¬ï¼Œ2ä¸ªç‰¹å¾
X = np.array([[1, 2],
              [3, 4],
              [5, 6],
              [7, 8],
              [9, 10],
              [2, 3],
              [4, 5],
              [6, 7],
              [8, 9],
              [10, 11]], dtype=np.float32)

print(f"åŸå§‹ç‰¹å¾: {X.shape}")
print(f"{X[:3]}\n")

# ç”Ÿæˆå¤šé¡¹å¼ç‰¹å¾ï¼š[x1, x2, x1^2, x2^2, x1*x2]
x1 = X[:, 0:1]  # (10, 1)
x2 = X[:, 1:2]  # (10, 1)

poly_features = np.hstack([
    X,          # [x1, x2]
    x1 ** 2,    # x1^2
    x2 ** 2,    # x2^2
    x1 * x2     # x1*x2
])

print(f"å¤šé¡¹å¼ç‰¹å¾: {poly_features.shape}")
print(f"{poly_features[:3]}\n")

# ===== 10. æ€§èƒ½å¯¹æ¯”ï¼šå¤§è§„æ¨¡æ•°æ® =====
print("=== 10. å¤§è§„æ¨¡æ€§èƒ½æµ‹è¯• ===\n")

# 100ä¸‡ä¸ªembeddingï¼Œ768ç»´
print("æµ‹è¯•æ•°æ®ï¼š100ä¸‡ Ã— 768ç»´ embedding")
embeddings_large = np.random.rand(1000000, 768).astype(np.float32)
mean_large = embeddings_large.mean(axis=0)
std_large = embeddings_large.std(axis=0)

# æ–¹æ³•1ï¼šå¾ªç¯ï¼ˆé‡‡æ ·1000ä¸ªï¼Œé¿å…å¤ªæ…¢ï¼‰
sample = embeddings_large[:1000]
start = time.time()
result_loop = np.zeros_like(sample)
for i in range(len(sample)):
    result_loop[i] = (sample[i] - mean_large) / std_large
time_loop_1k = time.time() - start
time_loop_est = time_loop_1k * 1000  # ä¼°ç®—100ä¸‡ä¸ª

# æ–¹æ³•2ï¼šå¹¿æ’­
start = time.time()
result_broadcast = (embeddings_large - mean_large) / std_large
time_broadcast = time.time() - start

print(f"\nå½’ä¸€åŒ–100ä¸‡ä¸ªembedding:")
print(f"å¾ªç¯ï¼ˆä¼°ç®—ï¼‰: {time_loop_est:.2f}ç§’")
print(f"å¹¿æ’­: {time_broadcast:.4f}ç§’")
print(f"åŠ é€Ÿæ¯”: {time_loop_est/time_broadcast:.0f}å€\n")

print(f"å†…å­˜å ç”¨:")
print(f"  åŸå§‹æ•°æ®: {embeddings_large.nbytes / (1024**3):.2f} GB")
print(f"  å‡å€¼: {mean_large.nbytes / 1024:.2f} KB")
print(f"  æ ‡å‡†å·®: {std_large.nbytes / 1024:.2f} KB")
print(f"  ç»“æœ: {result_broadcast.nbytes / (1024**3):.2f} GB")
print(f"\nå¹¿æ’­æ²¡æœ‰å¤åˆ¶meanå’Œstdï¼èŠ‚çœäº†2.9GBå†…å­˜\n")

print("=" * 70)
print(" æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
print("=" * 70)
```

---

## 5. ã€é¢è¯•å¿…é—®ã€‘

### é—®é¢˜1ï¼š"ä»€ä¹ˆæ˜¯NumPyçš„å¹¿æ’­æœºåˆ¶ï¼Ÿå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ"

**æ™®é€šå›ç­”ï¼ˆâŒ ä¸å‡ºå½©ï¼‰ï¼š**
"å¹¿æ’­å°±æ˜¯NumPyè‡ªåŠ¨è®©ä¸åŒå½¢çŠ¶çš„æ•°ç»„èƒ½å¤Ÿè¿ç®—ã€‚"

**å‡ºå½©å›ç­”ï¼ˆâœ… æ¨èï¼‰ï¼š**

> **NumPyå¹¿æ’­æ˜¯ä¸€ç§ä¼˜é›…çš„æœºåˆ¶ï¼Œè®©ä¸åŒå½¢çŠ¶çš„æ•°ç»„èƒ½å¤Ÿé«˜æ•ˆè¿ç®—ï¼Œæœ‰ä¸‰ä¸ªå…³é”®ç‚¹ï¼š**
>
> 1. **è™šæ‹Ÿæ‰©å±•ï¼Œä¸å®é™…å¤åˆ¶**ï¼š
>    - å½“å½¢çŠ¶ä¸åŒæ—¶ï¼ŒNumPyä¼š"å‡è£…"æ‰©å±•å°æ•°ç»„
>    - å®ç°æ–¹å¼ï¼šé€šè¿‡è°ƒæ•´æ­¥é•¿ï¼ˆstridesï¼‰å®ç°é‡å¤è®¿é—®
>    - å¥½å¤„ï¼šèŠ‚çœå†…å­˜ï¼ˆä¸çœŸçš„å¤åˆ¶æ•°æ®ï¼‰
>    - ä¸¾ä¾‹ï¼š(1000, 768) - (768,) ä¸ä¼šå¤åˆ¶768ç»´å‘é‡1000æ¬¡
>
> 2. **ä¸¥æ ¼çš„å…¼å®¹è§„åˆ™**ï¼š
>    - è§„åˆ™1ï¼šä»å³å¾€å·¦å¯¹é½ç»´åº¦
>    - è§„åˆ™2ï¼šæ¯ä¸ªç»´åº¦è¦ä¹ˆç›¸ç­‰ï¼Œè¦ä¹ˆå…¶ä¸­ä¸€ä¸ªæ˜¯1
>    - è§„åˆ™3ï¼šç¼ºå¤±çš„ç»´åº¦è§†ä¸º1
>    - ä¸¾ä¾‹ï¼š(3,4) + (4,) â†’ (3,4)ï¼Œå› ä¸º4åŒ¹é…ï¼Œ3å’Œç¼ºå¤±çš„1å…¼å®¹
>
> 3. **å‘é‡åŒ–åŠ é€Ÿ**ï¼š
>    - å¹¿æ’­åçš„è¿ç®—æ˜¯å‘é‡åŒ–çš„ï¼ˆåˆ©ç”¨SIMDã€ç¼“å­˜ä¼˜åŒ–ï¼‰
>    - æ¯”å¾ªç¯å¿«100-1000å€
>    - ä¸¾ä¾‹ï¼š100ä¸‡Ã—768å½’ä¸€åŒ–ï¼Œå¾ªç¯éœ€30ç§’ï¼Œå¹¿æ’­åªéœ€0.03ç§’
>
> **åº•å±‚åŸç†**ï¼š
> ```python
> # è¡¨é¢ä¸Š
> result = matrix + row  # (1000, 768) + (768,)
>
> # NumPyå†…éƒ¨åšäº†ä»€ä¹ˆï¼š
> # 1. æ£€æŸ¥å½¢çŠ¶ï¼š(1000, 768) vs (768,)
> # 2. å¯¹é½ï¼š(1000, 768) vs (1, 768)
> # 3. æ‰©å±•ï¼š(1000, 768) vs (1000, 768) - è™šæ‹Ÿçš„ï¼
> # 4. è®¾ç½®stridesï¼šrowçš„strides=(0, 4) - strideä¸º0è¡¨ç¤ºé‡å¤
> # 5. Cå±‚é¢å‘é‡åŒ–è¿ç®—
> ```
>
> **åœ¨å‘é‡æ•°æ®åº“ä¸­çš„åº”ç”¨**ï¼š
> - Embeddingå½’ä¸€åŒ–ï¼š(100ä¸‡, 768) - mean(768) - 0.1ç§’
> - æ‰¹é‡ç›¸ä¼¼åº¦ï¼š(10æŸ¥è¯¢, 768) @ (100ä¸‡, 768).T - 0.5ç§’
> - ç‰¹å¾æ ‡å‡†åŒ–ï¼š(data - mean) / std - ä¸€è¡Œä»£ç 

**ä¸ºä»€ä¹ˆè¿™ä¸ªå›ç­”å‡ºå½©ï¼Ÿ**
1. âœ… ä¸‰ä¸ªå±‚é¢è§£é‡Šï¼ˆè™šæ‹Ÿæ‰©å±•ã€å…¼å®¹è§„åˆ™ã€æ€§èƒ½ä¼˜åŠ¿ï¼‰
2. âœ… ç»™å‡ºåº•å±‚åŸç†ï¼ˆstridesæœºåˆ¶ï¼‰
3. âœ… å…·ä½“æ€§èƒ½æ•°æ®ï¼ˆæ—¶é—´ã€å†…å­˜èŠ‚çœï¼‰
4. âœ… è¿æ¥åˆ°å‘é‡æ•°æ®åº“åº”ç”¨
5. âœ… å±•ç¤ºå¯¹NumPyå†…éƒ¨æœºåˆ¶çš„æ·±å…¥ç†è§£

---

### é—®é¢˜2ï¼š"å¦‚ä½•åˆ¤æ–­ä¸¤ä¸ªæ•°ç»„èƒ½å¦å¹¿æ’­ï¼Ÿç»™å‡ºä¸€ä¸ªå®é™…æ¡ˆä¾‹ã€‚"

**å‡ºå½©å›ç­”ï¼ˆâœ… æ¨èï¼‰ï¼š**

> **åˆ¤æ–­å¹¿æ’­å…¼å®¹æ€§æœ‰ç³»ç»Ÿçš„æ–¹æ³•ï¼š**
>
> **æ­¥éª¤ï¼š**
> 1. å°†ä¸¤ä¸ªå½¢çŠ¶ä»å³å¾€å·¦å¯¹é½
> 2. é€ä¸ªæ¯”è¾ƒå¯¹åº”ç»´åº¦
> 3. æ¯ä¸ªç»´åº¦å¿…é¡»ï¼šç›¸ç­‰ OR å…¶ä¸­ä¸€ä¸ªæ˜¯1 OR å…¶ä¸­ä¸€ä¸ªä¸å­˜åœ¨ï¼ˆè§†ä¸º1ï¼‰
>
> **ç¤ºä¾‹åˆ†æï¼š**
>
> ```python
> # æ¡ˆä¾‹1ï¼šâœ… å…¼å®¹
> A: (5, 3, 4)
> B:    (3, 4)
>
> å¯¹é½å¹¶æ¯”è¾ƒï¼š
> A: 5  3  4
> B: 1  3  4  (ç¼ºå¤±ç»´åº¦è§†ä¸º1)
>    â†‘  â†‘  â†‘
>    OK OK OK
> ç»“æœï¼š(5, 3, 4)
>
> # æ¡ˆä¾‹2ï¼šâœ… å…¼å®¹
> A: (3, 1)
> B: (1, 4)
>
> æ¯”è¾ƒï¼š
> A: 3  1
> B: 1  4
>    â†‘  â†‘
>    OK OK (éƒ½æœ‰1ï¼Œå¯æ‰©å±•)
> ç»“æœï¼š(3, 4)
>
> # æ¡ˆä¾‹3ï¼šâŒ ä¸å…¼å®¹
> A: (3, 4)
> B: (3,  )
>
> å¯¹é½ï¼š
> A: 3  4
> B: 1  3  (ç¼ºå¤±ç»´åº¦è§†ä¸º1ï¼Œç„¶åå¯¹é½)
>    â†‘  â†‘
>    3vs1: OK
>    4vs3: âŒ éƒ½ä¸æ˜¯1ï¼Œä¸åŒ¹é…ï¼
>
> é”™è¯¯ï¼šValueError: operands could not be broadcast together
> ```
>
> **å®é™…æ¡ˆä¾‹ï¼ˆå‘é‡æ•°æ®åº“ï¼‰ï¼š**
>
> ```python
> # åœºæ™¯ï¼š5ä¸ªæŸ¥è¯¢ vs 1000ä¸ªæ–‡æ¡£
> queries = np.random.rand(5, 768)     # 5ä¸ªæŸ¥è¯¢å‘é‡
> docs = np.random.rand(1000, 768)     # 1000ä¸ªæ–‡æ¡£å‘é‡
>
> # âŒ ç›´æ¥ç›¸ä¹˜ï¼ˆä¸å…¼å®¹ï¼‰
> queries * docs  # (5, 768) * (1000, 768) âŒ
> # ç»´åº¦1ï¼š5 vs 1000ï¼Œéƒ½ä¸æ˜¯1ï¼Œä¸å…¼å®¹ï¼
>
> # âœ… æ–¹æ³•1ï¼šçŸ©é˜µä¹˜æ³•
> similarities = queries @ docs.T  # (5, 1000)
>
> # âœ… æ–¹æ³•2ï¼šå¹¿æ’­ï¼ˆè°ƒæ•´å½¢çŠ¶ï¼‰
> q = queries[:, None, :]  # (5, 1, 768)
> d = docs[None, :, :]     # (1, 1000, 768)
> # ç°åœ¨å¯ä»¥å¹¿æ’­ï¼š
> # ç»´åº¦1ï¼š5 vs 1 â†’ æ‰©å±•åˆ°5
> # ç»´åº¦2ï¼š1 vs 1000 â†’ æ‰©å±•åˆ°1000
> # ç»´åº¦3ï¼š768 vs 768 â†’ åŒ¹é…
> # ç»“æœï¼š(5, 1000, 768)
> similarities = (q * d).sum(axis=2)  # (5, 1000)
> ```

---

## 6. ã€åŒ–éª¨ç»µæŒã€‘10ä¸ª2åˆ†é’ŸçŸ¥è¯†å¡ç‰‡

### å¡ç‰‡1ï¼šå¹¿æ’­çš„æœ¬è´¨ ğŸ¯

**ä¸€å¥è¯ï¼š** å¹¿æ’­æ˜¯è™šæ‹Ÿæ‰©å±•å°æ•°ç»„ä»¥åŒ¹é…å¤§æ•°ç»„å½¢çŠ¶ï¼Œè€Œä¸å®é™…å¤åˆ¶æ•°æ®

**ä¸¾ä¾‹ï¼š**
```python
matrix = np.ones((1000, 768))
row = np.array([1, 2, ..., 768])

# å¹¿æ’­ï¼šrowè™šæ‹Ÿå¤åˆ¶1000æ¬¡
result = matrix + row

# å†…éƒ¨ï¼šé€šè¿‡strides=(0, 4)å®ç°
# stride=0è¡¨ç¤ºæ²¿è¯¥ç»´åº¦ä¸ç§»åŠ¨ï¼Œé‡å¤ä½¿ç”¨
```

**åº”ç”¨ï¼š** å‘é‡æ•°æ®åº“embeddingå½’ä¸€åŒ–ï¼ŒèŠ‚çœGBçº§å†…å­˜

---

### å¡ç‰‡2ï¼šå¹¿æ’­çš„3æ¡è§„åˆ™ ğŸ“

**è§„åˆ™1ï¼šä»å³å¾€å·¦å¯¹é½**
```
(5, 3, 4)
   (3, 4)  â† å³å¯¹é½
```

**è§„åˆ™2ï¼šç»´åº¦è¦ä¹ˆç›¸ç­‰ï¼Œè¦ä¹ˆå…¶ä¸­ä¸€ä¸ªæ˜¯1**
```
3 vs 3  âœ…
3 vs 1  âœ…  (1å¯æ‰©å±•åˆ°3)
3 vs 2  âŒ  (éƒ½ä¸æ˜¯1ï¼Œä¸åŒ¹é…)
```

**è§„åˆ™3ï¼šç¼ºå¤±ç»´åº¦è§†ä¸º1**
```
(3, 4) vs (4,)
â†’ (3, 4) vs (1, 4)
â†’ âœ… å…¼å®¹ï¼Œç»“æœ(3, 4)
```

---

### å¡ç‰‡3ï¼š`np.newaxis`çš„é­”æ³• âœ¨

**ä¸€å¥è¯ï¼š** ç”¨`np.newaxis`æˆ–`None`æ’å…¥æ–°ç»´åº¦

```python
arr = np.array([1, 2, 3])  # (3,)

# å˜æˆè¡Œå‘é‡
row = arr[None, :]    # (1, 3)
row = arr[np.newaxis, :]  # ç­‰ä»·

# å˜æˆåˆ—å‘é‡
col = arr[:, None]    # (3, 1)
col = arr[:, np.newaxis]  # ç­‰ä»·

# ä¸­é—´æ’å…¥ç»´åº¦
arr3d = arr[None, :, None]  # (1, 3, 1)
```

**åº”ç”¨ï¼š** è°ƒæ•´å½¢çŠ¶ä»¥å®ç°å¹¿æ’­

---

### å¡ç‰‡4ï¼šæ ‡é‡å¹¿æ’­ - æœ€ç®€å• ğŸ”¢

**ä¸€å¥è¯ï¼š** æ ‡é‡è‡ªåŠ¨æ‰©å±•åˆ°ä»»æ„å½¢çŠ¶

```python
arr = np.array([[1, 2],
                [3, 4]])

arr + 10  # 10æ‰©å±•åˆ°(2,2)
# [[11 12]
#  [13 14]]

arr * 2   # 2æ‰©å±•åˆ°(2,2)
# [[2 4]
#  [6 8]]
```

**åº”ç”¨ï¼š** æ‰¹é‡è°ƒæ•´åˆ†æ•°ã€é˜ˆå€¼è¿‡æ»¤

---

### å¡ç‰‡5ï¼šè¡Œ/åˆ—å¹¿æ’­ - æœ€å¸¸ç”¨ ğŸ“Š

**è¡Œå¹¿æ’­ï¼š**
```python
matrix = np.ones((3, 4))
row = np.array([10, 20, 30, 40])  # (4,)

result = matrix + row  # rowæ‰©å±•åˆ°(3,4)
# æ¯ä¸€è¡Œéƒ½åŠ ä¸Š[10, 20, 30, 40]
```

**åˆ—å¹¿æ’­ï¼š**
```python
column = np.array([100, 200, 300])  # (3,)
col = column[:, None]  # å˜æˆ(3, 1)

result = matrix + col  # colæ‰©å±•åˆ°(3,4)
# æ¯ä¸€åˆ—éƒ½åŠ ä¸Šç›¸åº”çš„å€¼
```

**åº”ç”¨ï¼š** ç‰¹å¾å½’ä¸€åŒ–ã€åŠ æƒè®¡ç®—

---

### å¡ç‰‡6ï¼šå¤–ç§¯ - ç”Ÿæˆç½‘æ ¼ ğŸŒ

**ä¸€å¥è¯ï¼š** åˆ©ç”¨å¹¿æ’­è®¡ç®—ä¸¤ä¸ªå‘é‡çš„å¤–ç§¯

```python
x = np.array([1, 2, 3])[:, None]    # (3, 1)
y = np.array([10, 20, 30, 40])[None, :]  # (1, 4)

# å¹¿æ’­ç›¸ä¹˜
outer = x * y  # (3, 4)
# [[10 20 30 40]
#  [20 40 60 80]
#  [30 60 90 120]]
```

**åº”ç”¨ï¼š** ç”Ÿæˆç½‘æ ¼ç‚¹ã€å‚æ•°æœç´¢ç©ºé—´

---

### å¡ç‰‡7ï¼šæˆå¯¹è·ç¦» - æ‰¹é‡è®¡ç®— ğŸ“

**ä¸€å¥è¯ï¼š** åˆ©ç”¨å¹¿æ’­ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰æˆå¯¹è·ç¦»

```python
points = np.array([[1, 2], [3, 4], [5, 6]])  # (3, 2)

# æ‰©å±•ç»´åº¦
p1 = points[:, None, :]  # (3, 1, 2)
p2 = points[None, :, :]  # (1, 3, 2)

# å¹¿æ’­ç›¸å‡
diff = p1 - p2  # (3, 3, 2)

# è®¡ç®—è·ç¦»
distances = np.sqrt((diff ** 2).sum(axis=2))  # (3, 3)
```

**åº”ç”¨ï¼š** èšç±»ã€KNNã€ç›¸ä¼¼åº¦çŸ©é˜µ

---

### å¡ç‰‡8ï¼šæ‰¹é‡å½’ä¸€åŒ– - æ•°æ®é¢„å¤„ç† ğŸ§¹

**ä¸€å¥è¯ï¼š** ç”¨å¹¿æ’­å®ç°Z-scoreæ ‡å‡†åŒ–

```python
data = np.random.rand(1000, 10)  # (1000, 10)

# è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆæ¯åˆ—ï¼‰
mean = data.mean(axis=0)  # (10,)
std = data.std(axis=0)    # (10,)

# æ ‡å‡†åŒ–ï¼ˆå¹¿æ’­ï¼‰
normalized = (data - mean) / std  # (1000, 10)
# meanå’Œstdè‡ªåŠ¨å¹¿æ’­åˆ°(1000, 10)

# éªŒè¯
print(normalized.mean(axis=0))  # æ¥è¿‘0
print(normalized.std(axis=0))   # æ¥è¿‘1
```

**åº”ç”¨ï¼š** æœºå™¨å­¦ä¹ é¢„å¤„ç†ã€embeddingæ ‡å‡†åŒ–

---

### å¡ç‰‡9ï¼šå½¢çŠ¶ä¸å…¼å®¹çš„å¸¸è§é”™è¯¯ âš ï¸

**é”™è¯¯1ï¼šæ··æ·†è¡Œåˆ—**
```python
matrix = np.ones((100, 768))
vec = np.ones((100,))  # æƒ³åŠ åˆ°æ¯åˆ—

# âŒ é”™è¯¯
matrix + vec  # (100, 768) + (100,) â†’ æŠ¥é”™ï¼
# 768 vs 100 ä¸åŒ¹é…

# âœ… æ­£ç¡®
matrix + vec[:, None]  # (100, 768) + (100, 1)
```

**é”™è¯¯2ï¼šæ‰¹é‡æ“ä½œå½¢çŠ¶é”™è¯¯**
```python
queries = np.ones((5, 768))
docs = np.ones((1000, 768))

# âŒ é”™è¯¯
queries * docs  # (5, 768) * (1000, 768) â†’ æŠ¥é”™ï¼

# âœ… æ­£ç¡®
queries @ docs.T  # (5, 1000)
```

---

### å¡ç‰‡10ï¼šæ€§èƒ½ä¼˜åŠ¿ - ä¸ºä»€ä¹ˆå¿« âš¡

**ä¸‰å±‚åŠ é€Ÿï¼š**

1. **æ— å†…å­˜å¤åˆ¶**ï¼š
   ```
   æ‰‹åŠ¨å¤åˆ¶ï¼š(1000, 768) - éœ€å¤åˆ¶mean 1000æ¬¡ â†’ 3MB Ã— 1000 = 3GB
   å¹¿æ’­ï¼šåªå­˜ä¸€ä»½mean â†’ 3KB
   ```

2. **å‘é‡åŒ–è¿ç®—**ï¼š
   ```
   å¾ªç¯ï¼šPythonè§£é‡Šå™¨ Ã— 100ä¸‡æ¬¡
   å¹¿æ’­ï¼š1æ¬¡Pythonè°ƒç”¨ + Cå±‚é¢SIMD
   ```

3. **ç¼“å­˜ä¼˜åŒ–**ï¼š
   ```
   è¿ç»­è®¿é—® â†’ cacheå‘½ä¸­ç‡é«˜ â†’ å¿«2-5å€
   ```

**å®æµ‹ï¼š**
```python
# 100ä¸‡Ã—768å½’ä¸€åŒ–
å¾ªç¯ï¼š30ç§’
å¹¿æ’­ï¼š0.03ç§’
åŠ é€Ÿ1000å€ï¼
```

---

## 7. ã€3ä¸ªæ ¸å¿ƒæ¦‚å¿µã€‘

### æ ¸å¿ƒæ¦‚å¿µ1ï¼šè™šæ‹Ÿæ‰©å±•ï¼ˆStridesæœºåˆ¶ï¼‰ğŸ”„

**å¹¿æ’­ä¸å¤åˆ¶æ•°æ®ï¼Œé€šè¿‡stride=0å®ç°è™šæ‹Ÿé‡å¤**

#### ä»€ä¹ˆæ˜¯Stridesï¼Ÿ

**Strides**ï¼šNumPyæ•°ç»„ä¸­ï¼Œæ¯ä¸ªç»´åº¦ç§»åŠ¨ä¸€ä¸ªä½ç½®éœ€è¦è·³è¿‡çš„å­—èŠ‚æ•°

```python
import numpy as np

arr = np.array([[1, 2, 3],
                [4, 5, 6]], dtype=np.int32)

print(f"å½¢çŠ¶: {arr.shape}")  # (2, 3)
print(f"Strides: {arr.strides}")  # (12, 4)
# ç»´åº¦0ï¼ˆè¡Œï¼‰ï¼šè·³1è¡Œéœ€è·³è¿‡12å­—èŠ‚ï¼ˆ3ä¸ªint32Ã—4å­—èŠ‚ï¼‰
# ç»´åº¦1ï¼ˆåˆ—ï¼‰ï¼šè·³1åˆ—éœ€è·³è¿‡4å­—èŠ‚ï¼ˆ1ä¸ªint32ï¼‰
```

#### å¹¿æ’­å¦‚ä½•åˆ©ç”¨Stridesï¼Ÿ

**å…³é”®ï¼šstride=0è¡¨ç¤ºä¸ç§»åŠ¨ï¼Œé‡å¤è®¿é—®åŒä¸€æ•°æ®**

```python
# ç¤ºä¾‹ï¼šçŸ©é˜µåŠ è¡Œå‘é‡
matrix = np.ones((3, 4), dtype=np.float32)
row = np.array([10, 20, 30, 40], dtype=np.float32)

print(f"matrix strides: {matrix.strides}")  # (16, 4)
print(f"row strides: {row.strides}")        # (4,)

# å¹¿æ’­åï¼Œrowè¢«"è™šæ‹Ÿ"æ‰©å±•æˆ(3, 4)
# å¦‚ä½•å®ç°ï¼Ÿè®¾ç½®rowçš„stridesä¸º(0, 4)ï¼
# stride=0 â†’ æ²¿ç»´åº¦0ä¸ç§»åŠ¨ï¼Œæ€»æ˜¯è®¿é—®åŒä¸€è¡Œ
```

#### å†…éƒ¨æœºåˆ¶æ¼”ç¤º

```python
import numpy as np
from numpy.lib.stride_tricks import as_strided

# åŸå§‹è¡Œå‘é‡
row = np.array([10, 20, 30, 40], dtype=np.float32)
print(f"åŸå§‹row: {row}")
print(f"åŸå§‹strides: {row.strides}")  # (4,)

# æ‰‹åŠ¨åˆ›å»º"å¹¿æ’­"æ•ˆæœï¼ˆæ•™å­¦ç›®çš„ï¼‰
# å°†rowè™šæ‹Ÿæ‰©å±•æˆ3è¡Œ
broadcasted = as_strided(row,
                         shape=(3, 4),      # æ–°å½¢çŠ¶
                         strides=(0, 4))    # stride=0ä¸ç§»åŠ¨
print(f"\nè™šæ‹Ÿæ‰©å±•å:\n{broadcasted}")
# [[10 20 30 40]
#  [10 20 30 40]  â† å®é™…æ²¡æœ‰å¤åˆ¶ï¼Œåªæ˜¯stride=0
#  [10 20 30 40]]

# éªŒè¯ï¼šéƒ½æŒ‡å‘åŒä¸€å†…å­˜
print(f"\næ˜¯å¦å…±äº«å†…å­˜: {np.shares_memory(row, broadcasted)}")  # True

# ä¿®æ”¹rowï¼Œbroadcastedä¹Ÿå˜
row[0] = 999
print(f"\nä¿®æ”¹rowåçš„broadcasted:\n{broadcasted}")
# [[999  20  30  40]
#  [999  20  30  40]
#  [999  20  30  40]]
```

#### æ€§èƒ½ä¼˜åŠ¿

**æ‰‹åŠ¨å¤åˆ¶ vs å¹¿æ’­**

```python
import time

matrix = np.random.rand(10000, 1000).astype(np.float32)
row = np.random.rand(1000).astype(np.float32)

# æ–¹æ³•1ï¼šæ‰‹åŠ¨å¤åˆ¶
start = time.time()
row_repeated = np.tile(row, (10000, 1))  # å®é™…å¤åˆ¶
result1 = matrix + row_repeated
time_copy = time.time() - start

# æ–¹æ³•2ï¼šå¹¿æ’­
start = time.time()
result2 = matrix + row  # è™šæ‹Ÿæ‰©å±•
time_broadcast = time.time() - start

print(f"æ‰‹åŠ¨å¤åˆ¶: {time_copy:.4f}ç§’")
print(f"å¹¿æ’­: {time_broadcast:.4f}ç§’")
print(f"åŠ é€Ÿæ¯”: {time_copy/time_broadcast:.1f}å€")
print(f"å†…å­˜èŠ‚çœ: {row_repeated.nbytes / (1024**2):.2f} MB")
```

**å…¸å‹è¾“å‡ºï¼š**
```
æ‰‹åŠ¨å¤åˆ¶: 0.0234ç§’
å¹¿æ’­: 0.0089ç§’
åŠ é€Ÿæ¯”: 2.6å€
å†…å­˜èŠ‚çœ: 38.15 MB
```

#### å‘é‡æ•°æ®åº“åº”ç”¨

```python
# åœºæ™¯ï¼š100ä¸‡embeddingå½’ä¸€åŒ–
embeddings = np.random.rand(1000000, 768).astype(np.float32)
mean = embeddings.mean(axis=0)  # (768,)

# å¹¿æ’­å‡å‡å€¼
centered = embeddings - mean  # meanè™šæ‹Ÿæ‰©å±•æˆ(1000000, 768)

# å†…å­˜åˆ†æ
print(f"embeddings: {embeddings.nbytes / (1024**3):.2f} GB")
print(f"mean: {mean.nbytes / 1024:.2f} KB")
print(f"result: {centered.nbytes / (1024**3):.2f} GB")
print(f"\nå¦‚æœæ‰‹åŠ¨å¤åˆ¶mean: +2.93 GB")
print(f"å¹¿æ’­èŠ‚çœ: 2.93 GBå†…å­˜ï¼")
```

**å…³é”®ç‚¹ï¼š**
- å¹¿æ’­é€šè¿‡stride=0å®ç°è™šæ‹Ÿé‡å¤
- ä¸å ç”¨é¢å¤–å†…å­˜ï¼ˆé™¤äº†ç»“æœï¼‰
- æ€§èƒ½ä¼˜äºæ‰‹åŠ¨å¤åˆ¶ï¼ˆå°‘ä¸€æ¬¡å†…å­˜åˆ†é…+æ‹·è´ï¼‰

---

### æ ¸å¿ƒæ¦‚å¿µ2ï¼šå½¢çŠ¶å…¼å®¹æ€§ç®—æ³• ğŸ§®

**ç³»ç»ŸåŒ–åˆ¤æ–­ä¸¤ä¸ªæ•°ç»„èƒ½å¦å¹¿æ’­**

#### ç®—æ³•æ­¥éª¤

```python
def broadcast_shapes(shape1, shape2):
    """
    åˆ¤æ–­ä¸¤ä¸ªå½¢çŠ¶èƒ½å¦å¹¿æ’­ï¼Œè¿”å›å¹¿æ’­åçš„å½¢çŠ¶
    """
    # æ­¥éª¤1ï¼šåè½¬å½¢çŠ¶ï¼ˆä»å³å¾€å·¦æ¯”è¾ƒï¼‰
    s1 = list(reversed(shape1))
    s2 = list(reversed(shape2))

    # æ­¥éª¤2ï¼šè¡¥é½çŸ­çš„ï¼ˆç¼ºå¤±ç»´åº¦è§†ä¸º1ï¼‰
    max_len = max(len(s1), len(s2))
    s1 += [1] * (max_len - len(s1))
    s2 += [1] * (max_len - len(s2))

    # æ­¥éª¤3ï¼šé€ç»´åº¦æ£€æŸ¥å…¼å®¹æ€§
    result = []
    for d1, d2 in zip(s1, s2):
        if d1 == d2:
            result.append(d1)  # ç›¸ç­‰ï¼Œå–ä»»æ„ä¸€ä¸ª
        elif d1 == 1:
            result.append(d2)  # d1æ˜¯1ï¼Œæ‰©å±•åˆ°d2
        elif d2 == 1:
            result.append(d1)  # d2æ˜¯1ï¼Œæ‰©å±•åˆ°d1
        else:
            raise ValueError(f"ä¸å…¼å®¹: {d1} vs {d2}")

    # æ­¥éª¤4ï¼šåè½¬å›æ¥
    return tuple(reversed(result))

# æµ‹è¯•
print(broadcast_shapes((3, 4), (4,)))       # (3, 4)
print(broadcast_shapes((3, 1), (1, 4)))     # (3, 4)
print(broadcast_shapes((5, 3, 4), (4,)))    # (5, 3, 4)
try:
    print(broadcast_shapes((3, 4), (3,)))   # æŠ¥é”™
except ValueError as e:
    print(f"é”™è¯¯: {e}")
```

#### å¯è§†åŒ–å¯¹æ¯”

```python
import numpy as np

def visualize_broadcast(shape1, shape2):
    """å¯è§†åŒ–å¹¿æ’­è¿‡ç¨‹"""
    print(f"\nå½¢çŠ¶1: {shape1}")
    print(f"å½¢çŠ¶2: {shape2}\n")

    # æ­¥éª¤1ï¼šå³å¯¹é½
    s1 = list(shape1)
    s2 = list(shape2)
    max_len = max(len(s1), len(s2))

    s1_padded = [1] * (max_len - len(s1)) + s1
    s2_padded = [1] * (max_len - len(s2)) + s2

    print("å³å¯¹é½å:")
    print(f"  å½¢çŠ¶1: {s1_padded}")
    print(f"  å½¢çŠ¶2: {s2_padded}\n")

    # æ­¥éª¤2ï¼šé€ç»´åº¦æ¯”è¾ƒ
    print("é€ç»´åº¦æ£€æŸ¥:")
    result = []
    for i, (d1, d2) in enumerate(zip(s1_padded, s2_padded)):
        if d1 == d2:
            status = f"âœ… {d1}=={d2}"
            result.append(d1)
        elif d1 == 1:
            status = f"âœ… {d1}â†’{d2} (æ‰©å±•)"
            result.append(d2)
        elif d2 == 1:
            status = f"âœ… {d2}â†’{d1} (æ‰©å±•)"
            result.append(d1)
        else:
            status = f"âŒ {d1}â‰ {d2} (ä¸å…¼å®¹)"
            result.append(None)

        print(f"  ç»´åº¦{i}: {status}")

    # ç»“æœ
    if None in result:
        print(f"\nç»“æœ: âŒ ä¸èƒ½å¹¿æ’­")
    else:
        print(f"\nç»“æœ: âœ… å¹¿æ’­åå½¢çŠ¶ {tuple(result)}")

# ç¤ºä¾‹
visualize_broadcast((3, 4), (4,))
visualize_broadcast((3, 1), (1, 4))
visualize_broadcast((3, 4), (3,))
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
å½¢çŠ¶1: (3, 4)
å½¢çŠ¶2: (4,)

å³å¯¹é½å:
  å½¢çŠ¶1: [3, 4]
  å½¢çŠ¶2: [1, 4]

é€ç»´åº¦æ£€æŸ¥:
  ç»´åº¦0: âœ… 1â†’3 (æ‰©å±•)
  ç»´åº¦1: âœ… 4==4

ç»“æœ: âœ… å¹¿æ’­åå½¢çŠ¶ (3, 4)
```

#### å¸¸è§æ¨¡å¼é€ŸæŸ¥è¡¨

| å½¢çŠ¶1 | å½¢çŠ¶2 | èƒ½å¦å¹¿æ’­ | ç»“æœå½¢çŠ¶ | è¯´æ˜ |
|-------|-------|---------|---------|------|
| (3, 4) | (4,) | âœ… | (3, 4) | è¡Œå¹¿æ’­ |
| (3, 4) | (3, 1) | âœ… | (3, 4) | åˆ—å¹¿æ’­ |
| (3, 1) | (1, 4) | âœ… | (3, 4) | åŒå‘æ‰©å±• |
| (5, 3, 4) | (3, 4) | âœ… | (5, 3, 4) | é«˜ç»´æ‰©å±• |
| (5, 3, 4) | (4,) | âœ… | (5, 3, 4) | æœ«ç»´åŒ¹é… |
| (3, 4) | (3,) | âŒ | - | æ— æ³•å¯¹é½ |
| (3, 4) | (5, 4) | âŒ | - | 3â‰ 5ä¸”éƒ½â‰ 1 |

#### å‘é‡æ•°æ®åº“åº”ç”¨

```python
# åœºæ™¯åˆ†æï¼šæ‰¹é‡æŸ¥è¯¢

# æƒ…å†µ1ï¼šå•æŸ¥è¯¢ vs å¤šæ–‡æ¡£ âœ…
query = np.random.rand(768)         # (768,)
docs = np.random.rand(1000, 768)    # (1000, 768)

# èƒ½å¦ç‚¹ä¹˜ï¼Ÿ
# query: (768,) â†’ (1, 768) å¯¹é½
# docs:   (1000, 768)
# ä½†ç‚¹ç§¯ä¸æ˜¯é€å…ƒç´ ï¼Œç”¨çŸ©é˜µä¹˜æ³•ï¼š
sims = docs @ query  # (1000,) âœ…

# æƒ…å†µ2ï¼šå¤šæŸ¥è¯¢ vs å¤šæ–‡æ¡£
queries = np.random.rand(5, 768)    # (5, 768)
docs = np.random.rand(1000, 768)    # (1000, 768)

# ä¸èƒ½ç›´æ¥å¹¿æ’­
# queries * docs  # (5, 768) * (1000, 768) âŒ

# æ–¹æ¡ˆï¼šçŸ©é˜µä¹˜æ³•
sims = queries @ docs.T  # (5, 1000) âœ…
```

---

### æ ¸å¿ƒæ¦‚å¿µ3ï¼šå¹¿æ’­çš„è®¡ç®—å¤æ‚åº¦ ğŸ“Š

**ç†è§£å¹¿æ’­ä¸æ”¹å˜æ—¶é—´å¤æ‚åº¦ï¼Œä½†æ”¹å˜å¸¸æ•°å› å­**

#### æ—¶é—´å¤æ‚åº¦åˆ†æ

**åŸºæœ¬åŸåˆ™ï¼š** å¹¿æ’­åçš„è¿ç®—å¤æ‚åº¦ = å¹¿æ’­åå½¢çŠ¶çš„å…ƒç´ æ€»æ•°

```python
# ç¤ºä¾‹ï¼š(1000, 768) + (768,)
matrix = np.ones((1000, 768))
row = np.ones((768,))

result = matrix + row
# å¹¿æ’­åï¼š(1000, 768) + (1000, 768)
# è¿ç®—æ¬¡æ•°ï¼š1000 Ã— 768 = 768,000æ¬¡åŠ æ³•

# æ—¶é—´å¤æ‚åº¦ï¼šO(n Ã— m)ï¼Œå…¶ä¸­n=1000, m=768
```

**å¯¹æ¯”æ‰‹åŠ¨å¾ªç¯ï¼š**
```python
# å¾ªç¯ç‰ˆæœ¬
for i in range(1000):
    for j in range(768):
        result[i, j] = matrix[i, j] + row[j]
# å¤æ‚åº¦ï¼šO(n Ã— m)  - ç›¸åŒï¼

# ä½†å¹¿æ’­ç‰ˆæœ¬æœ‰å¸¸æ•°å› å­ä¼˜åŠ¿ï¼š
# - æ— Pythonè§£é‡Šå™¨å¼€é”€ï¼ˆå¿«100å€ï¼‰
# - SIMDå¹¶è¡Œï¼ˆå¿«4-8å€ï¼‰
# - ç¼“å­˜ä¼˜åŒ–ï¼ˆå¿«2-5å€ï¼‰
# æ€»æå‡ï¼š100Ã—4Ã—2 = 800å€
```

#### ç©ºé—´å¤æ‚åº¦åˆ†æ

**å¹¿æ’­èŠ‚çœå†…å­˜ï¼Œä½†ç»“æœä»éœ€å®Œæ•´ç©ºé—´**

```python
# (1000, 768) - (768,)
matrix = np.ones((1000, 768), dtype=np.float32)
mean = np.ones((768,), dtype=np.float32)

# ç©ºé—´å ç”¨åˆ†æ
print(f"matrix: {matrix.nbytes / (1024**2):.2f} MB")  # 2.93 MB
print(f"mean: {mean.nbytes / 1024:.2f} KB")           # 3 KB

# å¹¿æ’­è¿ç®—
result = matrix - mean

print(f"result: {result.nbytes / (1024**2):.2f} MB")  # 2.93 MB

# æ€»ç©ºé—´ï¼š2.93 + 0.003 + 2.93 â‰ˆ 5.86 MB

# å¦‚æœæ‰‹åŠ¨å¤åˆ¶meanï¼š
mean_repeated = np.tile(mean, (1000, 1))
print(f"æ‰‹åŠ¨å¤åˆ¶: +{mean_repeated.nbytes / (1024**2):.2f} MB")  # +2.93 MB
# æ€»ç©ºé—´ï¼š2.93 + 2.93 + 2.93 â‰ˆ 8.79 MB

# èŠ‚çœï¼š8.79 - 5.86 = 2.93 MB (33%)
```

#### æ‰¹é‡æ“ä½œçš„å¤æ‚åº¦

**æˆå¯¹è·ç¦»çŸ©é˜µï¼šO(nÂ²m)**

```python
# nä¸ªç‚¹ï¼Œæ¯ä¸ªmç»´
n, m = 1000, 768
points = np.random.rand(n, m).astype(np.float32)

# è®¡ç®—æ‰€æœ‰æˆå¯¹è·ç¦»

# æ–¹æ³•1ï¼šåŒé‡å¾ªç¯ - O(nÂ²m)
start = time.time()
dist_loop = np.zeros((n, n))
for i in range(n):
    for j in range(n):
        dist_loop[i, j] = np.sqrt(((points[i] - points[j]) ** 2).sum())
time_loop = time.time() - start

# æ–¹æ³•2ï¼šå¹¿æ’­ - O(nÂ²m)ï¼ˆå¤æ‚åº¦ç›¸åŒï¼‰
start = time.time()
p1 = points[:, None, :]  # (n, 1, m)
p2 = points[None, :, :]  # (1, n, m)
diff = p1 - p2           # (n, n, m) - å¹¿æ’­
dist_broadcast = np.sqrt((diff ** 2).sum(axis=2))  # (n, n)
time_broadcast = time.time() - start

print(f"å¾ªç¯: {time_loop:.4f}ç§’, å¤æ‚åº¦O(nÂ²m) = O({n**2 * m})")
print(f"å¹¿æ’­: {time_broadcast:.4f}ç§’, å¤æ‚åº¦O(nÂ²m) = O({n**2 * m})")
print(f"åŠ é€Ÿæ¯”: {time_loop/time_broadcast:.1f}å€")
print(f"(å¤æ‚åº¦ç›¸åŒï¼Œä½†å¸¸æ•°å› å­å·®å¼‚å·¨å¤§)")
```

**å…¸å‹è¾“å‡ºï¼š**
```
å¾ªç¯: 45.2341ç§’, å¤æ‚åº¦O(nÂ²m) = O(768000000)
å¹¿æ’­: 0.0342ç§’, å¤æ‚åº¦O(nÂ²m) = O(768000000)
åŠ é€Ÿæ¯”: 1322.4å€
(å¤æ‚åº¦ç›¸åŒï¼Œä½†å¸¸æ•°å› å­å·®å¼‚å·¨å¤§)
```

#### å‘é‡æ•°æ®åº“çš„å¤æ‚åº¦ä¼˜åŒ–

**åœºæ™¯ï¼škä¸ªæŸ¥è¯¢ vs nä¸ªæ–‡æ¡£ï¼Œæ¯ä¸ªmç»´**

```python
k, n, m = 10, 1000000, 768

queries = np.random.rand(k, m).astype(np.float32)
docs = np.random.rand(n, m).astype(np.float32)

# æ–¹æ³•1ï¼šåŒé‡å¾ªç¯ - O(knm)
# for i in range(k):
#     for j in range(n):
#         sim = sum(queries[i] * docs[j])
# æ—¶é—´ï¼š10 Ã— 1M Ã— 768 Ã— (Pythonå¼€é”€) â‰ˆ å‡ åˆ†é’Ÿ

# æ–¹æ³•2ï¼šçŸ©é˜µä¹˜æ³• - O(knm)ï¼ˆå¤æ‚åº¦ç›¸åŒï¼‰
sims = queries @ docs.T  # (k, n)
# æ—¶é—´ï¼š10 Ã— 1M Ã— 768 Ã— (C+SIMD) â‰ˆ 0.5ç§’

# å¤æ‚åº¦éƒ½æ˜¯O(knm)ï¼Œä½†ï¼š
# å¾ªç¯ï¼šO(knm) Ã— 100ns (Python) â‰ˆ 77ç§’
# çŸ©é˜µä¹˜æ³•ï¼šO(knm) Ã— 0.1ns (SIMD) â‰ˆ 0.08ç§’
# åŠ é€Ÿçº¦1000å€ï¼
```

**å…³é”®ç»“è®ºï¼š**
- å¹¿æ’­ä¸æ”¹å˜Big-Oå¤æ‚åº¦
- ä½†æ”¹å˜å¸¸æ•°å› å­ï¼ˆ100-1000å€ï¼‰
- åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šï¼Œå¸¸æ•°å› å­è‡³å…³é‡è¦

---

## 8. ã€1ä¸ªç±»æ¯”ã€‘ç”¨å‰ç«¯å¼€å‘ç†è§£å¹¿æ’­

### ç±»æ¯”1ï¼šå¹¿æ’­ = CSSç»§æ‰¿ ğŸ¨

#### çˆ¶æ ·å¼è‡ªåŠ¨åº”ç”¨åˆ°å­å…ƒç´ 

```css
/* CSSç»§æ‰¿ï¼ˆç±»ä¼¼å¹¿æ’­ï¼‰ */
.container {
  color: red;        /* å®šä¹‰ä¸€æ¬¡ */
  font-size: 14px;
}

/* è‡ªåŠ¨åº”ç”¨åˆ°æ‰€æœ‰å­å…ƒç´  */
.container .child1 { /* color: redç»§æ‰¿ */ }
.container .child2 { /* color: redç»§æ‰¿ */ }
.container .child3 { /* color: redç»§æ‰¿ */ }
```

```python
# NumPyå¹¿æ’­ï¼ˆç­‰ä»·ï¼‰
children = np.array([[...], [...], [...]])  # å¤šä¸ªå­å…ƒç´ 
parent_style = np.array([red, 14px])        # çˆ¶æ ·å¼

# å¹¿æ’­åº”ç”¨
result = children + parent_style  # parent_styleè‡ªåŠ¨æ‰©å±•
```

**ç›¸ä¼¼ç‚¹ï¼š**
- éƒ½æ˜¯"å®šä¹‰ä¸€æ¬¡ï¼Œåº”ç”¨å¤šæ¬¡"
- éƒ½ä¸å®é™…å¤åˆ¶æ•°æ®
- éƒ½èŠ‚çœç©ºé—´ï¼ˆCSSä¸é‡å¤å†™æ ·å¼ï¼ŒNumPyä¸é‡å¤å­˜æ•°æ®ï¼‰

---

### ç±»æ¯”2ï¼šå¹¿æ’­ = React Propså‘ä¸‹ä¼ é€’ âš›ï¸

#### Propsè‡ªåŠ¨ä¼ ç»™æ‰€æœ‰å­ç»„ä»¶

```javascript
// Reactç»„ä»¶
function Parent() {
  const config = { theme: 'dark', fontSize: 14 };  // å®šä¹‰ä¸€æ¬¡

  return (
    <div>
      <Child config={config} />  {/* ä¼ é€’ */}
      <Child config={config} />  {/* ä¼ é€’ */}
      <Child config={config} />  {/* ä¼ é€’ */}
    </div>
  );
  // configå¯¹è±¡åªå­˜ä¸€ä»½ï¼Œå¤šä¸ªå­ç»„ä»¶å¼•ç”¨åŒä¸€ä¸ª
}
```

```python
# NumPyå¹¿æ’­
children = np.random.rand(3, 10)  # 3ä¸ªå­ç»„ä»¶ï¼Œ10ä¸ªå±æ€§
config = np.array([...])          # é…ç½®ï¼ˆä¸€ä»½ï¼‰

# å¹¿æ’­
result = children + config  # configä¼ é€’ç»™æ‰€æœ‰å­ç»„ä»¶
```

---

### ç±»æ¯”3ï¼šå½¢çŠ¶å…¼å®¹ = TypeScriptç±»å‹å…¼å®¹ ğŸ“

#### TypeScriptçš„ç»“æ„åŒ–ç±»å‹ç³»ç»Ÿ

```typescript
// TypeScriptç±»å‹å…¼å®¹
interface Small {
  x: number;
}

interface Large {
  x: number;
  y: number;
}

function process(obj: Large) {
  console.log(obj.x, obj.y);
}

const small: Small = { x: 1 };
// process(small);  // âŒ ç±»å‹ä¸å…¼å®¹ï¼ˆç¼ºå°‘yï¼‰

const large: Large = { x: 1, y: 2 };
process(large);     // âœ… ç±»å‹å…¼å®¹
```

```python
# NumPyå¹¿æ’­å…¼å®¹æ€§
small = np.ones((3,))     # "ç¼ºå°‘"ä¸€ä¸ªç»´åº¦
large = np.ones((4, 3))

# result = small + large  # âœ… å…¼å®¹ï¼ˆsmallæ‰©å±•ï¼‰

incompatible = np.ones((4,))  # ç»´åº¦ä¸åŒ¹é…
# result = large + incompatible  # âŒ ä¸å…¼å®¹
```

**ç›¸ä¼¼ç‚¹ï¼š**
- éƒ½æœ‰ä¸¥æ ¼çš„å…¼å®¹è§„åˆ™
- å°ç±»å‹å¯ä»¥æ‰©å±•åˆ°å¤§ç±»å‹ï¼ˆæŸäº›æƒ…å†µä¸‹ï¼‰
- ä¸å…¼å®¹æ—¶æ˜ç¡®æŠ¥é”™

---

### ç±»æ¯”4ï¼šè™šæ‹Ÿæ‰©å±• = è™šæ‹ŸDOMçš„å¤ç”¨ ğŸ”„

```javascript
// Reactè™šæ‹ŸDOMï¼šå¤ç”¨èŠ‚ç‚¹è€Œéåˆ›å»ºæ–°èŠ‚ç‚¹
const VirtualList = ({ items, ItemComponent }) => {
  // åªæ¸²æŸ“å¯è§çš„10ä¸ªé¡¹ï¼Œä½†æœ‰1000ä¸ªæ•°æ®
  // ä¸æ˜¯åˆ›å»º1000ä¸ªDOMèŠ‚ç‚¹ï¼Œè€Œæ˜¯å¤ç”¨10ä¸ªèŠ‚ç‚¹
  const visibleItems = items.slice(scrollTop, scrollTop + 10);

  return visibleItems.map((item, index) => (
    <ItemComponent key={index} data={item} />
    // æ»šåŠ¨æ—¶å¤ç”¨è¿™äº›èŠ‚ç‚¹ï¼Œåªæ›´æ–°data
  ));
};
```

```python
# NumPyå¹¿æ’­ï¼šè™šæ‹Ÿæ‰©å±•è€Œéå®é™…å¤åˆ¶
matrix = np.ones((1000, 768))
row = np.ones((768,))

# ä¸æ˜¯å¤åˆ¶row 1000æ¬¡ï¼Œè€Œæ˜¯è™šæ‹Ÿé‡å¤è®¿é—®
result = matrix + row  # rowé€šè¿‡stride=0å®ç°è™šæ‹Ÿå¤åˆ¶
```

**ç›¸ä¼¼ç‚¹ï¼š**
- éƒ½æ˜¯"å¤ç”¨"è€Œé"å¤åˆ¶"
- éƒ½èŠ‚çœå†…å­˜
- éƒ½æå‡æ€§èƒ½

---

### ç±»æ¯”5ï¼šæ‰¹é‡æ“ä½œ = æ•°æ®åº“æ‰¹é‡æ’å…¥ ğŸ—„ï¸

```sql
-- âŒ æ…¢ï¼šé€æ¡æ’å…¥
INSERT INTO users VALUES (1, 'Alice');
INSERT INTO users VALUES (2, 'Bob');
INSERT INTO users VALUES (3, 'Charlie');
-- 3æ¬¡æ•°æ®åº“è°ƒç”¨ï¼Œæ…¢

-- âœ… å¿«ï¼šæ‰¹é‡æ’å…¥
INSERT INTO users VALUES
  (1, 'Alice'),
  (2, 'Bob'),
  (3, 'Charlie');
-- 1æ¬¡æ•°æ®åº“è°ƒç”¨ï¼Œå¿«10-100å€
```

```python
# NumPyå¹¿æ’­ï¼ˆç±»ä¼¼æ‰¹é‡æ“ä½œï¼‰
# âŒ æ…¢ï¼šé€ä¸ªæ“ä½œ
for i in range(len(matrix)):
    matrix[i] = matrix[i] + row

# âœ… å¿«ï¼šæ‰¹é‡æ“ä½œï¼ˆå¹¿æ’­ï¼‰
matrix = matrix + row  # ä¸€æ¬¡æ“ä½œï¼Œå¿«100å€
```

---

### ç±»æ¯”æ€»ç»“è¡¨ ğŸ¯

| NumPyæ¦‚å¿µ | å‰ç«¯ç±»æ¯” | å…³é”®ç›¸ä¼¼ç‚¹ |
|----------|---------|-----------|
| å¹¿æ’­ | CSSç»§æ‰¿ | å®šä¹‰ä¸€æ¬¡ï¼Œåº”ç”¨å¤šæ¬¡ |
| è™šæ‹Ÿæ‰©å±• | è™šæ‹ŸDOMå¤ç”¨ | å¤ç”¨è€Œéå¤åˆ¶ |
| å½¢çŠ¶å…¼å®¹ | TSç±»å‹å…¼å®¹ | ä¸¥æ ¼çš„å…¼å®¹è§„åˆ™ |
| æ‰¹é‡æ“ä½œ | æ‰¹é‡æ•°æ®åº“æ“ä½œ | å‡å°‘è°ƒç”¨æ¬¡æ•° |
| Propsä¼ é€’ | React Props | å¼•ç”¨åŒä¸€æ•°æ® |
| æ ‡é‡å¹¿æ’­ | å…¨å±€CSSå˜é‡ | å…¨å±€é…ç½®åº”ç”¨åˆ°æ‰€æœ‰ |

---

## 9. ã€ç¬¬ä¸€æ€§åŸç†ã€‘

### å¹¿æ’­æœºåˆ¶çš„ç¬¬ä¸€æ€§åŸç† ğŸ¯

#### 1. æœ€åŸºç¡€çš„é—®é¢˜

**æ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•é«˜æ•ˆåœ°å¯¹å¤§é‡æ•°æ®æ‰§è¡Œç®€å•é‡å¤æ“ä½œï¼Ÿ**

```
ç°å®éœ€æ±‚ï¼š
- 1000ä¸ªå‘é‡ï¼Œæ¯ä¸ªéƒ½è¦å‡å»åŒä¸€ä¸ªå‡å€¼å‘é‡
- 100ä¸‡ä¸ªembeddingï¼Œæ¯ä¸ªéƒ½è¦é™¤ä»¥åŒä¸€ä¸ªæ ‡å‡†å·®å‘é‡

æœ´ç´ æ–¹æ¡ˆï¼š
- å¤åˆ¶å‡å€¼å‘é‡1000æ¬¡ â†’ æµªè´¹å†…å­˜
- å¾ªç¯1000æ¬¡å‡æ³• â†’ æµªè´¹æ—¶é—´

æ ¹æœ¬çŸ›ç›¾ï¼š
- æ“ä½œç®€å•ï¼ˆå‡æ³•ï¼‰ä¸”é‡å¤
- ä½†æ•°æ®é‡å·¨å¤§ï¼ˆç™¾ä¸‡çº§ï¼‰
```

---

#### 2. ç¬¬ä¸€æ€§åŸç†çš„æ´å¯Ÿ

**æ´å¯Ÿ1ï¼šé‡å¤çš„æ“ä½œä¸éœ€è¦é‡å¤çš„æ•°æ®**

```
ä¼ ç»Ÿæ€ç»´ï¼š
è¦å¯¹1000ä¸ªå‘é‡éƒ½å‡å»mean â†’ éœ€è¦1000ä»½mean

ç¬¬ä¸€æ€§åŸç†æ€è€ƒï¼š
çœŸçš„éœ€è¦1000ä»½meanå—ï¼Ÿ
â†’ ä¸éœ€è¦ï¼æ¯æ¬¡éƒ½ç”¨åŒä¸€ä¸ªmeanå°±è¡Œ

å…³é”®ï¼š
- æ“ä½œæ˜¯é‡å¤çš„ï¼ˆéƒ½æ˜¯å‡æ³•ï¼‰
- æ•°æ®ä¸éœ€è¦é‡å¤ï¼ˆmeanåªéœ€ä¸€ä»½ï¼‰
```

**æ´å¯Ÿ2ï¼šè®¡ç®—æœºå¯ä»¥ç”¨"å‡è£…"ä»£æ›¿"å®é™…"**

```
æ‰‹åŠ¨å¤åˆ¶ï¼š
mean_repeated = [mean] * 1000  # å®é™…åˆ›å»º1000ä»½

è™šæ‹Ÿæ‰©å±•ï¼š
"å‡è£…"æœ‰1000ä»½meanï¼Œä½†å®é™…åªå­˜ä¸€ä»½
é€šè¿‡stride=0å®ç°ï¼š
- stride=0 â†’ ä¸ç§»åŠ¨æŒ‡é’ˆ
- é‡å¤è®¿é—®åŒä¸€ä¸ªmean
```

---

#### 3. å¹¿æ’­çš„ä¸‰å±‚ä»·å€¼

##### ä»·å€¼1ï¼šå†…å­˜æ•ˆç‡ï¼ˆSpace Efficiencyï¼‰

```python
# åœºæ™¯ï¼š100ä¸‡Ã—768ç»´embeddingå‡å»å‡å€¼
embeddings = np.random.rand(1000000, 768).astype(np.float32)
mean = embeddings.mean(axis=0)  # (768,)

# æ–¹æ¡ˆ1ï¼šæ‰‹åŠ¨å¤åˆ¶
mean_repeated = np.tile(mean, (1000000, 1))  # å¤åˆ¶100ä¸‡æ¬¡
# å†…å­˜ï¼š768 Ã— 100ä¸‡ Ã— 4å­—èŠ‚ = 2.93 GB

# æ–¹æ¡ˆ2ï¼šå¹¿æ’­
result = embeddings - mean  # è™šæ‹Ÿæ‰©å±•ï¼Œä¸å¤åˆ¶
# é¢å¤–å†…å­˜ï¼š0 GBï¼ˆåªæœ‰ç»“æœå 2.93 GBï¼‰

# èŠ‚çœï¼š2.93 GB (50%å†…å­˜)
```

---

##### ä»·å€¼2ï¼šè®¡ç®—æ€§èƒ½ï¼ˆPerformanceï¼‰

```python
# æ–¹æ¡ˆ1ï¼šå¾ªç¯
for i in range(1000000):
    for j in range(768):
        result[i, j] = embeddings[i, j] - mean[j]
# æ¯æ¬¡å¾ªç¯ï¼šPythonè§£é‡Šå™¨å¼€é”€ + è¿ç®—
# æ€»æ—¶é—´ï¼š100ä¸‡Ã—768Ã—(100ns + 1ns) â‰ˆ 77ç§’

# æ–¹æ¡ˆ2ï¼šå¹¿æ’­
result = embeddings - mean
# ä¸€æ¬¡Pythonè°ƒç”¨ + Cå±‚é¢å¾ªç¯ + SIMD
# æ€»æ—¶é—´ï¼š1æ¬¡è°ƒç”¨ + (100ä¸‡Ã—768Ã—0.1ns) â‰ˆ 0.08ç§’

# åŠ é€Ÿï¼š77 / 0.08 â‰ˆ 960å€
```

---

##### ä»·å€¼3ï¼šä»£ç ç®€æ´ï¼ˆClarityï¼‰

```python
# å¾ªç¯ç‰ˆæœ¬ï¼ˆ10è¡Œï¼‰
result = np.zeros_like(embeddings)
mean = embeddings.mean(axis=0)
for i in range(len(embeddings)):
    for j in range(len(mean)):
        result[i, j] = embeddings[i, j] - mean[j]

# å¹¿æ’­ç‰ˆæœ¬ï¼ˆ1è¡Œï¼‰
result = embeddings - embeddings.mean(axis=0)

# æ›´å°‘çš„ä»£ç  = æ›´å°‘çš„bug = æ›´æ˜“ç»´æŠ¤
```

---

#### 4. ä»ç¬¬ä¸€æ€§åŸç†æ¨å¯¼å‘é‡æ•°æ®åº“

**æ¨ç†é“¾ï¼š**

```
1. å‘é‡æ•°æ®åº“éœ€è¦æ‰¹é‡å¤„ç†embedding
   â†“ ä¾‹ï¼šå½’ä¸€åŒ–ã€ç›¸ä¼¼åº¦è®¡ç®—ã€è·ç¦»åº¦é‡

2. Embeddingé€šå¸¸ç™¾ä¸‡çº§ï¼Œ768-1536ç»´
   â†“ æ•°æ®é‡ï¼š100ä¸‡Ã—768Ã—4å­—èŠ‚ = 3GB

3. éœ€è¦å¯¹æ¯ä¸ªembeddingåº”ç”¨ç›¸åŒæ“ä½œ
   â†“ ä¾‹ï¼šå‡å»å‡å€¼ã€é™¤ä»¥æ ‡å‡†å·®ã€è®¡ç®—ç‚¹ç§¯

4. å¦‚æœæ‰‹åŠ¨å¤åˆ¶å‚æ•°ï¼ˆmean/std/queryï¼‰
   â†“ å†…å­˜ï¼šÃ—2ï¼ˆéœ€è¦6GBè€Œé3GBï¼‰
   â†“ æ—¶é—´ï¼šé¢å¤–çš„å¤åˆ¶å¼€é”€

5. å¹¿æ’­æœºåˆ¶ï¼šè™šæ‹Ÿæ‰©å±•ï¼Œä¸å®é™…å¤åˆ¶
   â†“ å†…å­˜ï¼šèŠ‚çœ50%
   â†“ æ—¶é—´ï¼šæ— å¤åˆ¶å¼€é”€

6. å®æ—¶æŸ¥è¯¢è¦æ±‚<100ms
   â†“ å¿…é¡»ç”¨å¹¿æ’­ + å‘é‡åŒ–
   â†“ å¾ªç¯ï¼šå‡ ç§’ï¼ˆä¸å¯æ¥å—ï¼‰
   â†“ å¹¿æ’­ï¼šå‡ åæ¯«ç§’ï¼ˆå¯æ¥å—ï¼‰

7. å¹¿æ’­æ˜¯å‘é‡æ•°æ®åº“é«˜æ€§èƒ½çš„åŸºç¡€ï¼
```

---

#### 5. å®é™…æ¡ˆä¾‹ï¼šä»åŸå‹åˆ°ç”Ÿäº§

**é˜¶æ®µ1ï¼šæœ´ç´ å®ç°ï¼ˆæ…¢ä¸”å å†…å­˜ï¼‰**

```python
def normalize_naive(embeddings):
    """æœ´ç´ å½’ä¸€åŒ–"""
    mean = embeddings.mean(axis=0)
    std = embeddings.std(axis=0)

    # æ‰‹åŠ¨å¤åˆ¶
    mean_repeated = np.tile(mean, (len(embeddings), 1))
    std_repeated = np.tile(std, (len(embeddings), 1))

    # å½’ä¸€åŒ–
    return (embeddings - mean_repeated) / std_repeated

# 100ä¸‡embeddingï¼š6GBå†…å­˜ï¼Œ0.5ç§’
```

**é˜¶æ®µ2ï¼šå¹¿æ’­ä¼˜åŒ–ï¼ˆå¿«ä¸”çœå†…å­˜ï¼‰**

```python
def normalize_broadcast(embeddings):
    """å¹¿æ’­å½’ä¸€åŒ–"""
    mean = embeddings.mean(axis=0)
    std = embeddings.std(axis=0)

    # å¹¿æ’­
    return (embeddings - mean) / std

# 100ä¸‡embeddingï¼š3GBå†…å­˜ï¼Œ0.1ç§’
```

**é˜¶æ®µ3ï¼šç”Ÿäº§çº§ä¼˜åŒ–ï¼ˆæœ€å¿«ï¼‰**

```python
def normalize_production(embeddings):
    """ç”Ÿäº§çº§å½’ä¸€åŒ–"""
    # ä½¿ç”¨float32èŠ‚çœå†…å­˜
    embeddings = embeddings.astype(np.float32)

    # å¹¿æ’­å½’ä¸€åŒ–
    mean = embeddings.mean(axis=0, keepdims=True)  # (1, 768)
    std = embeddings.std(axis=0, keepdims=True)    # (1, 768)

    return (embeddings - mean) / (std + 1e-8)  # é¿å…é™¤0

# 100ä¸‡embeddingï¼š1.5GBå†…å­˜ï¼Œ0.05ç§’
```

---

#### 6. ä¸€å¥è¯æ€»ç»“

**å¹¿æ’­æœºåˆ¶é€šè¿‡è™šæ‹Ÿæ‰©å±•å°æ•°ç»„è€Œéå®é™…å¤åˆ¶ï¼Œä½¿å¾—æ‰¹é‡æ“ä½œåœ¨èŠ‚çœå†…å­˜çš„åŒæ—¶ä¿æŒå‘é‡åŒ–æ€§èƒ½ï¼Œæ˜¯NumPyå’Œå‘é‡æ•°æ®åº“é«˜æ•ˆå¤„ç†å¤§è§„æ¨¡æ•°æ®çš„æ ¸å¿ƒæœºåˆ¶ã€‚**

---

## 10. ã€ä¸€å¥è¯æ€»ç»“ã€‘

**å¹¿æ’­æœºåˆ¶æ˜¯NumPyé€šè¿‡è™šæ‹Ÿæ‰©å±•ä¸åŒå½¢çŠ¶æ•°ç»„ä»¥è¿›è¡Œè¿ç®—çš„è§„åˆ™ï¼ŒåŸºäºstride=0çš„å†…å­˜å¤ç”¨æŠ€æœ¯ï¼Œåœ¨ä¸å®é™…å¤åˆ¶æ•°æ®çš„æƒ…å†µä¸‹å®ç°æ‰¹é‡æ“ä½œï¼ŒèŠ‚çœ50%ä»¥ä¸Šå†…å­˜ï¼Œé…åˆå‘é‡åŒ–è¿ç®—å¯æå‡100-1000å€æ€§èƒ½ï¼Œæ˜¯å‘é‡æ•°æ®åº“é«˜æ•ˆå¤„ç†ç™¾ä¸‡çº§embeddingå½’ä¸€åŒ–ã€ç›¸ä¼¼åº¦è®¡ç®—ç­‰æ‰¹é‡æ“ä½œçš„åŸºç¡€ã€‚**

---

## é™„å½•ï¼šå¿«é€Ÿå‚è€ƒå¡ ğŸ“‹

### å¹¿æ’­è§„åˆ™é€ŸæŸ¥

```python
# è§„åˆ™1ï¼šä»å³å¾€å·¦å¯¹é½
(5, 3, 4)
   (3, 4)  â† å³å¯¹é½

# è§„åˆ™2ï¼šç»´åº¦è¦ä¹ˆç›¸ç­‰ï¼Œè¦ä¹ˆå…¶ä¸­ä¸€ä¸ªæ˜¯1
3 vs 3  âœ…
3 vs 1  âœ…
3 vs 2  âŒ

# è§„åˆ™3ï¼šç¼ºå¤±ç»´åº¦è§†ä¸º1
(3, 4) vs (4,)
â†’ (3, 4) vs (1, 4)
â†’ âœ… å…¼å®¹
```

---

### å¸¸ç”¨æ“ä½œé€ŸæŸ¥

```python
import numpy as np

# ===== å½¢çŠ¶è°ƒæ•´ =====
arr = np.array([1, 2, 3])  # (3,)

arr[None, :]    # (1, 3) è¡Œå‘é‡
arr[:, None]    # (3, 1) åˆ—å‘é‡
arr[None, :, None]  # (1, 3, 1)

# ===== æ ‡é‡å¹¿æ’­ =====
matrix + 10     # æ ‡é‡è‡ªåŠ¨æ‰©å±•

# ===== è¡Œ/åˆ—å¹¿æ’­ =====
matrix + row    # è¡Œå‘é‡å¹¿æ’­
matrix + col[:, None]  # åˆ—å‘é‡å¹¿æ’­

# ===== æ‰¹é‡å½’ä¸€åŒ– =====
(data - data.mean(axis=0)) / data.std(axis=0)

# ===== æˆå¯¹è·ç¦» =====
p1 = points[:, None, :]  # (n, 1, m)
p2 = points[None, :, :]  # (1, n, m)
distances = np.sqrt(((p1 - p2) ** 2).sum(axis=2))
```

---

### å‘é‡æ•°æ®åº“å¸¸ç”¨æ¨¡å¼ ğŸ—„ï¸

```python
# 1. Embeddingå½’ä¸€åŒ–
mean = embeddings.mean(axis=0, keepdims=True)
std = embeddings.std(axis=0, keepdims=True)
normalized = (embeddings - mean) / std

# 2. L2å½’ä¸€åŒ–
norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
l2_normalized = embeddings / norms

# 3. æ‰¹é‡ç›¸ä¼¼åº¦
similarities = queries @ embeddings.T

# 4. åŠ æƒæ±‚å’Œ
weighted = features * weights
scores = weighted.sum(axis=1)

# 5. Min-Maxå½’ä¸€åŒ–
min_val = embeddings.min(axis=0, keepdims=True)
max_val = embeddings.max(axis=0, keepdims=True)
minmax_normalized = (embeddings - min_val) / (max_val - min_val)
```

---

## å­¦ä¹ æ£€æŸ¥æ¸…å• âœ…

- [ ] ç†è§£å¹¿æ’­çš„3æ¡è§„åˆ™ï¼ˆå¯¹é½ã€å…¼å®¹ã€ç¼ºå¤±ï¼‰
- [ ] æŒæ¡`np.newaxis`/`None`è°ƒæ•´å½¢çŠ¶
- [ ] ç†è§£è™šæ‹Ÿæ‰©å±•ï¼ˆstride=0æœºåˆ¶ï¼‰
- [ ] èƒ½åˆ¤æ–­ä¸¤ä¸ªå½¢çŠ¶èƒ½å¦å¹¿æ’­
- [ ] æŒæ¡æ ‡é‡ã€ä¸€ç»´ã€äºŒç»´æ•°ç»„çš„å¹¿æ’­
- [ ] èƒ½ç”¨å¹¿æ’­å®ç°æ‰¹é‡å½’ä¸€åŒ–
- [ ] èƒ½è®¡ç®—æˆå¯¹è·ç¦»çŸ©é˜µï¼ˆå¹¿æ’­ï¼‰
- [ ] ç†è§£å¹¿æ’­çš„å†…å­˜å’Œæ€§èƒ½ä¼˜åŠ¿
- [ ] çŸ¥é“å¸¸è§çš„å½¢çŠ¶ä¸å…¼å®¹é”™è¯¯
- [ ] èƒ½åœ¨å‘é‡æ•°æ®åº“åœºæ™¯ä¸­åº”ç”¨å¹¿æ’­

---

## ä¸‹ä¸€æ­¥å­¦ä¹  ğŸš€

æ­å–œï¼ä½ å·²å®ŒæˆNumPyä¸‰éƒ¨æ›²ï¼š
1. âœ… æ•°ç»„åˆ›å»ºä¸ç´¢å¼•
2. âœ… å‘é‡åŒ–è¿ç®—
3. âœ… å¹¿æ’­æœºåˆ¶

**å»ºè®®ç»§ç»­å­¦ä¹ ï¼š**
1. **çº¿æ€§ä»£æ•°åº”ç”¨**ï¼šç‚¹ç§¯ã€èŒƒæ•°ã€ä½™å¼¦ç›¸ä¼¼åº¦
2. **å‘é‡æ•°æ®åº“å®æˆ˜**ï¼šFaissã€Annoyã€HNSW
3. **é«˜çº§NumPy**ï¼šé«˜çº§ç´¢å¼•ã€å†…å­˜è§†å›¾ã€ufunc

**å­¦ä¹ è·¯å¾„ï¼š**
```
NumPyåŸºç¡€ï¼ˆå·²å®Œæˆï¼‰âœ…
    â†“
ç‚¹ç§¯è¿ç®—
    â†“
å‘é‡èŒƒæ•°
    â†“
ä½™å¼¦ç›¸ä¼¼åº¦
    â†“
å‘é‡æ•°æ®åº“é¡¹ç›®å®æˆ˜
```

---

## å‚è€ƒèµ„æº ğŸ“š

1. **NumPyå®˜æ–¹æ–‡æ¡£**ï¼šhttps://numpy.org/doc/stable/user/basics.broadcasting.html
2. **Broadcastingå¯è§†åŒ–**ï¼šhttp://www.astroml.org/book_figures/appendix/fig_broadcast_visual.html
3. **NumPyæ€§èƒ½æŒ‡å—**ï¼šhttps://numpy.org/doc/stable/user/performance.html
4. **Faisså‘é‡æ•°æ®åº“**ï¼šhttps://github.com/facebookresearch/faiss

---

**ç»“è¯­ï¼š** å¹¿æ’­æœºåˆ¶æ˜¯NumPyçš„ç²¾é«“ï¼æŒæ¡äº†å¹¿æ’­ï¼Œä½ å°±èƒ½ç”¨æç®€çš„ä»£ç å®ç°é«˜æ€§èƒ½çš„æ‰¹é‡æ“ä½œã€‚åœ¨å‘é‡æ•°æ®åº“å¼€å‘ä¸­ï¼Œå¹¿æ’­è®©ç™¾ä¸‡çº§embeddingçš„å¤„ç†å˜å¾—è½»æ¾é«˜æ•ˆã€‚ç»§ç»­åŠ æ²¹ï¼ğŸš€
