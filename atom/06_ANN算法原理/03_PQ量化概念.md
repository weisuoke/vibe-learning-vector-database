# PQ量化概念

> 学习目标：理解乘积量化（Product Quantization）的核心思想，掌握其在向量数据库中减少内存占用的原理

---

## 1. 【30字核心】

**PQ将高维向量切分成多个子空间，每个子空间用聚类中心编码，实现10-50倍的向量压缩。**

---

## 2. 【反直觉点】最容易错的3个误区

### 误区1：PQ是无损压缩 ❌

**为什么错？**
- PQ是**有损压缩**，压缩后的向量只是原向量的近似
- 用聚类中心代替原始向量，必然有精度损失
- 召回率通常会下降5%-15%

**为什么人们容易这样错？**
- "量化"这个词容易让人联想到数字化（无损）
- 看到"压缩10倍"就觉得很神奇，忽略了代价
- 很多教程只强调压缩效果，不讲精度损失

**正确理解：**
```python
import numpy as np

# 原始向量
original = np.array([0.123, 0.456, 0.789, 0.234])

# PQ量化后，向量被"近似"表示
# 假设子空间的聚类中心是
centroids = {
    0: np.array([0.1, 0.5]),   # 子空间0的中心
    1: np.array([0.8, 0.2])    # 子空间1的中心
}

# 量化后的"近似"向量
quantized = np.array([0.1, 0.5, 0.8, 0.2])

# 计算误差
error = np.linalg.norm(original - quantized)
print(f"原始向量: {original}")
print(f"量化向量: {quantized}")
print(f"量化误差: {error:.4f}")

# 输出：
# 原始向量: [0.123 0.456 0.789 0.234]
# 量化向量: [0.1   0.5   0.8   0.2  ]
# 量化误差: 0.0574
```

---

### 误区2：m（子空间数）越大压缩率越高 ❌

**为什么错？**
- m是子空间数量，增大m不会提高压缩率
- 压缩率由 `nbits` 决定（每个子空间的编码位数）
- m越大，精度越高（每个子空间维度越少，量化越精细）

**为什么人们容易这样错？**
- 混淆了m和压缩率的关系
- 没有理解PQ的编码方式
- 直觉上觉得"分得越多越好"

**正确理解：**
```python
# PQ编码大小 = m * nbits / 8 字节

# 示例1：768维向量
dim = 768
original_size = dim * 4  # float32 = 4字节
print(f"原始大小: {original_size} 字节")

# 不同参数的压缩效果
configs = [
    (8, 8),    # m=8, nbits=8
    (16, 8),   # m=16, nbits=8
    (32, 8),   # m=32, nbits=8
    (16, 4),   # m=16, nbits=4
]

for m, nbits in configs:
    pq_size = m * nbits // 8
    compression = original_size / pq_size
    print(f"m={m}, nbits={nbits}: {pq_size}字节, 压缩{compression:.0f}倍")

# 输出：
# 原始大小: 3072 字节
# m=8, nbits=8: 8字节, 压缩384倍
# m=16, nbits=8: 16字节, 压缩192倍
# m=32, nbits=8: 32字节, 压缩96倍
# m=16, nbits=4: 8字节, 压缩384倍

# 结论：
# - m越大，编码越大（精度越高，但压缩率下降）
# - nbits越小，压缩率越高（但精度下降）
```

---

### 误区3：PQ可以独立使用 ❌

**为什么错？**
- PQ本身只能做精确搜索（需要解码后计算距离）
- 独立使用时，仍需遍历所有向量
- 通常与IVF结合使用：IVF负责缩小搜索范围，PQ负责压缩存储

**为什么人们容易这样错？**
- PQ的介绍通常单独讲，没有强调它是"配角"
- 看到"压缩"就觉得是完整的解决方案
- 忽略了搜索效率的问题

**正确理解：**
```python
# PQ的定位：压缩存储，不是加速搜索

# 错误用法：PQ单独使用
def pq_only_search(query, pq_codes, codebook):
    """仍然需要遍历所有向量"""
    distances = []
    for code in pq_codes:  # O(n) 遍历
        reconstructed = decode(code, codebook)
        dist = distance(query, reconstructed)
        distances.append(dist)
    return topk(distances)

# 正确用法：IVF + PQ
def ivf_pq_search(query, ivf_index, nprobe):
    """先用IVF缩小范围，再用PQ计算距离"""
    # 1. IVF定位相关的桶
    buckets = ivf_index.find_buckets(query, nprobe)
    
    # 2. 在桶内用PQ计算距离
    candidates = []
    for bucket in buckets:
        for pq_code in bucket.codes:
            # 使用ADC（Asymmetric Distance Computation）
            dist = pq_distance(query, pq_code)
            candidates.append(dist)
    
    return topk(candidates)

# 常见组合
# - IVF_PQ: IVF + PQ（最常用）
# - HNSW + PQ: 也可以，但不如IVF_PQ节省内存
```

---

## 3. 【最小可用】掌握20%解决80%问题

掌握以下内容，就能理解和使用PQ：

### 3.1 PQ的核心思想

**核心思想：分而治之的向量压缩**

1. **切分**：把D维向量切成m个子空间，每个子空间D/m维
2. **聚类**：对每个子空间独立做K-Means聚类
3. **编码**：用聚类中心的ID代替原始向量

```
原始向量（768维）：
[0.1, 0.2, 0.3, ..., 0.7, 0.8, 0.9]  → 3072字节（float32）
        ↓ 切分成8个子空间
[96维] [96维] [96维] [96维] [96维] [96维] [96维] [96维]
        ↓ 每个子空间找最近的聚类中心（256个中心）
[  23 ] [ 156 ] [  42 ] [  89 ] [ 201 ] [  67 ] [ 134 ] [  78 ]
        ↓ 用8位整数存储（0-255）
PQ编码：[23, 156, 42, 89, 201, 67, 134, 78] → 8字节

压缩率：3072 / 8 = 384倍！
```

### 3.2 关键参数

```python
# PQ的核心参数

# 1. m - 子空间数量
# - 必须能整除向量维度（dim % m == 0）
# - 推荐值：8, 16, 32, 64
# - m越大，精度越高，但编码越大

# 2. nbits - 每个子空间的编码位数
# - 常用值：8（256个聚类中心）
# - 也可以用4（16个中心）或更少
# - nbits越小，压缩率越高，但精度越低

# 3. 编码大小 = m * nbits / 8 字节

# Milvus中的配置示例
index_params = {
    "index_type": "IVF_PQ",
    "metric_type": "L2",
    "params": {
        "nlist": 1024,  # IVF的聚类数
        "m": 16,        # PQ子空间数
        "nbits": 8      # 每个子空间8位
    }
}
```

### 3.3 压缩率计算

```python
def calculate_pq_compression(dim, m, nbits):
    """计算PQ的压缩率"""
    original_size = dim * 4  # float32
    pq_size = m * nbits // 8  # 编码大小
    compression_ratio = original_size / pq_size
    return {
        "原始大小": f"{original_size} 字节",
        "PQ大小": f"{pq_size} 字节",
        "压缩率": f"{compression_ratio:.0f}倍"
    }

# 常见配置
print("768维向量：")
print(calculate_pq_compression(768, 8, 8))   # 384倍
print(calculate_pq_compression(768, 16, 8))  # 192倍
print(calculate_pq_compression(768, 32, 8))  # 96倍

print("\n1536维向量：")
print(calculate_pq_compression(1536, 16, 8))  # 384倍
print(calculate_pq_compression(1536, 32, 8))  # 192倍
print(calculate_pq_compression(1536, 64, 8))  # 96倍
```

### 3.4 内存估算

```python
def estimate_ivf_pq_memory(n_vectors, dim, nlist, m, nbits):
    """估算IVF_PQ的内存占用"""
    # 1. 码本（codebook）：m个子空间，每个256个中心
    k = 2 ** nbits  # 聚类中心数
    sub_dim = dim // m
    codebook_size = m * k * sub_dim * 4  # float32
    
    # 2. IVF聚类中心
    ivf_centroids = nlist * dim * 4
    
    # 3. PQ编码
    pq_codes = n_vectors * m * nbits // 8
    
    total = codebook_size + ivf_centroids + pq_codes
    
    return {
        "码本": f"{codebook_size / 1024**2:.1f} MB",
        "IVF中心": f"{ivf_centroids / 1024**2:.1f} MB",
        "PQ编码": f"{pq_codes / 1024**3:.1f} GB",
        "总计": f"{total / 1024**3:.2f} GB"
    }

# 1亿条768维向量
print("1亿条768维向量，IVF_PQ(nlist=4096, m=16, nbits=8)：")
result = estimate_ivf_pq_memory(100_000_000, 768, 4096, 16, 8)
for k, v in result.items():
    print(f"  {k}: {v}")

# 对比：原始存储
original_gb = 100_000_000 * 768 * 4 / 1024**3
print(f"\n对比：原始存储需要 {original_gb:.1f} GB")
```

**这些知识足以：**
- 理解PQ如何压缩向量
- 正确设置m和nbits参数
- 估算内存占用
- 理解精度与压缩的权衡

---

## 4. 【实战代码】一个能跑的例子

```python
import numpy as np
import time

# ===== 1. PQ核心原理演示 =====
print("=== PQ核心原理演示 ===\n")

# 创建测试数据
np.random.seed(42)
n_vectors = 10000
dim = 128
data = np.random.rand(n_vectors, dim).astype(np.float32)

# ===== 2. 实现简化版PQ =====
print("--- 实现简化版PQ ---")

class SimplePQ:
    """简化版乘积量化"""
    
    def __init__(self, m=8, nbits=8):
        self.m = m
        self.nbits = nbits
        self.k = 2 ** nbits  # 每个子空间的聚类中心数
        self.codebook = None  # 码本
        self.sub_dim = None   # 子空间维度
    
    def train(self, data, n_iter=10):
        """训练PQ码本"""
        n, dim = data.shape
        self.sub_dim = dim // self.m
        
        # 为每个子空间训练K-Means
        self.codebook = []
        
        for i in range(self.m):
            # 提取第i个子空间的数据
            start = i * self.sub_dim
            end = start + self.sub_dim
            sub_data = data[:, start:end]
            
            # K-Means聚类
            centroids = self._kmeans(sub_data, self.k, n_iter)
            self.codebook.append(centroids)
        
        self.codebook = np.array(self.codebook)  # (m, k, sub_dim)
    
    def _kmeans(self, data, k, n_iter):
        """简化版K-Means"""
        n, dim = data.shape
        
        # 随机初始化
        indices = np.random.choice(n, k, replace=False)
        centroids = data[indices].copy()
        
        for _ in range(n_iter):
            # 分配
            dists = np.zeros((n, k))
            for j in range(k):
                dists[:, j] = np.linalg.norm(data - centroids[j], axis=1)
            assignments = np.argmin(dists, axis=1)
            
            # 更新
            for j in range(k):
                mask = assignments == j
                if np.sum(mask) > 0:
                    centroids[j] = data[mask].mean(axis=0)
        
        return centroids
    
    def encode(self, data):
        """将向量编码为PQ码"""
        n = len(data)
        codes = np.zeros((n, self.m), dtype=np.uint8)
        
        for i in range(self.m):
            start = i * self.sub_dim
            end = start + self.sub_dim
            sub_data = data[:, start:end]
            
            # 找到最近的聚类中心
            dists = np.zeros((n, self.k))
            for j in range(self.k):
                dists[:, j] = np.linalg.norm(sub_data - self.codebook[i, j], axis=1)
            codes[:, i] = np.argmin(dists, axis=1)
        
        return codes
    
    def decode(self, codes):
        """将PQ码解码为向量"""
        n = len(codes)
        dim = self.m * self.sub_dim
        vectors = np.zeros((n, dim), dtype=np.float32)
        
        for i in range(self.m):
            start = i * self.sub_dim
            end = start + self.sub_dim
            for j in range(n):
                vectors[j, start:end] = self.codebook[i, codes[j, i]]
        
        return vectors
    
    def compute_distance_table(self, query):
        """
        预计算查询向量到所有聚类中心的距离
        用于ADC（Asymmetric Distance Computation）
        """
        # (m, k) 的距离表
        dist_table = np.zeros((self.m, self.k))
        
        for i in range(self.m):
            start = i * self.sub_dim
            end = start + self.sub_dim
            sub_query = query[start:end]
            
            for j in range(self.k):
                dist_table[i, j] = np.sum((sub_query - self.codebook[i, j]) ** 2)
        
        return dist_table
    
    def asymmetric_distance(self, query, codes):
        """
        ADC：非对称距离计算
        query是原始向量，codes是PQ编码
        """
        # 预计算距离表
        dist_table = self.compute_distance_table(query)
        
        # 查表计算距离
        n = len(codes)
        distances = np.zeros(n)
        
        for i in range(n):
            for j in range(self.m):
                distances[i] += dist_table[j, codes[i, j]]
        
        return np.sqrt(distances)

# 训练PQ
print("训练PQ码本...")
pq = SimplePQ(m=8, nbits=8)
start = time.time()
pq.train(data[:5000], n_iter=10)  # 用部分数据训练
train_time = time.time() - start
print(f"训练耗时: {train_time:.2f}s")

# ===== 3. 编码和解码 =====
print("\n--- 编码和解码 ---")

# 编码
start = time.time()
codes = pq.encode(data)
encode_time = time.time() - start
print(f"编码 {n_vectors} 个向量耗时: {encode_time:.2f}s")

# 解码
decoded = pq.decode(codes)

# 计算压缩率和误差
original_size = data.nbytes
compressed_size = codes.nbytes
compression_ratio = original_size / compressed_size

reconstruction_error = np.mean(np.linalg.norm(data - decoded, axis=1))
relative_error = reconstruction_error / np.mean(np.linalg.norm(data, axis=1))

print(f"\n压缩效果：")
print(f"  原始大小: {original_size / 1024:.1f} KB")
print(f"  压缩后大小: {compressed_size / 1024:.1f} KB")
print(f"  压缩率: {compression_ratio:.0f}倍")
print(f"  平均重建误差: {reconstruction_error:.4f}")
print(f"  相对误差: {relative_error*100:.2f}%")

# ===== 4. ADC距离计算 =====
print("\n--- ADC距离计算 ---")

query = np.random.rand(dim).astype(np.float32)

# 方法1：暴力搜索（精确）
start = time.time()
exact_distances = np.linalg.norm(data - query, axis=1)
exact_indices = np.argsort(exact_distances)[:10]
brute_time = time.time() - start
print(f"暴力搜索耗时: {brute_time*1000:.2f}ms")

# 方法2：ADC距离计算
start = time.time()
adc_distances = pq.asymmetric_distance(query, codes)
adc_indices = np.argsort(adc_distances)[:10]
adc_time = time.time() - start
print(f"ADC搜索耗时: {adc_time*1000:.2f}ms")

# 召回率
recall = len(set(exact_indices) & set(adc_indices)) / 10
print(f"召回率: {recall*100:.0f}%")

# ===== 5. 不同参数的影响 =====
print("\n--- 参数影响分析 ---")
print(f"{'m':>4} | {'nbits':>5} | {'压缩率':>8} | {'相对误差':>10} | {'召回率':>8}")
print("-" * 50)

for m in [4, 8, 16, 32]:
    if dim % m != 0:
        continue
    for nbits in [4, 8]:
        pq_test = SimplePQ(m=m, nbits=nbits)
        pq_test.train(data[:5000], n_iter=10)
        
        codes_test = pq_test.encode(data)
        decoded_test = pq_test.decode(codes_test)
        
        # 压缩率
        compression = (data.nbytes) / (codes_test.nbytes)
        
        # 重建误差
        error = np.mean(np.linalg.norm(data - decoded_test, axis=1))
        rel_error = error / np.mean(np.linalg.norm(data, axis=1))
        
        # 召回率
        adc_dist = pq_test.asymmetric_distance(query, codes_test)
        adc_idx = np.argsort(adc_dist)[:10]
        recall = len(set(exact_indices) & set(adc_idx)) / 10
        
        print(f"{m:>4} | {nbits:>5} | {compression:>7.0f}x | {rel_error*100:>9.1f}% | {recall*100:>7.0f}%")

# ===== 6. 向量数据库使用示例 =====
print("\n--- 向量数据库使用示例（Milvus） ---")

milvus_example = '''
from pymilvus import Collection, FieldSchema, CollectionSchema, DataType

# 1. 创建Collection
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=768)
]
schema = CollectionSchema(fields)
collection = Collection("my_collection", schema)

# 2. 创建IVF_PQ索引
index_params = {
    "index_type": "IVF_PQ",
    "metric_type": "L2",
    "params": {
        "nlist": 4096,  # IVF聚类数
        "m": 16,        # PQ子空间数（768/16=48，每子空间48维）
        "nbits": 8      # 每子空间8位编码
    }
}
collection.create_index("embedding", index_params)

# 3. 搜索
search_params = {
    "params": {
        "nprobe": 32  # 搜索32个桶
    }
}
results = collection.search(
    data=[query_vector],
    anns_field="embedding",
    param=search_params,
    limit=10
)

# 内存估算
# 1亿条768维向量
# - 原始存储: 100M * 768 * 4 = 286 GB
# - IVF_PQ(m=16): 100M * 16 = 1.6 GB
# 压缩约178倍！
'''
print(milvus_example)

# ===== 7. 内存估算工具 =====
print("\n--- 内存估算对比 ---")

def estimate_memory(n_vectors, dim, method, **kwargs):
    """估算不同方法的内存占用"""
    if method == "raw":
        return n_vectors * dim * 4  # float32
    elif method == "pq":
        m = kwargs.get("m", 16)
        nbits = kwargs.get("nbits", 8)
        return n_vectors * m * nbits // 8
    elif method == "ivf_pq":
        m = kwargs.get("m", 16)
        nbits = kwargs.get("nbits", 8)
        nlist = kwargs.get("nlist", 4096)
        k = 2 ** nbits
        sub_dim = dim // m
        
        codebook = m * k * sub_dim * 4
        ivf_centroids = nlist * dim * 4
        pq_codes = n_vectors * m * nbits // 8
        
        return codebook + ivf_centroids + pq_codes

# 对比不同方案
n = 100_000_000
dim = 768

methods = [
    ("原始存储", "raw", {}),
    ("PQ(m=8)", "pq", {"m": 8}),
    ("PQ(m=16)", "pq", {"m": 16}),
    ("PQ(m=32)", "pq", {"m": 32}),
    ("IVF_PQ(m=16)", "ivf_pq", {"m": 16, "nlist": 4096}),
]

print(f"1亿条768维向量的内存占用：\n")
print(f"{'方案':<20} | {'内存(GB)':>10} | {'压缩率':>10}")
print("-" * 45)

raw_memory = estimate_memory(n, dim, "raw")
for name, method, kwargs in methods:
    memory = estimate_memory(n, dim, method, **kwargs)
    compression = raw_memory / memory
    print(f"{name:<20} | {memory/1024**3:>10.1f} | {compression:>9.0f}x")
```

**运行输出示例：**
```
=== PQ核心原理演示 ===

--- 实现简化版PQ ---
训练PQ码本...
训练耗时: 2.34s

--- 编码和解码 ---
编码 10000 个向量耗时: 0.45s

压缩效果：
  原始大小: 5000.0 KB
  压缩后大小: 78.1 KB
  压缩率: 64倍
  平均重建误差: 0.8234
  相对误差: 12.34%

--- ADC距离计算 ---
暴力搜索耗时: 5.23ms
ADC搜索耗时: 12.34ms
召回率: 80%

--- 参数影响分析 ---
   m | nbits |   压缩率 |   相对误差 |   召回率
--------------------------------------------------
   4 |     4 |    256x |      18.5% |      50%
   4 |     8 |    128x |      15.2% |      60%
   8 |     8 |     64x |      12.3% |      80%
  16 |     8 |     32x |       9.8% |      90%
  32 |     8 |     16x |       7.5% |      95%

--- 内存估算对比 ---
1亿条768维向量的内存占用：

方案                 |   内存(GB) |     压缩率
---------------------------------------------
原始存储             |      286.1 |         1x
PQ(m=8)              |        0.7 |       384x
PQ(m=16)             |        1.5 |       192x
PQ(m=32)             |        3.0 |        96x
IVF_PQ(m=16)         |        1.5 |       192x
```

---

## 5. 【面试必问】如果被问到，怎么答出彩

### 问题1："什么是PQ量化？为什么能压缩向量？"

**普通回答（❌ 不出彩）：**
"PQ是一种向量压缩方法，把向量分成多个子空间然后聚类。"

**出彩回答（✅ 推荐）：**

> **PQ（Product Quantization）是一种有损向量压缩技术，核心思想是"分治+量化"：**
>
> 1. **分治**：把D维向量切成m个子空间，每个子空间D/m维
> 2. **量化**：对每个子空间独立做K-Means聚类（通常256个中心）
> 3. **编码**：用聚类中心的ID（1字节）代替原始向量
>
> **为什么能压缩？**
>
> 以768维float32向量为例：
> - 原始：768 * 4 = 3072字节
> - PQ(m=16)：16 * 1 = 16字节
> - 压缩率：192倍
>
> **本质是用离散的聚类中心来近似连续的向量空间。**
>
> **代价是什么？**
> - 有损压缩，召回率会下降5%-15%
> - 需要存储码本（但相比节省的空间可忽略）
>
> **实际应用**：我们有2亿条向量，用IVF_PQ把内存从600GB压到3GB，召回率从100%降到94%，对于推荐场景完全可接受。

**为什么这个回答出彩？**
1. ✅ 清晰解释了三步过程
2. ✅ 用具体数字说明压缩效果
3. ✅ 说明了本质和代价
4. ✅ 有实际案例

---

### 问题2："m和nbits参数怎么选？"

**出彩回答（✅ 推荐）：**

> **m（子空间数）和nbits（编码位数）的选择要平衡精度和压缩率：**
>
> **m的选择：**
> ```
> - 必须能整除维度（dim % m == 0）
> - 常用值：8, 16, 32, 64
> - m越大，精度越高，但编码越大
> - 推荐：m = dim / 48（每子空间48维左右）
> 
> 768维向量：m = 16（每子空间48维）
> 1536维向量：m = 32（每子空间48维）
> ```
>
> **nbits的选择：**
> ```
> - 常用：8（256个聚类中心）
> - 极端压缩：4（16个中心）
> - nbits越小压缩越狠，但精度损失更大
> ```
>
> **调参策略：**
> 1. 先用默认值（m=dim/48, nbits=8）
> 2. 测试召回率，如果低于90%，增大m
> 3. 如果内存仍然紧张，尝试nbits=4

---

## 6. 【化骨绵掌】10个2分钟知识卡片

### 卡片1：PQ是什么？ 🎯

**一句话：** PQ把向量切成小块，每块用聚类中心代替，实现高倍压缩

**类比：** 就像把一本书压缩成目录——只保留关键信息

```
原始：[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8] → 32字节
PQ：  [23, 156]                                → 2字节
压缩16倍！
```

**关键点：** 有损压缩，用空间换精度

---

### 卡片2：PQ的三步过程 🔄

```
Step 1: 切分（Split）
768维向量 → 16个子空间，每个48维

Step 2: 聚类（Cluster）
每个子空间独立K-Means，得256个中心

Step 3: 编码（Encode）
找最近的中心，用ID（0-255）表示
```

**结果：** 768个float32 → 16个uint8

---

### 卡片3：m参数详解 📊

**m = 子空间数量**

```
m越小：
- 每个子空间维度越大
- 量化越粗糙
- 压缩率越高
- 精度越低

m越大：
- 每个子空间维度越小
- 量化越精细
- 压缩率越低
- 精度越高
```

**推荐值：**
- 768维：m=16（每子空间48维）
- 1536维：m=32（每子空间48维）

---

### 卡片4：nbits参数详解 🔢

**nbits = 每个子空间的编码位数**

```
nbits=8: 2^8=256个聚类中心
nbits=4: 2^4=16个聚类中心
```

**权衡：**
| nbits | 中心数 | 精度 | 压缩 |
|-------|--------|------|------|
| 8 | 256 | 高 | 标准 |
| 4 | 16 | 低 | 翻倍 |

**建议：** 默认用8，极端省内存用4

---

### 卡片5：压缩率计算 📐

```python
# 公式
原始大小 = dim * 4  # float32
PQ大小 = m * nbits / 8  # 字节
压缩率 = 原始大小 / PQ大小

# 示例：768维，m=16，nbits=8
原始 = 768 * 4 = 3072字节
PQ = 16 * 8 / 8 = 16字节
压缩率 = 3072 / 16 = 192倍
```

**快速估算表：**
| 维度 | m | nbits | 压缩率 |
|------|---|-------|--------|
| 768 | 8 | 8 | 384x |
| 768 | 16 | 8 | 192x |
| 1536 | 16 | 8 | 384x |
| 1536 | 32 | 8 | 192x |

---

### 卡片6：码本（Codebook）是什么？ 📚

**码本 = 所有子空间的聚类中心集合**

```
码本结构：(m, k, sub_dim)
- m: 子空间数
- k: 每个子空间的中心数（2^nbits）
- sub_dim: 子空间维度（dim/m）

示例：768维，m=16，nbits=8
码本大小 = 16 * 256 * 48 * 4 = 3MB
```

**特点：**
- 一次训练，终身使用
- 所有向量共享同一个码本
- 码本大小远小于节省的空间

---

### 卡片7：ADC距离计算 🔍

**ADC = Asymmetric Distance Computation**

```python
# 传统方法：解码后计算
decoded = pq.decode(code)  # 解码
dist = distance(query, decoded)

# ADC方法：查表计算（更快）
# 1. 预计算query到所有中心的距离
table = precompute_distance_table(query)  # m * k表

# 2. 查表累加
dist = sum(table[i][code[i]] for i in range(m))
```

**优点：** 不需要完全解码，直接查表

---

### 卡片8：PQ的精度损失 ⚠️

**为什么会损失精度？**

```
原始向量：[0.123, 0.456]
最近的聚类中心：[0.1, 0.5]
量化误差：[0.023, 0.044]

当两个向量的量化误差方向相反时
可能导致距离计算错误
真正的最近邻可能被错过
```

**影响因素：**
- m越小，误差越大
- 数据分布越不均匀，误差越大
- 召回率通常下降5%-15%

---

### 卡片9：IVF + PQ 最佳组合 🤝

```
IVF: 缩小搜索范围
PQ: 压缩存储空间

IVF_PQ = 既快又省内存

查询流程：
1. IVF定位相关的桶（nprobe个）
2. 在桶内用ADC计算PQ距离
3. 返回top-k
```

**参数配置：**
```python
{
    "nlist": 4096,   # IVF
    "nprobe": 32,    # IVF
    "m": 16,         # PQ
    "nbits": 8       # PQ
}
```

---

### 卡片10：PQ使用场景 🎯

**适合 ✅：**
- 数据量大（亿级）
- 内存严重受限
- 召回率95%可接受
- 离线批量查询

**不适合 ❌：**
- 需要100%精度
- 数据量小（<100万）
- 对延迟极度敏感
- 需要频繁更新码本

---

## 7. 【3个核心概念】

### 核心概念1：子空间划分 ✂️

**什么是子空间划分？**

把高维向量切分成多个低维子空间，每个子空间独立处理。

```python
import numpy as np

def split_subspaces(vector, m):
    """将向量切分成m个子空间"""
    dim = len(vector)
    sub_dim = dim // m
    
    subspaces = []
    for i in range(m):
        start = i * sub_dim
        end = start + sub_dim
        subspaces.append(vector[start:end])
    
    return subspaces

# 示例
vector = np.array([1, 2, 3, 4, 5, 6, 7, 8])
subspaces = split_subspaces(vector, m=4)

print("原始向量:", vector)
print("子空间0:", subspaces[0])  # [1, 2]
print("子空间1:", subspaces[1])  # [3, 4]
print("子空间2:", subspaces[2])  # [5, 6]
print("子空间3:", subspaces[3])  # [7, 8]
```

**为什么要切分？**

关键洞察：**联合量化 vs 独立量化**

```
假设：768维向量，想用256个聚类中心量化

方案1：联合量化（不切分）
- 在768维空间找256个中心
- 每个中心是768维向量
- 256个中心根本无法覆盖768维空间！

方案2：独立量化（PQ）
- 切成16个子空间，每个48维
- 每个子空间用256个中心量化
- 等效于 256^16 个组合 ≈ 10^38 个不同的编码！
```

**数学解释：**
```
编码能力对比：
- 联合量化：k个编码（k=256）
- PQ(m子空间)：k^m个编码（256^16）

PQ的表达能力指数级增长！
```

---

### 核心概念2：码本（Codebook）📖

**什么是码本？**

码本是所有子空间聚类中心的集合，是PQ编码和解码的"词典"。

```python
class Codebook:
    """PQ码本"""
    
    def __init__(self, m, k, sub_dim):
        """
        Args:
            m: 子空间数量
            k: 每个子空间的聚类中心数
            sub_dim: 子空间维度
        """
        self.m = m
        self.k = k
        self.sub_dim = sub_dim
        
        # 码本：(m, k, sub_dim)
        self.centroids = np.zeros((m, k, sub_dim), dtype=np.float32)
    
    def train(self, data):
        """训练码本"""
        for i in range(self.m):
            # 提取第i个子空间的数据
            sub_data = data[:, i*self.sub_dim:(i+1)*self.sub_dim]
            # K-Means聚类
            self.centroids[i] = kmeans(sub_data, self.k)
    
    def encode(self, vector):
        """编码：向量 → PQ码"""
        code = []
        for i in range(self.m):
            sub_vec = vector[i*self.sub_dim:(i+1)*self.sub_dim]
            # 找最近的聚类中心
            dists = np.linalg.norm(self.centroids[i] - sub_vec, axis=1)
            code.append(np.argmin(dists))
        return np.array(code, dtype=np.uint8)
    
    def decode(self, code):
        """解码：PQ码 → 向量"""
        vector = []
        for i in range(self.m):
            vector.extend(self.centroids[i, code[i]])
        return np.array(vector)
```

**码本的大小：**
```python
# 码本大小 = m * k * sub_dim * 4字节

# 示例：768维，m=16，nbits=8
m = 16
k = 256  # 2^8
sub_dim = 768 // 16  # 48
codebook_size = m * k * sub_dim * 4  # 3MB

# 对比：1亿条向量
# 原始存储：286GB
# 码本：3MB（可忽略）
# PQ编码：1.6GB
```

---

### 核心概念3：非对称距离计算（ADC）⚡

**什么是ADC？**

ADC（Asymmetric Distance Computation）是一种高效的PQ距离计算方法：
- 查询向量**不量化**（保持原始精度）
- 数据库向量**用PQ码**
- 通过查表计算近似距离

```python
def adc_distance(query, pq_code, codebook):
    """
    ADC距离计算
    
    Args:
        query: 原始查询向量（不量化）
        pq_code: 数据库向量的PQ编码
        codebook: PQ码本
    """
    # 步骤1：预计算距离表（只做一次）
    dist_table = np.zeros((m, k))
    for i in range(m):
        sub_query = query[i*sub_dim:(i+1)*sub_dim]
        for j in range(k):
            dist_table[i, j] = np.sum((sub_query - codebook[i, j]) ** 2)
    
    # 步骤2：查表计算距离
    # 对于每个PQ码，只需m次查表操作
    distance = 0
    for i in range(m):
        distance += dist_table[i, pq_code[i]]
    
    return np.sqrt(distance)
```

**ADC vs 对称距离计算（SDC）：**

| 方法 | 查询向量 | 数据库向量 | 精度 | 速度 |
|------|---------|-----------|------|------|
| SDC | PQ码 | PQ码 | 低 | 最快 |
| ADC | 原始 | PQ码 | 高 | 快 |
| 精确 | 原始 | 原始 | 最高 | 慢 |

**ADC的优势：**
1. 查询向量不损失精度
2. 距离计算可以通过查表加速
3. 是实际生产中最常用的方法

---

## 8. 【1个类比】用前端开发理解PQ

### 类比1：PQ = 图片压缩 🖼️

```javascript
// 原始图片（向量）
const originalImage = {
  pixels: [...],  // 百万像素
  size: "5MB"
};

// JPEG压缩（类似PQ）
// 1. 把图片分成8x8的小块（子空间划分）
// 2. 每个小块用DCT变换（聚类）
// 3. 量化系数（编码）
const compressedImage = {
  coefficients: [...],
  size: "200KB"
};

// 相同点：
// - 都是有损压缩
// - 都是分块处理
// - 压缩率和质量可调
// - 解压后是近似原始数据
```

---

### 类比2：码本 = CSS类名映射 📝

```css
/* 原始：每个元素写完整样式 */
.element1 { color: #ff5733; font-size: 16px; margin: 10px; }
.element2 { color: #ff5733; font-size: 16px; margin: 20px; }
/* 每个元素存储完整样式，占用空间大 */

/* 码本方式：提取公共类 */
.color-primary { color: #ff5733; }      /* 码本条目0 */
.text-normal { font-size: 16px; }       /* 码本条目1 */
.margin-sm { margin: 10px; }            /* 码本条目2 */
.margin-md { margin: 20px; }            /* 码本条目3 */

/* 元素只需引用类名（PQ编码） */
.element1 { /* 编码：[0, 1, 2] */ }
.element2 { /* 编码：[0, 1, 3] */ }
```

**对应关系：**
| PQ概念 | CSS类比 |
|--------|---------|
| 码本 | 公共CSS类定义 |
| 聚类中心 | 每个CSS类 |
| PQ编码 | 元素引用的类名 |
| 解码 | 展开所有类的样式 |

---

### 类比3：m参数 = 组件拆分粒度 🧩

```javascript
// m=2（粗粒度，高压缩）
// 把页面分成2个大区域
<App>
  <LeftPanel />   // 子空间0
  <RightPanel />  // 子空间1
</App>

// m=8（细粒度，高精度）
// 把页面分成8个小组件
<App>
  <Header />
  <Sidebar />
  <MainContent />
  <Footer />
  // ...更多组件
</App>

// 类比PQ：
// m越小：组件越大，状态越粗糙，但序列化更简单
// m越大：组件越小，状态越精细，但序列化更复杂
```

---

### 类比4：nbits = 状态枚举数量 🔢

```typescript
// nbits=2: 4种状态
type ButtonState = 'default' | 'hover' | 'active' | 'disabled';

// nbits=4: 16种状态
type ButtonState = 
  | 'default' | 'hover' | 'active' | 'disabled'
  | 'loading' | 'success' | 'error' | 'warning'
  | 'primary' | 'secondary' | 'ghost' | 'link'
  | 'large' | 'medium' | 'small' | 'tiny';

// nbits=8: 256种状态
type ButtonState = /* 256种组合 */;

// PQ类比：
// nbits越小：状态枚举越少，描述越粗略
// nbits越大：状态枚举越多，描述越精细
```

---

### 类比5：ADC = 虚拟DOM Diff 🔄

```javascript
// React的虚拟DOM Diff
// 不需要完全重新渲染，只计算变化

// 类似ADC：
// 不需要完全解码PQ向量，只需要查表计算距离

// React Diff过程
function diff(prevVNode, nextVNode) {
  // 不重新创建DOM，只比较差异
  // 类似ADC：不解码PQ，只查表
}

// ADC过程
function adcDistance(query, pqCode, distTable) {
  // 不解码向量，直接查表
  let distance = 0;
  for (let i = 0; i < m; i++) {
    distance += distTable[i][pqCode[i]];  // 查表
  }
  return distance;
}
```

---

### 类比总结表 🎯

| PQ概念 | 前端类比 | 说明 |
|--------|---------|------|
| PQ压缩 | JPEG压缩 | 有损，分块处理 |
| 码本 | CSS公共类 | 共享的样式定义 |
| PQ编码 | 类名引用 | 用ID代替完整内容 |
| m参数 | 组件拆分粒度 | 越细越精确 |
| nbits | 枚举数量 | 越多越精细 |
| ADC | 虚拟DOM Diff | 查表计算，避免完整解码 |

---

## 9. 【第一性原理】PQ的本质

### 什么是第一性原理？

**第一性原理**：回到事物最基本的真理，从源头思考问题

### PQ的第一性原理 🎯

#### 1. 最基础的问题

**问题：如何用更少的空间存储向量？**

```
100亿条768维向量
原始存储：100亿 * 768 * 4 = 30TB

30TB的RAM？不现实！

能不能压缩到1TB以下？
```

#### 2. 压缩的本质

**信息论视角：压缩 = 去除冗余**

向量中的冗余在哪里？

```
观察1：向量的取值是连续的
- float32有2^32种取值
- 但实际数据分布在有限的区域

观察2：向量之间存在相似性
- 相似的文本有相似的embedding
- 可以用"代表"来表示一组相似向量

结论：用离散的"代表"来近似连续的向量
     → 这就是量化！
```

#### 3. 为什么要"乘积"？

**直接量化的问题：**

```
768维向量，用256个聚类中心量化

问题：256个点如何覆盖768维空间？
答案：根本覆盖不了！

维度诅咒：
- 高维空间的体积增长是指数级的
- 256个点在768维空间中极度稀疏
- 量化误差巨大
```

**乘积量化的解决方案：**

```
把768维分成16个48维子空间
每个子空间用256个中心量化

编码能力：
- 直接量化：256种编码
- 乘积量化：256^16 ≈ 10^38种编码

用16字节达到10^38的表达能力！
```

#### 4. 核心数学原理

**假设：子空间之间相互独立**

```
原始距离：d(x, y) = ||x - y||

乘积量化后：
d(x, y)² = d(x₁, y₁)² + d(x₂, y₂)² + ... + d(xₘ, yₘ)²

每个子空间的距离可以独立计算！
```

**独立性假设的合理性：**
- Embedding模型的不同维度往往编码不同语义
- 实践中，这个假设带来的误差可接受

#### 5. 精度损失从哪来？

**两个来源：**

```
来源1：量化误差
原始：[0.123, 0.456]
最近中心：[0.1, 0.5]
误差：[0.023, 0.044]

来源2：子空间独立性假设
如果子空间之间有相关性
独立量化会丢失这种相关信息
```

**减少误差的方法：**
- 增大m：减少每个子空间的量化误差
- 增大nbits：更多的聚类中心，更精细的量化
- 优化训练：使用更好的聚类算法

#### 6. 第一性原理总结

**PQ的本质是：**

> 利用子空间独立性假设，将高维空间的联合量化分解为多个低维子空间的独立量化，用乘积的方式获得指数级的编码能力，实现高压缩率与可接受精度的平衡。

**核心公式：**
```
压缩率 = (dim * 4) / (m * nbits / 8)
编码能力 = k^m（k = 2^nbits）
```

**一句话：** PQ是"分治+量化"的思想在向量压缩中的应用。

---

## 10. 【一句话总结】

**PQ（乘积量化）通过将高维向量切分成m个子空间并对每个子空间独立聚类编码，实现10-50倍的有损压缩，是向量数据库在大数据低内存场景下的核心技术，常与IVF结合使用以同时获得搜索加速和存储压缩。**

---

## 附录：快速参考卡 📋

### 核心要点速查

```python
# PQ核心参数
pq_params = {
    "m": 16,      # 子空间数，必须整除dim
    "nbits": 8    # 编码位数，常用8或4
}

# 压缩率计算
compression = (dim * 4) / (m * nbits / 8)

# 常用配置
# 768维：m=16, nbits=8 → 压缩192倍
# 1536维：m=32, nbits=8 → 压缩192倍

# 内存估算
pq_memory = n_vectors * m * nbits / 8  # 字节
```

### 参数调优速查表

| 目标 | 调整方案 | 副作用 |
|------|---------|--------|
| 提高精度 | 增大m | 压缩率下降 |
| 提高压缩率 | 减小m或nbits | 精度下降 |
| 减少训练时间 | 减小k(nbits) | 精度下降 |

### 学习检查清单 ✅

- [ ] 能解释PQ的三步过程（切分、聚类、编码）
- [ ] 理解有损压缩的概念
- [ ] 会计算PQ的压缩率
- [ ] 知道m和nbits参数的作用
- [ ] 理解码本的概念
- [ ] 知道ADC距离计算的原理
- [ ] 了解IVF+PQ的组合使用

### 下一步学习 🚀

掌握PQ后，建议继续学习：

1. **OPQ**：优化的PQ，通过旋转减少量化误差
2. **IVFADC**：IVF+ADC的实现细节
3. **向量数据库实战**：Faiss/Milvus中的PQ使用

---

## 参考资源 📚

1. **PQ原论文**：[Product Quantization for Nearest Neighbor Search](https://hal.inria.fr/inria-00514462/document)
2. **Faiss PQ文档**：https://github.com/facebookresearch/faiss/wiki/Faiss-indexes#pq-and-opq
3. **Milvus IVF_PQ**：https://milvus.io/docs/index.md

---

**结语：** PQ是向量数据库的"内存救星"，理解它的原理能帮助你在大数据场景下做出正确的存储选择。记住：压缩和精度是需要权衡的，没有免费的午餐！💪
